[2025-04-13 13:08:26,326] INFO Kafka Connect worker initializing ... (org.apache.kafka.connect.cli.AbstractConnectCli:114)
[2025-04-13 13:08:26,335] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote=true, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=/home/kafkadmin/kafka/bin/../logs, -Dlog4j.configuration=file:/home/kafkadmin/kafka/bin/../config/connect-log4j.properties
	jvm.spec = Ubuntu, OpenJDK 64-Bit Server VM, 21.0.6, 21.0.6+7-Ubuntu-122.04.1
	jvm.classpath = /home/kafkadmin/kafka/bin/../libs/activation-1.1.1.jar:/home/kafkadmin/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/kafkadmin/kafka/bin/../libs/argparse4j-0.7.0.jar:/home/kafkadmin/kafka/bin/../libs/audience-annotations-0.12.0.jar:/home/kafkadmin/kafka/bin/../libs/caffeine-2.9.3.jar:/home/kafkadmin/kafka/bin/../libs/checker-qual-3.19.0.jar:/home/kafkadmin/kafka/bin/../libs/commons-beanutils-1.9.4.jar:/home/kafkadmin/kafka/bin/../libs/commons-cli-1.4.jar:/home/kafkadmin/kafka/bin/../libs/commons-collections-3.2.2.jar:/home/kafkadmin/kafka/bin/../libs/commons-digester-2.1.jar:/home/kafkadmin/kafka/bin/../libs/commons-io-2.14.0.jar:/home/kafkadmin/kafka/bin/../libs/commons-lang3-3.12.0.jar:/home/kafkadmin/kafka/bin/../libs/commons-logging-1.2.jar:/home/kafkadmin/kafka/bin/../libs/commons-validator-1.7.jar:/home/kafkadmin/kafka/bin/../libs/connect-api-3.8.1.jar:/home/kafkadmin/kafka/bin/../libs/connect-basic-auth-extension-3.8.1.jar:/home/kafkadmin/kafka/bin/../libs/connect-json-3.8.1.jar:/home/kafkadmin/kafka/bin/../libs/connect-mirror-3.8.1.jar:/home/kafkadmin/kafka/bin/../libs/connect-mirror-client-3.8.1.jar:/home/kafkadmin/kafka/bin/../libs/connect-runtime-3.8.1.jar:/home/kafkadmin/kafka/bin/../libs/connect-transforms-3.8.1.jar:/home/kafkadmin/kafka/bin/../libs/error_prone_annotations-2.10.0.jar:/home/kafkadmin/kafka/bin/../libs/hk2-api-2.6.1.jar:/home/kafkadmin/kafka/bin/../libs/hk2-locator-2.6.1.jar:/home/kafkadmin/kafka/bin/../libs/hk2-utils-2.6.1.jar:/home/kafkadmin/kafka/bin/../libs/jackson-annotations-2.16.2.jar:/home/kafkadmin/kafka/bin/../libs/jackson-core-2.16.2.jar:/home/kafkadmin/kafka/bin/../libs/jackson-databind-2.16.2.jar:/home/kafkadmin/kafka/bin/../libs/jackson-dataformat-csv-2.16.2.jar:/home/kafkadmin/kafka/bin/../libs/jackson-datatype-jdk8-2.16.2.jar:/home/kafkadmin/kafka/bin/../libs/jackson-jaxrs-base-2.16.2.jar:/home/kafkadmin/kafka/bin/../libs/jackson-jaxrs-json-provider-2.16.2.jar:/home/kafkadmin/kafka/bin/../libs/jackson-module-afterburner-2.16.2.jar:/home/kafkadmin/kafka/bin/../libs/jackson-module-jaxb-annotations-2.16.2.jar:/home/kafkadmin/kafka/bin/../libs/jackson-module-scala_2.13-2.16.2.jar:/home/kafkadmin/kafka/bin/../libs/jakarta.activation-api-1.2.2.jar:/home/kafkadmin/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/kafkadmin/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/home/kafkadmin/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/kafkadmin/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/kafkadmin/kafka/bin/../libs/jakarta.xml.bind-api-2.3.3.jar:/home/kafkadmin/kafka/bin/../libs/javassist-3.29.2-GA.jar:/home/kafkadmin/kafka/bin/../libs/javax.activation-api-1.2.0.jar:/home/kafkadmin/kafka/bin/../libs/javax.annotation-api-1.3.2.jar:/home/kafkadmin/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/home/kafkadmin/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/kafkadmin/kafka/bin/../libs/jaxb-api-2.3.1.jar:/home/kafkadmin/kafka/bin/../libs/jersey-client-2.39.1.jar:/home/kafkadmin/kafka/bin/../libs/jersey-common-2.39.1.jar:/home/kafkadmin/kafka/bin/../libs/jersey-container-servlet-2.39.1.jar:/home/kafkadmin/kafka/bin/../libs/jersey-container-servlet-core-2.39.1.jar:/home/kafkadmin/kafka/bin/../libs/jersey-hk2-2.39.1.jar:/home/kafkadmin/kafka/bin/../libs/jersey-server-2.39.1.jar:/home/kafkadmin/kafka/bin/../libs/jetty-client-9.4.56.v20240826.jar:/home/kafkadmin/kafka/bin/../libs/jetty-continuation-9.4.56.v20240826.jar:/home/kafkadmin/kafka/bin/../libs/jetty-http-9.4.56.v20240826.jar:/home/kafkadmin/kafka/bin/../libs/jetty-io-9.4.56.v20240826.jar:/home/kafkadmin/kafka/bin/../libs/jetty-security-9.4.56.v20240826.jar:/home/kafkadmin/kafka/bin/../libs/jetty-server-9.4.56.v20240826.jar:/home/kafkadmin/kafka/bin/../libs/jetty-servlet-9.4.56.v20240826.jar:/home/kafkadmin/kafka/bin/../libs/jetty-servlets-9.4.56.v20240826.jar:/home/kafkadmin/kafka/bin/../libs/jetty-util-9.4.56.v20240826.jar:/home/kafkadmin/kafka/bin/../libs/jetty-util-ajax-9.4.56.v20240826.jar:/home/kafkadmin/kafka/bin/../libs/jline-3.25.1.jar:/home/kafkadmin/kafka/bin/../libs/jopt-simple-5.0.4.jar:/home/kafkadmin/kafka/bin/../libs/jose4j-0.9.4.jar:/home/kafkadmin/kafka/bin/../libs/jsr305-3.0.2.jar:/home/kafkadmin/kafka/bin/../libs/kafka-clients-3.8.1.jar:/home/kafkadmin/kafka/bin/../libs/kafka-group-coordinator-3.8.1.jar:/home/kafkadmin/kafka/bin/../libs/kafka-group-coordinator-api-3.8.1.jar:/home/kafkadmin/kafka/bin/../libs/kafka-log4j-appender-3.8.1.jar:/home/kafkadmin/kafka/bin/../libs/kafka-metadata-3.8.1.jar:/home/kafkadmin/kafka/bin/../libs/kafka-raft-3.8.1.jar:/home/kafkadmin/kafka/bin/../libs/kafka-server-3.8.1.jar:/home/kafkadmin/kafka/bin/../libs/kafka-server-common-3.8.1.jar:/home/kafkadmin/kafka/bin/../libs/kafka-shell-3.8.1.jar:/home/kafkadmin/kafka/bin/../libs/kafka-storage-3.8.1.jar:/home/kafkadmin/kafka/bin/../libs/kafka-storage-api-3.8.1.jar:/home/kafkadmin/kafka/bin/../libs/kafka-streams-3.8.1.jar:/home/kafkadmin/kafka/bin/../libs/kafka-streams-examples-3.8.1.jar:/home/kafkadmin/kafka/bin/../libs/kafka-streams-scala_2.13-3.8.1.jar:/home/kafkadmin/kafka/bin/../libs/kafka-streams-test-utils-3.8.1.jar:/home/kafkadmin/kafka/bin/../libs/kafka-tools-3.8.1.jar:/home/kafkadmin/kafka/bin/../libs/kafka-tools-api-3.8.1.jar:/home/kafkadmin/kafka/bin/../libs/kafka-transaction-coordinator-3.8.1.jar:/home/kafkadmin/kafka/bin/../libs/kafka_2.13-3.8.1.jar:/home/kafkadmin/kafka/bin/../libs/lz4-java-1.8.0.jar:/home/kafkadmin/kafka/bin/../libs/maven-artifact-3.9.6.jar:/home/kafkadmin/kafka/bin/../libs/metrics-core-2.2.0.jar:/home/kafkadmin/kafka/bin/../libs/metrics-core-4.1.12.1.jar:/home/kafkadmin/kafka/bin/../libs/netty-buffer-4.1.110.Final.jar:/home/kafkadmin/kafka/bin/../libs/netty-codec-4.1.110.Final.jar:/home/kafkadmin/kafka/bin/../libs/netty-common-4.1.110.Final.jar:/home/kafkadmin/kafka/bin/../libs/netty-handler-4.1.110.Final.jar:/home/kafkadmin/kafka/bin/../libs/netty-resolver-4.1.110.Final.jar:/home/kafkadmin/kafka/bin/../libs/netty-transport-4.1.110.Final.jar:/home/kafkadmin/kafka/bin/../libs/netty-transport-classes-epoll-4.1.110.Final.jar:/home/kafkadmin/kafka/bin/../libs/netty-transport-native-epoll-4.1.110.Final.jar:/home/kafkadmin/kafka/bin/../libs/netty-transport-native-unix-common-4.1.110.Final.jar:/home/kafkadmin/kafka/bin/../libs/opentelemetry-proto-1.0.0-alpha.jar:/home/kafkadmin/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/kafkadmin/kafka/bin/../libs/paranamer-2.8.jar:/home/kafkadmin/kafka/bin/../libs/pcollections-4.0.1.jar:/home/kafkadmin/kafka/bin/../libs/plexus-utils-3.5.1.jar:/home/kafkadmin/kafka/bin/../libs/protobuf-java-3.25.5.jar:/home/kafkadmin/kafka/bin/../libs/reflections-0.10.2.jar:/home/kafkadmin/kafka/bin/../libs/reload4j-1.2.25.jar:/home/kafkadmin/kafka/bin/../libs/rocksdbjni-7.9.2.jar:/home/kafkadmin/kafka/bin/../libs/scala-collection-compat_2.13-2.10.0.jar:/home/kafkadmin/kafka/bin/../libs/scala-java8-compat_2.13-1.0.2.jar:/home/kafkadmin/kafka/bin/../libs/scala-library-2.13.14.jar:/home/kafkadmin/kafka/bin/../libs/scala-logging_2.13-3.9.4.jar:/home/kafkadmin/kafka/bin/../libs/scala-reflect-2.13.14.jar:/home/kafkadmin/kafka/bin/../libs/slf4j-api-1.7.36.jar:/home/kafkadmin/kafka/bin/../libs/slf4j-reload4j-1.7.36.jar:/home/kafkadmin/kafka/bin/../libs/snappy-java-1.1.10.5.jar:/home/kafkadmin/kafka/bin/../libs/swagger-annotations-2.2.8.jar:/home/kafkadmin/kafka/bin/../libs/trogdor-3.8.1.jar:/home/kafkadmin/kafka/bin/../libs/zookeeper-3.8.4.jar:/home/kafkadmin/kafka/bin/../libs/zookeeper-jute-3.8.4.jar:/home/kafkadmin/kafka/bin/../libs/zstd-jni-1.5.6-4.jar
	os.spec = Linux, amd64, 6.8.0-1026-azure
	os.vcpus = 2
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2025-04-13 13:08:26,335] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.AbstractConnectCli:120)
[2025-04-13 13:08:26,372] INFO Loading plugin from: /home/kafkadmin/kafka/connect-plugins/jdbc (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-04-13 13:08:26,655] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/kafkadmin/kafka/connect-plugins/jdbc/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-04-13 13:08:26,876] INFO Loading plugin from: /home/kafkadmin/kafka/connect-plugins/debezium (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-04-13 13:08:26,937] INFO Using up-to-date JsonConverter implementation (io.debezium.converters.CloudEventsConverter:118)
[2025-04-13 13:08:27,012] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/kafkadmin/kafka/connect-plugins/debezium/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-04-13 13:08:27,069] INFO Loading plugin from: classpath (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-04-13 13:08:27,082] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@76ed5528 (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-04-13 13:08:27,082] INFO Scanning plugins with ServiceLoaderScanner took 711 ms (org.apache.kafka.connect.runtime.isolation.PluginScanner:70)
[2025-04-13 13:08:27,087] INFO Loading plugin from: /home/kafkadmin/kafka/connect-plugins/jdbc (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-04-13 13:08:27,483] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/kafkadmin/kafka/connect-plugins/jdbc/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-04-13 13:08:27,502] INFO Loading plugin from: /home/kafkadmin/kafka/connect-plugins/debezium (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-04-13 13:08:27,788] INFO Registered loader: PluginClassLoader{pluginLocation=file:/home/kafkadmin/kafka/connect-plugins/debezium/} (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-04-13 13:08:27,799] INFO Loading plugin from: classpath (org.apache.kafka.connect.runtime.isolation.PluginScanner:75)
[2025-04-13 13:08:30,865] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@76ed5528 (org.apache.kafka.connect.runtime.isolation.PluginScanner:80)
[2025-04-13 13:08:30,867] INFO Scanning plugins with ReflectionScanner took 3780 ms (org.apache.kafka.connect.runtime.isolation.PluginScanner:70)
[2025-04-13 13:08:30,874] WARN One or more plugins are missing ServiceLoader manifests may not be usable with plugin.discovery=service_load: [
file:/home/kafkadmin/kafka/connect-plugins/jdbc/	io.confluent.connect.jdbc.JdbcSinkConnector	sink	10.7.0
file:/home/kafkadmin/kafka/connect-plugins/jdbc/	io.confluent.connect.jdbc.JdbcSourceConnector	source	10.7.0
]
Read the documentation at https://kafka.apache.org/documentation.html#connect_plugindiscovery for instructions on migrating your plugins to take advantage of the performance improvements of service_load mode. To silence this warning, set plugin.discovery=only_scan in the worker config. (org.apache.kafka.connect.runtime.isolation.Plugins:122)
[2025-04-13 13:08:30,875] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-04-13 13:08:30,875] INFO Added plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-04-13 13:08:30,875] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-04-13 13:08:30,875] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-04-13 13:08:30,875] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-04-13 13:08:30,875] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-04-13 13:08:30,875] INFO Added plugin 'io.debezium.connector.sqlserver.SqlServerConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-04-13 13:08:30,875] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-04-13 13:08:30,875] INFO Added plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-04-13 13:08:30,876] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-04-13 13:08:30,876] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-04-13 13:08:30,876] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-04-13 13:08:30,876] INFO Added plugin 'io.debezium.converters.BinaryDataConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-04-13 13:08:30,876] INFO Added plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-04-13 13:08:30,876] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-04-13 13:08:30,876] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-04-13 13:08:30,876] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-04-13 13:08:30,876] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-04-13 13:08:30,876] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-04-13 13:08:30,876] INFO Added plugin 'io.debezium.transforms.ExtractNewRecordState' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-04-13 13:08:30,876] INFO Added plugin 'io.debezium.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-04-13 13:08:30,877] INFO Added plugin 'io.debezium.transforms.partitions.PartitionRouting' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-04-13 13:08:30,877] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-04-13 13:08:30,877] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-04-13 13:08:30,877] INFO Added plugin 'io.debezium.transforms.outbox.EventRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-04-13 13:08:30,879] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-04-13 13:08:30,879] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-04-13 13:08:30,879] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-04-13 13:08:30,879] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-04-13 13:08:30,879] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-04-13 13:08:30,879] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-04-13 13:08:30,880] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-04-13 13:08:30,880] INFO Added plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-04-13 13:08:30,880] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-04-13 13:08:30,880] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-04-13 13:08:30,880] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-04-13 13:08:30,880] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-04-13 13:08:30,880] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-04-13 13:08:30,880] INFO Added plugin 'io.debezium.transforms.HeaderToValue' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-04-13 13:08:30,880] INFO Added plugin 'io.debezium.transforms.SchemaChangeEventFilter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-04-13 13:08:30,880] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-04-13 13:08:30,880] INFO Added plugin 'io.debezium.transforms.ExtractSchemaToNewRecord' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-04-13 13:08:30,880] INFO Added plugin 'io.debezium.transforms.ByLogicalTableRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-04-13 13:08:30,880] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-04-13 13:08:30,881] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-04-13 13:08:30,881] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-04-13 13:08:30,881] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-04-13 13:08:30,881] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-04-13 13:08:30,882] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-04-13 13:08:30,882] INFO Added plugin 'io.debezium.transforms.TimezoneConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-04-13 13:08:30,882] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-04-13 13:08:30,882] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-04-13 13:08:30,882] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-04-13 13:08:30,882] INFO Added plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-04-13 13:08:30,882] INFO Added plugin 'io.debezium.transforms.ExtractChangedRecordState' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-04-13 13:08:30,882] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-04-13 13:08:30,882] INFO Added plugin 'io.debezium.transforms.tracing.ActivateTracingSpan' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-04-13 13:08:30,883] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-04-13 13:08:30,883] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-04-13 13:08:30,883] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-04-13 13:08:30,883] INFO Added plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-04-13 13:08:30,883] INFO Added plugin 'io.debezium.connector.sqlserver.rest.DebeziumSqlServerConnectRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-04-13 13:08:30,883] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-04-13 13:08:30,883] INFO Added plugin 'io.debezium.converters.CloudEventsConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-04-13 13:08:30,883] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-04-13 13:08:30,883] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:105)
[2025-04-13 13:08:30,886] INFO Added alias 'RecordIsTombstone' to plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-04-13 13:08:30,886] INFO Added alias 'CloudEventsConverter' to plugin 'io.debezium.converters.CloudEventsConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-04-13 13:08:30,888] INFO Added alias 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-04-13 13:08:30,888] INFO Added alias 'EnvVar' to plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-04-13 13:08:30,888] INFO Added alias 'EnvVarConfigProvider' to plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-04-13 13:08:30,888] INFO Added alias 'MirrorCheckpointConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-04-13 13:08:30,888] INFO Added alias 'Boolean' to plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-04-13 13:08:30,888] INFO Added alias 'HeaderToValue' to plugin 'io.debezium.transforms.HeaderToValue' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-04-13 13:08:30,888] INFO Added alias 'DebeziumSqlServer' to plugin 'io.debezium.connector.sqlserver.rest.DebeziumSqlServerConnectRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-04-13 13:08:30,889] INFO Added alias 'PartitionRouting' to plugin 'io.debezium.transforms.partitions.PartitionRouting' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-04-13 13:08:30,889] INFO Added alias 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-04-13 13:08:30,889] INFO Added alias 'StringConverter' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-04-13 13:08:30,889] INFO Added alias 'IntegerConverter' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-04-13 13:08:30,889] INFO Added alias 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-04-13 13:08:30,890] INFO Added alias 'JdbcSource' to plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-04-13 13:08:30,890] INFO Added alias 'LongConverter' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-04-13 13:08:30,891] INFO Added alias 'DropHeaders' to plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-04-13 13:08:30,891] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-04-13 13:08:30,891] INFO Added alias 'SqlServerConnector' to plugin 'io.debezium.connector.sqlserver.SqlServerConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-04-13 13:08:30,891] INFO Added alias 'ExtractSchemaToNewRecord' to plugin 'io.debezium.transforms.ExtractSchemaToNewRecord' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-04-13 13:08:30,891] INFO Added alias 'BinaryData' to plugin 'io.debezium.converters.BinaryDataConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-04-13 13:08:30,891] INFO Added alias 'DirectoryConfigProvider' to plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-04-13 13:08:30,891] INFO Added alias 'ShortConverter' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-04-13 13:08:30,891] INFO Added alias 'CloudEvents' to plugin 'io.debezium.converters.CloudEventsConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-04-13 13:08:30,891] INFO Added alias 'TimezoneConverter' to plugin 'io.debezium.transforms.TimezoneConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-04-13 13:08:30,891] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-04-13 13:08:30,891] INFO Added alias 'Simple' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-04-13 13:08:30,891] INFO Added alias 'AllConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-04-13 13:08:30,891] INFO Added alias 'ExtractNewRecordState' to plugin 'io.debezium.transforms.ExtractNewRecordState' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-04-13 13:08:30,892] INFO Added alias 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-04-13 13:08:30,892] INFO Added alias 'Directory' to plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-04-13 13:08:30,892] INFO Added alias 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-04-13 13:08:30,892] INFO Added alias 'BooleanConverter' to plugin 'org.apache.kafka.connect.converters.BooleanConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-04-13 13:08:30,892] INFO Added alias 'HasHeaderKey' to plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-04-13 13:08:30,893] INFO Added alias 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-04-13 13:08:30,893] INFO Added alias 'ExtractChangedRecordState' to plugin 'io.debezium.transforms.ExtractChangedRecordState' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-04-13 13:08:30,893] INFO Added alias 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-04-13 13:08:30,893] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-04-13 13:08:30,893] INFO Added alias 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-04-13 13:08:30,893] INFO Added alias 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-04-13 13:08:30,893] INFO Added alias 'JsonConverter' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-04-13 13:08:30,893] INFO Added alias 'JdbcSinkConnector' to plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-04-13 13:08:30,893] INFO Added alias 'SqlServer' to plugin 'io.debezium.connector.sqlserver.SqlServerConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-04-13 13:08:30,894] INFO Added alias 'JdbcSink' to plugin 'io.confluent.connect.jdbc.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-04-13 13:08:30,894] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-04-13 13:08:30,894] INFO Added alias 'JdbcSourceConnector' to plugin 'io.confluent.connect.jdbc.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-04-13 13:08:30,894] INFO Added alias 'NoneConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-04-13 13:08:30,894] INFO Added alias 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-04-13 13:08:30,894] INFO Added alias 'ByLogicalTableRouter' to plugin 'io.debezium.transforms.ByLogicalTableRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-04-13 13:08:30,894] INFO Added alias 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-04-13 13:08:30,894] INFO Added alias 'FileConfigProvider' to plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-04-13 13:08:30,894] INFO Added alias 'EventRouter' to plugin 'io.debezium.transforms.outbox.EventRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-04-13 13:08:30,894] INFO Added alias 'SchemaChangeEventFilter' to plugin 'io.debezium.transforms.SchemaChangeEventFilter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-04-13 13:08:30,894] INFO Added alias 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-04-13 13:08:30,894] INFO Added alias 'File' to plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-04-13 13:08:30,894] INFO Added alias 'FloatConverter' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-04-13 13:08:30,894] INFO Added alias 'ActivateTracingSpan' to plugin 'io.debezium.transforms.tracing.ActivateTracingSpan' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-04-13 13:08:30,894] INFO Added alias 'DoubleConverter' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-04-13 13:08:30,895] INFO Added alias 'DebeziumSqlServerConnectRestExtension' to plugin 'io.debezium.connector.sqlserver.rest.DebeziumSqlServerConnectRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-04-13 13:08:30,895] INFO Added alias 'BinaryDataConverter' to plugin 'io.debezium.converters.BinaryDataConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-04-13 13:08:30,895] INFO Added alias 'TopicNameMatches' to plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-04-13 13:08:30,895] INFO Added alias 'MirrorHeartbeatConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-04-13 13:08:30,895] INFO Added alias 'InsertHeader' to plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-04-13 13:08:30,895] INFO Added alias 'MirrorSourceConnector' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-04-13 13:08:30,897] INFO Added alias 'PrincipalConnectorClientConfigOverridePolicy' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-04-13 13:08:30,897] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-04-13 13:08:30,897] INFO Added alias 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-04-13 13:08:30,897] INFO Added alias 'Filter' to plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:109)
[2025-04-13 13:08:30,943] INFO DistributedConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	config.providers = []
	config.storage.replication.factor = 1
	config.storage.topic = connect-configs
	connect.protocol = sessioned
	connections.max.idle.ms = 540000
	connector.client.config.override.policy = All
	exactly.once.source.support = disabled
	group.id = connect-cluster
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	heartbeat.interval.ms = 3000
	inter.worker.key.generation.algorithm = HmacSHA256
	inter.worker.key.size = null
	inter.worker.key.ttl.ms = 3600000
	inter.worker.signature.algorithm = HmacSHA256
	inter.worker.verification.algorithms = [HmacSHA256]
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	listeners = [http://:8083]
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 60000
	offset.flush.timeout.ms = 5000
	offset.storage.partitions = 25
	offset.storage.replication.factor = 1
	offset.storage.topic = connect-offsets
	plugin.discovery = hybrid_warn
	plugin.path = [/home/kafkadmin/kafka/connect-plugins/]
	rebalance.timeout.ms = 60000
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 40000
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	scheduled.rebalance.max.delay.ms = 300000
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	status.storage.partitions = 5
	status.storage.replication.factor = 1
	status.storage.topic = connect-status
	task.shutdown.graceful.timeout.ms = 5000
	topic.creation.enable = true
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
	worker.sync.timeout.ms = 3000
	worker.unsync.backoff.ms = 300000
 (org.apache.kafka.connect.runtime.distributed.DistributedConfig:372)
[2025-04-13 13:08:30,945] INFO Creating Kafka admin client (org.apache.kafka.connect.runtime.WorkerConfig:283)
[2025-04-13 13:08:30,949] INFO AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.controllers = []
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = true
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:372)
[2025-04-13 13:08:31,017] INFO These configurations '[config.storage.topic, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, key.converter.schemas.enable, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:381)
[2025-04-13 13:08:31,019] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-04-13 13:08:31,020] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-04-13 13:08:31,020] INFO Kafka startTimeMs: 1744549711017 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-04-13 13:08:31,388] INFO Kafka cluster ID: PRZJITuEQBeLmWOW7dnIsg (org.apache.kafka.connect.runtime.WorkerConfig:300)
[2025-04-13 13:08:31,389] INFO App info kafka.admin.client for adminclient-1 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-04-13 13:08:31,401] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-04-13 13:08:31,401] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-04-13 13:08:31,401] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-04-13 13:08:31,410] INFO PublicConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	listeners = [http://:8083]
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
 (org.apache.kafka.connect.runtime.rest.RestServerConfig$PublicConfig:372)
[2025-04-13 13:08:31,420] INFO Logging initialized @5718ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:170)
[2025-04-13 13:08:31,463] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:121)
[2025-04-13 13:08:31,464] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:192)
[2025-04-13 13:08:31,495] INFO jetty-9.4.56.v20240826; built: 2024-08-26T17:15:05.868Z; git: ec6782ff5ead824dabdcf47fa98f90a4aedff401; jvm 21.0.6+7-Ubuntu-122.04.1 (org.eclipse.jetty.server.Server:375)
[2025-04-13 13:08:31,521] INFO Started http_8083@370d49d1{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:333)
[2025-04-13 13:08:31,522] INFO Started @5820ms (org.eclipse.jetty.server.Server:415)
[2025-04-13 13:08:31,549] INFO Advertised URI: http://10.0.0.4:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:412)
[2025-04-13 13:08:31,549] INFO REST server listening at http://10.0.0.4:8083/, advertising URL http://10.0.0.4:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:212)
[2025-04-13 13:08:31,549] INFO Advertised URI: http://10.0.0.4:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:412)
[2025-04-13 13:08:31,549] INFO REST admin endpoints at http://10.0.0.4:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:215)
[2025-04-13 13:08:31,549] INFO Advertised URI: http://10.0.0.4:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:412)
[2025-04-13 13:08:31,550] INFO Setting up All Policy for ConnectorClientConfigOverride. This will allow all client configurations to be overridden (org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy:44)
[2025-04-13 13:08:31,556] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-04-13 13:08:31,573] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-04-13 13:08:31,573] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-04-13 13:08:31,573] INFO Kafka startTimeMs: 1744549711572 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-04-13 13:08:31,581] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-04-13 13:08:31,581] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-04-13 13:08:31,600] INFO Advertised URI: http://10.0.0.4:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:412)
[2025-04-13 13:08:31,632] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-04-13 13:08:31,632] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-04-13 13:08:31,632] INFO Kafka startTimeMs: 1744549711632 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-04-13 13:08:31,635] INFO Kafka Connect worker initialization took 5306ms (org.apache.kafka.connect.cli.AbstractConnectCli:141)
[2025-04-13 13:08:31,635] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2025-04-13 13:08:31,638] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Herder starting (org.apache.kafka.connect.runtime.distributed.DistributedHerder:370)
[2025-04-13 13:08:31,639] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:232)
[2025-04-13 13:08:31,639] INFO Starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:231)
[2025-04-13 13:08:31,639] INFO Starting KafkaBasedLog with topic connect-offsets reportErrorsToCallback=false (org.apache.kafka.connect.util.KafkaBasedLog:253)
[2025-04-13 13:08:31,640] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2025-04-13 13:08:31,644] INFO AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.controllers = []
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-shared-admin
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = true
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:372)
[2025-04-13 13:08:31,649] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:381)
[2025-04-13 13:08:31,651] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-04-13 13:08:31,651] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-04-13 13:08:31,651] INFO Kafka startTimeMs: 1744549711649 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-04-13 13:08:31,701] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:234)
[2025-04-13 13:08:31,782] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:334)
[2025-04-13 13:08:31,783] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:339)
[2025-04-13 13:08:31,784] INFO node0 Scavenging every 600000ms (org.eclipse.jetty.server.session:132)
[2025-04-13 13:08:31,822] INFO Created topic (name=connect-offsets, numPartitions=25, replicationFactor=1, replicasAssignments=null, configs={cleanup.policy=compact}) on brokers at localhost:9092 (org.apache.kafka.connect.util.TopicAdmin:415)
[2025-04-13 13:08:31,854] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-offsets
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2025-04-13 13:08:31,946] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-04-13 13:08:32,037] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:381)
[2025-04-13 13:08:32,037] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-04-13 13:08:32,037] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-04-13 13:08:32,038] INFO Kafka startTimeMs: 1744549712037 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-04-13 13:08:32,068] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-offsets
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-04-13 13:08:32,074] INFO [Producer clientId=connect-cluster-offsets] Cluster ID: PRZJITuEQBeLmWOW7dnIsg (org.apache.kafka.clients.Metadata:364)
[2025-04-13 13:08:32,101] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-04-13 13:08:32,179] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, plugin.path, config.storage.replication.factor, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-04-13 13:08:32,179] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-04-13 13:08:32,179] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-04-13 13:08:32,179] INFO Kafka startTimeMs: 1744549712179 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-04-13 13:08:32,204] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Cluster ID: PRZJITuEQBeLmWOW7dnIsg (org.apache.kafka.clients.Metadata:364)
[2025-04-13 13:08:32,232] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Assigned to partition(s): connect-offsets-17, connect-offsets-20, connect-offsets-11, connect-offsets-23, connect-offsets-14, connect-offsets-5, connect-offsets-0, connect-offsets-8, connect-offsets-7, connect-offsets-4, connect-offsets-1, connect-offsets-10, connect-offsets-13, connect-offsets-24, connect-offsets-21, connect-offsets-16, connect-offsets-3, connect-offsets-9, connect-offsets-15, connect-offsets-18, connect-offsets-19, connect-offsets-22, connect-offsets-6, connect-offsets-2, connect-offsets-12 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:574)
[2025-04-13 13:08:32,238] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-17 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-04-13 13:08:32,239] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-20 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-04-13 13:08:32,239] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-11 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-04-13 13:08:32,239] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-23 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-04-13 13:08:32,239] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-14 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-04-13 13:08:32,239] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-5 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-04-13 13:08:32,239] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-04-13 13:08:32,239] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-8 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-04-13 13:08:32,241] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-7 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-04-13 13:08:32,241] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-4 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-04-13 13:08:32,241] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-1 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-04-13 13:08:32,241] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-10 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-04-13 13:08:32,241] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-13 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-04-13 13:08:32,242] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-24 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-04-13 13:08:32,242] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-21 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-04-13 13:08:32,242] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-16 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-04-13 13:08:32,242] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-3 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-04-13 13:08:32,242] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-9 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-04-13 13:08:32,242] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-15 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-04-13 13:08:32,242] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-18 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-04-13 13:08:32,242] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-19 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-04-13 13:08:32,242] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-22 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-04-13 13:08:32,242] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-6 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-04-13 13:08:32,243] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-2 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-04-13 13:08:32,243] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-12 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-04-13 13:08:32,626] INFO 127.0.0.1 - - [13/Apr/2025:13:08:32 +0000] "GET / HTTP/1.1" 404 437 "-" "curl/7.81.0" 63 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-04-13 13:08:32,778] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-10 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-04-13 13:08:32,782] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-8 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-04-13 13:08:32,783] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-14 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-04-13 13:08:32,783] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-12 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-04-13 13:08:32,783] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-2 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-04-13 13:08:32,783] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-04-13 13:08:32,783] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-6 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-04-13 13:08:32,783] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-04-13 13:08:32,785] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-24 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-04-13 13:08:32,785] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-18 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-04-13 13:08:32,786] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-16 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-04-13 13:08:32,786] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-22 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-04-13 13:08:32,786] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-20 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-04-13 13:08:32,786] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-9 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-04-13 13:08:32,786] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-7 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-04-13 13:08:32,786] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-13 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-04-13 13:08:32,786] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-11 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-04-13 13:08:32,786] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-04-13 13:08:32,786] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-5 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-04-13 13:08:32,786] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-04-13 13:08:32,786] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-23 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-04-13 13:08:32,786] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-17 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-04-13 13:08:32,787] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-15 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-04-13 13:08:32,787] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-21 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-04-13 13:08:32,787] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Resetting offset for partition connect-offsets-19 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-04-13 13:08:32,791] INFO Finished reading KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:310)
[2025-04-13 13:08:32,791] INFO Started KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:312)
[2025-04-13 13:08:32,791] INFO Finished reading offsets topic and starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:248)
[2025-04-13 13:08:32,793] INFO Worker started (org.apache.kafka.connect.runtime.Worker:242)
[2025-04-13 13:08:32,793] INFO Starting KafkaBasedLog with topic connect-status reportErrorsToCallback=false (org.apache.kafka.connect.util.KafkaBasedLog:253)
[2025-04-13 13:08:32,813] INFO Started o.e.j.s.ServletContextHandler@1b18f38f{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:921)
[2025-04-13 13:08:32,813] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:299)
[2025-04-13 13:08:32,814] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2025-04-13 13:08:32,851] INFO Created topic (name=connect-status, numPartitions=5, replicationFactor=1, replicasAssignments=null, configs={cleanup.policy=compact}) on brokers at localhost:9092 (org.apache.kafka.connect.util.TopicAdmin:415)
[2025-04-13 13:08:32,852] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-statuses
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2025-04-13 13:08:32,852] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-04-13 13:08:32,877] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:381)
[2025-04-13 13:08:32,877] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-04-13 13:08:32,877] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-04-13 13:08:32,881] INFO Kafka startTimeMs: 1744549712877 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-04-13 13:08:32,882] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-statuses
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-04-13 13:08:32,882] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-04-13 13:08:32,899] INFO [Producer clientId=connect-cluster-statuses] Cluster ID: PRZJITuEQBeLmWOW7dnIsg (org.apache.kafka.clients.Metadata:364)
[2025-04-13 13:08:32,911] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, plugin.path, config.storage.replication.factor, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-04-13 13:08:32,911] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-04-13 13:08:32,912] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-04-13 13:08:32,912] INFO Kafka startTimeMs: 1744549712911 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-04-13 13:08:32,930] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Cluster ID: PRZJITuEQBeLmWOW7dnIsg (org.apache.kafka.clients.Metadata:364)
[2025-04-13 13:08:32,932] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Assigned to partition(s): connect-status-1, connect-status-3, connect-status-2, connect-status-0, connect-status-4 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:574)
[2025-04-13 13:08:32,932] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-1 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-04-13 13:08:32,932] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-3 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-04-13 13:08:32,932] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-2 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-04-13 13:08:32,932] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-04-13 13:08:32,932] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-status-4 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-04-13 13:08:33,048] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-04-13 13:08:33,048] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-2 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-04-13 13:08:33,048] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-04-13 13:08:33,048] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-04-13 13:08:33,049] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Resetting offset for partition connect-status-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-04-13 13:08:33,049] INFO Finished reading KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:310)
[2025-04-13 13:08:33,049] INFO Started KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:312)
[2025-04-13 13:08:33,054] INFO Starting KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:376)
[2025-04-13 13:08:33,055] INFO Starting KafkaBasedLog with topic connect-configs reportErrorsToCallback=false (org.apache.kafka.connect.util.KafkaBasedLog:253)
[2025-04-13 13:08:33,094] INFO Created topic (name=connect-configs, numPartitions=1, replicationFactor=1, replicasAssignments=null, configs={cleanup.policy=compact}) on brokers at localhost:9092 (org.apache.kafka.connect.util.TopicAdmin:415)
[2025-04-13 13:08:33,095] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-configs
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2025-04-13 13:08:33,098] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-04-13 13:08:33,111] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, group.id, plugin.path, config.storage.replication.factor, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:381)
[2025-04-13 13:08:33,111] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-04-13 13:08:33,111] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-04-13 13:08:33,111] INFO Kafka startTimeMs: 1744549713111 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-04-13 13:08:33,114] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster-configs
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-04-13 13:08:33,116] INFO initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-04-13 13:08:33,128] INFO These configurations '[config.storage.topic, metrics.context.connect.group.id, status.storage.topic, plugin.path, config.storage.replication.factor, key.converter.schemas.enable, metrics.context.connect.kafka.cluster.id, status.storage.replication.factor, value.converter.schemas.enable, offset.storage.replication.factor, offset.storage.topic, value.converter, key.converter]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-04-13 13:08:33,135] INFO Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-04-13 13:08:33,135] INFO Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-04-13 13:08:33,135] INFO Kafka startTimeMs: 1744549713135 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-04-13 13:08:33,134] INFO [Producer clientId=connect-cluster-configs] Cluster ID: PRZJITuEQBeLmWOW7dnIsg (org.apache.kafka.clients.Metadata:364)
[2025-04-13 13:08:33,147] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Cluster ID: PRZJITuEQBeLmWOW7dnIsg (org.apache.kafka.clients.Metadata:364)
[2025-04-13 13:08:33,149] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Assigned to partition(s): connect-configs-0 (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:574)
[2025-04-13 13:08:33,149] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Seeking to earliest offset of partition connect-configs-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:704)
[2025-04-13 13:08:33,162] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Resetting offset for partition connect-configs-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-04-13 13:08:33,163] INFO Finished reading KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:310)
[2025-04-13 13:08:33,163] INFO Started KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:312)
[2025-04-13 13:08:33,163] INFO Started KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:400)
[2025-04-13 13:08:33,163] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Herder started (org.apache.kafka.connect.runtime.distributed.DistributedHerder:377)
[2025-04-13 13:08:33,174] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Cluster ID: PRZJITuEQBeLmWOW7dnIsg (org.apache.kafka.clients.Metadata:364)
[2025-04-13 13:08:35,041] INFO 127.0.0.1 - - [13/Apr/2025:13:08:34 +0000] "GET / HTTP/1.1" 200 91 "-" "curl/7.81.0" 88 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-04-13 13:08:43,472] INFO 127.0.0.1 - - [13/Apr/2025:13:08:43 +0000] "GET / HTTP/1.1" 200 91 "-" "curl/7.81.0" 4 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-04-13 13:08:49,901] INFO 127.0.0.1 - - [13/Apr/2025:13:08:49 +0000] "GET /connector-plugins HTTP/1.1" 200 593 "-" "curl/7.81.0" 31 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-04-13 13:09:05,595] INFO 87.208.3.218 - - [13/Apr/2025:13:09:05 +0000] "GET /connector-plugins HTTP/1.1" 200 593 "-" "PostmanRuntime/7.43.3" 3 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-04-13 13:13:31,769] INFO [AdminClient clientId=connect-cluster-shared-admin] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-04-13 13:15:02,408] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Discovered group coordinator localhost:9092 (id: 2147483646 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:936)
[2025-04-13 13:15:02,412] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-04-13 13:15:02,412] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-04-13 13:15:02,421] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Group coordinator localhost:9092 (id: 2147483646 rack: null) is unavailable or invalid due to cause: error response NOT_COORDINATOR. isDisconnected: false. Rediscovery will be attempted. (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:999)
[2025-04-13 13:15:02,421] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Requesting disconnect from last known coordinator localhost:9092 (id: 2147483646 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1012)
[2025-04-13 13:15:02,421] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] JoinGroup failed: This is not the correct coordinator. Marking coordinator unknown. Sent generation was Generation{generationId=-1, memberId='', protocol='null'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:694)
[2025-04-13 13:15:02,421] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Request joining group due to: rebalance failed due to 'This is not the correct coordinator.' (NotCoordinatorException) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1102)
[2025-04-13 13:15:02,522] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Client requested disconnect from node 2147483646 (org.apache.kafka.clients.NetworkClient:343)
[2025-04-13 13:15:02,524] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Discovered group coordinator localhost:9092 (id: 2147483646 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:936)
[2025-04-13 13:15:02,524] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Group coordinator localhost:9092 (id: 2147483646 rack: null) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: false. Rediscovery will be attempted. (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:999)
[2025-04-13 13:15:02,524] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Requesting disconnect from last known coordinator localhost:9092 (id: 2147483646 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1012)
[2025-04-13 13:15:02,630] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Discovered group coordinator localhost:9092 (id: 2147483646 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:936)
[2025-04-13 13:15:02,632] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-04-13 13:15:02,636] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Group coordinator localhost:9092 (id: 2147483646 rack: null) is unavailable or invalid due to cause: error response NOT_COORDINATOR. isDisconnected: false. Rediscovery will be attempted. (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:999)
[2025-04-13 13:15:02,636] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Requesting disconnect from last known coordinator localhost:9092 (id: 2147483646 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1012)
[2025-04-13 13:15:02,636] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] JoinGroup failed: This is not the correct coordinator. Marking coordinator unknown. Sent generation was Generation{generationId=-1, memberId='', protocol='null'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:694)
[2025-04-13 13:15:02,636] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Request joining group due to: rebalance failed due to 'This is not the correct coordinator.' (NotCoordinatorException) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1102)
[2025-04-13 13:15:02,736] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Client requested disconnect from node 2147483646 (org.apache.kafka.clients.NetworkClient:343)
[2025-04-13 13:15:02,739] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Discovered group coordinator localhost:9092 (id: 2147483646 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:936)
[2025-04-13 13:15:02,739] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Group coordinator localhost:9092 (id: 2147483646 rack: null) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: false. Rediscovery will be attempted. (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:999)
[2025-04-13 13:15:02,739] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Requesting disconnect from last known coordinator localhost:9092 (id: 2147483646 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1012)
[2025-04-13 13:15:02,843] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Discovered group coordinator localhost:9092 (id: 2147483646 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:936)
[2025-04-13 13:15:02,843] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-04-13 13:15:02,851] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-04-13 13:15:05,854] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=1, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-04-13 13:15:05,870] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=1, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-04-13 13:15:05,870] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Joined group at generation 1 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', leaderUrl='http://10.0.0.4:8083/', offset=-1, connectorIds=[], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2621)
[2025-04-13 13:15:05,871] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Starting connectors and tasks using config offset -1 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1959)
[2025-04-13 13:15:05,871] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1988)
[2025-04-13 13:15:05,928] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Session key updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2483)
[2025-04-13 13:16:08,948] INFO 87.208.3.218 - - [13/Apr/2025:13:16:08 +0000] "GET /connector-plugins HTTP/1.1" 200 593 "-" "PostmanRuntime/7.43.3" 3 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-04-13 13:17:23,652] INFO 48.217.82.15 - - [13/Apr/2025:13:17:23 +0000] "- - -" 400 49 "-" "-" 1 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-04-13 13:17:32,298] INFO [Producer clientId=connect-cluster-offsets] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-04-13 13:17:32,311] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-04-13 13:17:33,113] INFO [Producer clientId=connect-cluster-statuses] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-04-13 13:17:33,186] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-04-13 13:17:33,310] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-04-13 13:17:33,312] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-04-13 13:17:36,017] INFO [Producer clientId=connect-cluster-configs] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-04-13 13:18:16,683] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:372)
[2025-04-13 13:18:16,714] INFO 87.208.3.218 - - [13/Apr/2025:13:18:16 +0000] "POST /connectors HTTP/1.1" 400 273 "-" "PostmanRuntime/7.43.3" 138 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-04-13 13:19:17,198] INFO Loading the custom source info struct maker plugin: io.debezium.connector.sqlserver.SqlServerSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1318)
[2025-04-13 13:19:17,802] INFO Checking if user has access to CDC table (io.debezium.connector.sqlserver.SqlServerConnector:128)
[2025-04-13 13:19:17,939] INFO Connection gracefully closed (io.debezium.jdbc.JdbcConnection:949)
[2025-04-13 13:19:17,940] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:372)
[2025-04-13 13:19:17,948] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Connector azure-sql-server-source config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2425)
[2025-04-13 13:19:17,949] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-04-13 13:19:17,949] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-04-13 13:19:17,957] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=2, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-04-13 13:19:17,969] INFO 87.208.3.218 - - [13/Apr/2025:13:19:17 +0000] "POST /connectors HTTP/1.1" 201 703 "-" "PostmanRuntime/7.43.3" 791 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-04-13 13:19:17,971] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=2, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-04-13 13:19:17,972] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Joined group at generation 2 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', leaderUrl='http://10.0.0.4:8083/', offset=2, connectorIds=[azure-sql-server-source], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2621)
[2025-04-13 13:19:17,972] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 2 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1959)
[2025-04-13 13:19:17,974] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Starting connector azure-sql-server-source (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2077)
[2025-04-13 13:19:17,977] INFO [azure-sql-server-source|worker] Creating connector azure-sql-server-source of type io.debezium.connector.sqlserver.SqlServerConnector (org.apache.kafka.connect.runtime.Worker:312)
[2025-04-13 13:19:17,977] INFO [azure-sql-server-source|worker] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.sqlserver.SqlServerConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = azure-sql-server-source
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [unwrap]
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2025-04-13 13:19:17,978] INFO [azure-sql-server-source|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.sqlserver.SqlServerConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = azure-sql-server-source
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.fields.from.key = false
	transforms.unwrap.drop.fields.header.name = null
	transforms.unwrap.drop.fields.keep.schema.compatible = true
	transforms.unwrap.drop.tombstones = true
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.transforms.ExtractNewRecordState
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-04-13 13:19:17,983] INFO [azure-sql-server-source|worker] Instantiated connector azure-sql-server-source with version 2.5.1.Final of type class io.debezium.connector.sqlserver.SqlServerConnector (org.apache.kafka.connect.runtime.Worker:334)
[2025-04-13 13:19:17,983] INFO [azure-sql-server-source|worker] Finished creating connector azure-sql-server-source (org.apache.kafka.connect.runtime.Worker:355)
[2025-04-13 13:19:17,984] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1988)
[2025-04-13 13:19:17,990] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.sqlserver.SqlServerConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = azure-sql-server-source
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [unwrap]
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2025-04-13 13:19:17,991] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.sqlserver.SqlServerConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = azure-sql-server-source
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.fields.from.key = false
	transforms.unwrap.drop.fields.header.name = null
	transforms.unwrap.drop.fields.keep.schema.compatible = true
	transforms.unwrap.drop.tombstones = true
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.transforms.ExtractNewRecordState
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-04-13 13:19:17,996] INFO [azure-sql-server-source|worker] Loading the custom source info struct maker plugin: io.debezium.connector.sqlserver.SqlServerSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1318)
[2025-04-13 13:19:18,113] INFO [azure-sql-server-source|worker] Connection gracefully closed (io.debezium.jdbc.JdbcConnection:949)
[2025-04-13 13:19:18,125] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Tasks [azure-sql-server-source-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2440)
[2025-04-13 13:19:18,127] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-04-13 13:19:18,127] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-04-13 13:19:18,131] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=3, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-04-13 13:19:18,135] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=3, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-04-13 13:19:18,135] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Joined group at generation 3 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', leaderUrl='http://10.0.0.4:8083/', offset=4, connectorIds=[azure-sql-server-source], taskIds=[azure-sql-server-source-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2621)
[2025-04-13 13:19:18,136] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 4 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1959)
[2025-04-13 13:19:18,137] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Starting task azure-sql-server-source-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2002)
[2025-04-13 13:19:18,140] INFO [azure-sql-server-source|task-0] Creating task azure-sql-server-source-0 (org.apache.kafka.connect.runtime.Worker:645)
[2025-04-13 13:19:18,141] INFO [azure-sql-server-source|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.sqlserver.SqlServerConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = azure-sql-server-source
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap]
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2025-04-13 13:19:18,142] INFO [azure-sql-server-source|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.sqlserver.SqlServerConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = azure-sql-server-source
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.fields.from.key = false
	transforms.unwrap.drop.fields.header.name = null
	transforms.unwrap.drop.fields.keep.schema.compatible = true
	transforms.unwrap.drop.tombstones = true
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.transforms.ExtractNewRecordState
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-04-13 13:19:18,143] INFO [azure-sql-server-source|task-0] TaskConfig values: 
	task.class = class io.debezium.connector.sqlserver.SqlServerConnectorTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2025-04-13 13:19:18,146] INFO [azure-sql-server-source|task-0] Instantiated task azure-sql-server-source-0 with version 2.5.1.Final of type io.debezium.connector.sqlserver.SqlServerConnectorTask (org.apache.kafka.connect.runtime.Worker:664)
[2025-04-13 13:19:18,147] INFO [azure-sql-server-source|task-0] JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-04-13 13:19:18,147] INFO [azure-sql-server-source|task-0] Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task azure-sql-server-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:677)
[2025-04-13 13:19:18,147] INFO [azure-sql-server-source|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-04-13 13:19:18,147] INFO [azure-sql-server-source|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task azure-sql-server-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:683)
[2025-04-13 13:19:18,147] INFO [azure-sql-server-source|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task azure-sql-server-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:690)
[2025-04-13 13:19:18,153] WARN [azure-sql-server-source|task-0] The deleted record handling configs "drop.tombstones" and "delete.handling.mode" have been deprecated, please use "delete.tombstone.handling.mode" instead. (io.debezium.transforms.AbstractExtractNewRecordState:101)
[2025-04-13 13:19:18,154] INFO [azure-sql-server-source|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{io.debezium.transforms.ExtractNewRecordState} (org.apache.kafka.connect.runtime.Worker:1794)
[2025-04-13 13:19:18,154] INFO [azure-sql-server-source|task-0] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.sqlserver.SqlServerConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = azure-sql-server-source
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [unwrap]
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2025-04-13 13:19:18,155] INFO [azure-sql-server-source|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.sqlserver.SqlServerConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = azure-sql-server-source
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.fields.from.key = false
	transforms.unwrap.drop.fields.header.name = null
	transforms.unwrap.drop.fields.keep.schema.compatible = true
	transforms.unwrap.drop.tombstones = true
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.transforms.ExtractNewRecordState
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-04-13 13:19:18,155] INFO [azure-sql-server-source|task-0] ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connector-producer-azure-sql-server-source-0
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2025-04-13 13:19:18,156] INFO [azure-sql-server-source|task-0] initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-04-13 13:19:18,159] INFO [azure-sql-server-source|task-0] These configurations '[metrics.context.connect.kafka.cluster.id, metrics.context.connect.group.id]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:381)
[2025-04-13 13:19:18,159] INFO [azure-sql-server-source|task-0] Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-04-13 13:19:18,159] INFO [azure-sql-server-source|task-0] Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-04-13 13:19:18,159] INFO [azure-sql-server-source|task-0] Kafka startTimeMs: 1744550358159 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-04-13 13:19:18,167] INFO [azure-sql-server-source|task-0] [Producer clientId=connector-producer-azure-sql-server-source-0] Cluster ID: PRZJITuEQBeLmWOW7dnIsg (org.apache.kafka.clients.Metadata:364)
[2025-04-13 13:19:18,173] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1988)
[2025-04-13 13:19:18,174] INFO [azure-sql-server-source|task-0] Starting SqlServerConnectorTask with configuration: (io.debezium.connector.common.BaseSourceTask:135)
[2025-04-13 13:19:18,176] INFO [azure-sql-server-source|task-0]    connector.class = io.debezium.connector.sqlserver.SqlServerConnector (io.debezium.connector.common.BaseSourceTask:137)
[2025-04-13 13:19:18,176] INFO [azure-sql-server-source|task-0]    incrementing.column.name = ProductID (io.debezium.connector.common.BaseSourceTask:137)
[2025-04-13 13:19:18,176] INFO [azure-sql-server-source|task-0]    database.user = kafkadmin@kafkadatabase (io.debezium.connector.common.BaseSourceTask:137)
[2025-04-13 13:19:18,176] INFO [azure-sql-server-source|task-0]    database.names = database01 (io.debezium.connector.common.BaseSourceTask:137)
[2025-04-13 13:19:18,176] INFO [azure-sql-server-source|task-0]    tasks.max = 1 (io.debezium.connector.common.BaseSourceTask:137)
[2025-04-13 13:19:18,176] INFO [azure-sql-server-source|task-0]    transforms = unwrap (io.debezium.connector.common.BaseSourceTask:137)
[2025-04-13 13:19:18,176] INFO [azure-sql-server-source|task-0]    database.server.name = server1 (io.debezium.connector.common.BaseSourceTask:137)
[2025-04-13 13:19:18,176] INFO [azure-sql-server-source|task-0]    database.port = 1433 (io.debezium.connector.common.BaseSourceTask:137)
[2025-04-13 13:19:18,176] INFO [azure-sql-server-source|task-0]    mode = incrementing (io.debezium.connector.common.BaseSourceTask:137)
[2025-04-13 13:19:18,176] INFO [azure-sql-server-source|task-0]    topic.prefix = azure-sql- (io.debezium.connector.common.BaseSourceTask:137)
[2025-04-13 13:19:18,176] INFO [azure-sql-server-source|task-0]    task.class = io.debezium.connector.sqlserver.SqlServerConnectorTask (io.debezium.connector.common.BaseSourceTask:137)
[2025-04-13 13:19:18,176] INFO [azure-sql-server-source|task-0]    database.hostname = kafkadatabase.database.windows.net (io.debezium.connector.common.BaseSourceTask:137)
[2025-04-13 13:19:18,176] INFO [azure-sql-server-source|task-0]    database.password = ******** (io.debezium.connector.common.BaseSourceTask:137)
[2025-04-13 13:19:18,176] INFO [azure-sql-server-source|task-0]    poll.interval.ms = 10000 (io.debezium.connector.common.BaseSourceTask:137)
[2025-04-13 13:19:18,176] INFO [azure-sql-server-source|task-0]    transforms.unwrap.drop.tombstones = true (io.debezium.connector.common.BaseSourceTask:137)
[2025-04-13 13:19:18,176] INFO [azure-sql-server-source|task-0]    name = azure-sql-server-source (io.debezium.connector.common.BaseSourceTask:137)
[2025-04-13 13:19:18,176] INFO [azure-sql-server-source|task-0]    transforms.unwrap.type = io.debezium.transforms.ExtractNewRecordState (io.debezium.connector.common.BaseSourceTask:137)
[2025-04-13 13:19:18,176] INFO [azure-sql-server-source|task-0]    task.id = 0 (io.debezium.connector.common.BaseSourceTask:137)
[2025-04-13 13:19:18,177] INFO [azure-sql-server-source|task-0]    table.include.list = SalesLT.Product (io.debezium.connector.common.BaseSourceTask:137)
[2025-04-13 13:19:18,177] INFO [azure-sql-server-source|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.sqlserver.SqlServerSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1318)
[2025-04-13 13:19:18,180] INFO [azure-sql-server-source|task-0] Loading the custom topic naming strategy plugin: io.debezium.schema.SchemaTopicNamingStrategy (io.debezium.config.CommonConnectorConfig:1066)
[2025-04-13 13:19:18,204] ERROR [azure-sql-server-source|task-0] The 'schema.history.internal.kafka.topic' value is invalid: A value is required (io.debezium.storage.kafka.history.KafkaSchemaHistory:1947)
[2025-04-13 13:19:18,204] ERROR [azure-sql-server-source|task-0] The 'schema.history.internal.kafka.bootstrap.servers' value is invalid: A value is required (io.debezium.storage.kafka.history.KafkaSchemaHistory:1947)
[2025-04-13 13:19:18,205] ERROR [azure-sql-server-source|task-0] WorkerSourceTask{id=azure-sql-server-source-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:233)
org.apache.kafka.connect.errors.ConnectException: Error configuring an instance of KafkaSchemaHistory; check the logs for details
	at io.debezium.storage.kafka.history.KafkaSchemaHistory.configure(KafkaSchemaHistory.java:208)
	at io.debezium.relational.HistorizedRelationalDatabaseConnectorConfig.getSchemaHistory(HistorizedRelationalDatabaseConnectorConfig.java:137)
	at io.debezium.relational.HistorizedRelationalDatabaseSchema.<init>(HistorizedRelationalDatabaseSchema.java:49)
	at io.debezium.connector.sqlserver.SqlServerDatabaseSchema.<init>(SqlServerDatabaseSchema.java:35)
	at io.debezium.connector.sqlserver.SqlServerConnectorTask.start(SqlServerConnectorTask.java:86)
	at io.debezium.connector.common.BaseSourceTask.start(BaseSourceTask.java:141)
	at org.apache.kafka.connect.runtime.AbstractWorkerSourceTask.initializeAndStart(AbstractWorkerSourceTask.java:278)
	at org.apache.kafka.connect.runtime.WorkerTask.doStart(WorkerTask.java:175)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:224)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.AbstractWorkerSourceTask.run(AbstractWorkerSourceTask.java:78)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:19:18,207] INFO [azure-sql-server-source|task-0] Stopping down connector (io.debezium.connector.common.BaseSourceTask:282)
[2025-04-13 13:19:18,207] INFO [azure-sql-server-source|task-0] [Producer clientId=connector-producer-azure-sql-server-source-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1373)
[2025-04-13 13:19:18,211] INFO [azure-sql-server-source|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-04-13 13:19:18,211] INFO [azure-sql-server-source|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-04-13 13:19:18,212] INFO [azure-sql-server-source|task-0] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-04-13 13:19:18,212] INFO [azure-sql-server-source|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-04-13 13:19:18,212] INFO [azure-sql-server-source|task-0] App info kafka.producer for connector-producer-azure-sql-server-source-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-04-13 13:19:37,280] INFO 87.208.3.218 - - [13/Apr/2025:13:19:37 +0000] "GET /connectors/azure-sql-source/status HTTP/1.1" 404 77 "-" "PostmanRuntime/7.43.3" 5 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-04-13 13:20:15,326] INFO 87.208.3.218 - - [13/Apr/2025:13:20:15 +0000] "GET /connectors HTTP/1.1" 200 27 "-" "PostmanRuntime/7.43.3" 5 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-04-13 13:20:45,515] INFO 127.0.0.1 - - [13/Apr/2025:13:20:45 +0000] "GET /connectors HTTP/1.1" 200 27 "-" "curl/7.81.0" 5 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-04-13 13:21:48,690] INFO 127.0.0.1 - - [13/Apr/2025:13:21:48 +0000] "GET /connectors/azure-sql-server-source/status HTTP/1.1" 200 1914 "-" "curl/7.81.0" 11 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-04-13 13:23:23,338] ERROR Uncaught exception in REST call to /connectors/azure-sql-source/config (org.apache.kafka.connect.runtime.rest.errors.ConnectExceptionMapper:64)
com.fasterxml.jackson.databind.exc.MismatchedInputException: Cannot deserialize value of type `java.lang.String` from Object value (token `JsonToken.START_OBJECT`)
 at [Source: REDACTED (`StreamReadFeature.INCLUDE_SOURCE_IN_LOCATION` disabled); line: 3, column: 13] (through reference chain: java.util.LinkedHashMap["config"])
	at com.fasterxml.jackson.databind.exc.MismatchedInputException.from(MismatchedInputException.java:59)
	at com.fasterxml.jackson.databind.DeserializationContext.reportInputMismatch(DeserializationContext.java:1767)
	at com.fasterxml.jackson.databind.DeserializationContext.handleUnexpectedToken(DeserializationContext.java:1541)
	at com.fasterxml.jackson.databind.DeserializationContext.handleUnexpectedToken(DeserializationContext.java:1446)
	at com.fasterxml.jackson.databind.DeserializationContext.extractScalarFromObject(DeserializationContext.java:958)
	at com.fasterxml.jackson.databind.deser.std.StdDeserializer._parseString(StdDeserializer.java:1424)
	at com.fasterxml.jackson.databind.deser.std.StringDeserializer.deserialize(StringDeserializer.java:48)
	at com.fasterxml.jackson.databind.deser.std.StringDeserializer.deserialize(StringDeserializer.java:11)
	at com.fasterxml.jackson.databind.deser.std.MapDeserializer._readAndBindStringKeyMap(MapDeserializer.java:623)
	at com.fasterxml.jackson.databind.deser.std.MapDeserializer.deserialize(MapDeserializer.java:449)
	at com.fasterxml.jackson.databind.deser.std.MapDeserializer.deserialize(MapDeserializer.java:32)
	at com.fasterxml.jackson.databind.deser.DefaultDeserializationContext.readRootValue(DefaultDeserializationContext.java:342)
	at com.fasterxml.jackson.databind.ObjectReader._bind(ObjectReader.java:2099)
	at com.fasterxml.jackson.databind.ObjectReader.readValue(ObjectReader.java:1249)
	at com.fasterxml.jackson.jaxrs.base.ProviderBase.readFrom(ProviderBase.java:801)
	at org.glassfish.jersey.message.internal.ReaderInterceptorExecutor$TerminalReaderInterceptor.invokeReadFrom(ReaderInterceptorExecutor.java:233)
	at org.glassfish.jersey.message.internal.ReaderInterceptorExecutor$TerminalReaderInterceptor.aroundReadFrom(ReaderInterceptorExecutor.java:212)
	at org.glassfish.jersey.message.internal.ReaderInterceptorExecutor.proceed(ReaderInterceptorExecutor.java:132)
	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundReadFrom(MappableExceptionWrapperInterceptor.java:49)
	at org.glassfish.jersey.message.internal.ReaderInterceptorExecutor.proceed(ReaderInterceptorExecutor.java:132)
	at org.glassfish.jersey.message.internal.MessageBodyFactory.readFrom(MessageBodyFactory.java:1072)
	at org.glassfish.jersey.message.internal.InboundMessageContext.readEntity(InboundMessageContext.java:919)
	at org.glassfish.jersey.server.ContainerRequest.readEntity(ContainerRequest.java:290)
	at org.glassfish.jersey.server.internal.inject.EntityParamValueParamProvider$EntityValueSupplier.apply(EntityParamValueParamProvider.java:73)
	at org.glassfish.jersey.server.internal.inject.EntityParamValueParamProvider$EntityValueSupplier.apply(EntityParamValueParamProvider.java:56)
	at org.glassfish.jersey.server.spi.internal.ParamValueFactoryWithSource.apply(ParamValueFactoryWithSource.java:50)
	at org.glassfish.jersey.server.spi.internal.ParameterValueHelper.getParameterValues(ParameterValueHelper.java:68)
	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$AbstractMethodParamInvoker.getParamValues(JavaResourceMethodDispatcherProvider.java:109)
	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:81)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:478)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:400)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:256)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:235)
	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:684)
	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:358)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:311)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1440)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)
	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1355)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:191)
	at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:181)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.Server.handle(Server.java:516)
	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:23:23,339] INFO 87.208.3.218 - - [13/Apr/2025:13:23:23 +0000] "PATCH /connectors/azure-sql-source/config HTTP/1.1" 500 299 "-" "PostmanRuntime/7.43.3" 6 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-04-13 13:23:31,453] ERROR Uncaught exception in REST call to /connectors/azure-sql-source/config (org.apache.kafka.connect.runtime.rest.errors.ConnectExceptionMapper:64)
com.fasterxml.jackson.databind.exc.MismatchedInputException: Cannot deserialize value of type `java.lang.String` from Object value (token `JsonToken.START_OBJECT`)
 at [Source: REDACTED (`StreamReadFeature.INCLUDE_SOURCE_IN_LOCATION` disabled); line: 3, column: 13] (through reference chain: java.util.LinkedHashMap["config"])
	at com.fasterxml.jackson.databind.exc.MismatchedInputException.from(MismatchedInputException.java:59)
	at com.fasterxml.jackson.databind.DeserializationContext.reportInputMismatch(DeserializationContext.java:1767)
	at com.fasterxml.jackson.databind.DeserializationContext.handleUnexpectedToken(DeserializationContext.java:1541)
	at com.fasterxml.jackson.databind.DeserializationContext.handleUnexpectedToken(DeserializationContext.java:1446)
	at com.fasterxml.jackson.databind.DeserializationContext.extractScalarFromObject(DeserializationContext.java:958)
	at com.fasterxml.jackson.databind.deser.std.StdDeserializer._parseString(StdDeserializer.java:1424)
	at com.fasterxml.jackson.databind.deser.std.StringDeserializer.deserialize(StringDeserializer.java:48)
	at com.fasterxml.jackson.databind.deser.std.StringDeserializer.deserialize(StringDeserializer.java:11)
	at com.fasterxml.jackson.databind.deser.std.MapDeserializer._readAndBindStringKeyMap(MapDeserializer.java:623)
	at com.fasterxml.jackson.databind.deser.std.MapDeserializer.deserialize(MapDeserializer.java:449)
	at com.fasterxml.jackson.databind.deser.std.MapDeserializer.deserialize(MapDeserializer.java:32)
	at com.fasterxml.jackson.databind.deser.DefaultDeserializationContext.readRootValue(DefaultDeserializationContext.java:342)
	at com.fasterxml.jackson.databind.ObjectReader._bind(ObjectReader.java:2099)
	at com.fasterxml.jackson.databind.ObjectReader.readValue(ObjectReader.java:1249)
	at com.fasterxml.jackson.jaxrs.base.ProviderBase.readFrom(ProviderBase.java:801)
	at org.glassfish.jersey.message.internal.ReaderInterceptorExecutor$TerminalReaderInterceptor.invokeReadFrom(ReaderInterceptorExecutor.java:233)
	at org.glassfish.jersey.message.internal.ReaderInterceptorExecutor$TerminalReaderInterceptor.aroundReadFrom(ReaderInterceptorExecutor.java:212)
	at org.glassfish.jersey.message.internal.ReaderInterceptorExecutor.proceed(ReaderInterceptorExecutor.java:132)
	at org.glassfish.jersey.server.internal.MappableExceptionWrapperInterceptor.aroundReadFrom(MappableExceptionWrapperInterceptor.java:49)
	at org.glassfish.jersey.message.internal.ReaderInterceptorExecutor.proceed(ReaderInterceptorExecutor.java:132)
	at org.glassfish.jersey.message.internal.MessageBodyFactory.readFrom(MessageBodyFactory.java:1072)
	at org.glassfish.jersey.message.internal.InboundMessageContext.readEntity(InboundMessageContext.java:919)
	at org.glassfish.jersey.server.ContainerRequest.readEntity(ContainerRequest.java:290)
	at org.glassfish.jersey.server.internal.inject.EntityParamValueParamProvider$EntityValueSupplier.apply(EntityParamValueParamProvider.java:73)
	at org.glassfish.jersey.server.internal.inject.EntityParamValueParamProvider$EntityValueSupplier.apply(EntityParamValueParamProvider.java:56)
	at org.glassfish.jersey.server.spi.internal.ParamValueFactoryWithSource.apply(ParamValueFactoryWithSource.java:50)
	at org.glassfish.jersey.server.spi.internal.ParameterValueHelper.getParameterValues(ParameterValueHelper.java:68)
	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$AbstractMethodParamInvoker.getParamValues(JavaResourceMethodDispatcherProvider.java:109)
	at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:176)
	at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:81)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:478)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:400)
	at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:81)
	at org.glassfish.jersey.server.ServerRuntime$1.run(ServerRuntime.java:256)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:248)
	at org.glassfish.jersey.internal.Errors$1.call(Errors.java:244)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:292)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:274)
	at org.glassfish.jersey.internal.Errors.process(Errors.java:244)
	at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:265)
	at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:235)
	at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:684)
	at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:394)
	at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:346)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:358)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:311)
	at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:205)
	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1624)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1440)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)
	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1594)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1355)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:191)
	at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:181)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)
	at org.eclipse.jetty.server.Server.handle(Server.java:516)
	at org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)
	at org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
	at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)
	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:23:31,455] INFO 87.208.3.218 - - [13/Apr/2025:13:23:31 +0000] "PUT /connectors/azure-sql-source/config HTTP/1.1" 500 299 "-" "PostmanRuntime/7.43.3" 5 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-04-13 13:23:38,078] INFO 87.208.3.218 - - [13/Apr/2025:13:23:38 +0000] "DELETE /connectors/azure-sql-source HTTP/1.1" 404 67 "-" "PostmanRuntime/7.43.3" 9 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-04-13 13:23:47,197] INFO 87.208.3.218 - - [13/Apr/2025:13:23:47 +0000] "GET /connectors HTTP/1.1" 200 27 "-" "PostmanRuntime/7.43.3" 3 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-04-13 13:24:00,897] INFO Successfully processed removal of connector 'azure-sql-server-source' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1003)
[2025-04-13 13:24:00,897] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Connector azure-sql-server-source config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2412)
[2025-04-13 13:24:00,897] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Handling connector-only config update by stopping connector azure-sql-server-source (org.apache.kafka.connect.runtime.distributed.DistributedHerder:716)
[2025-04-13 13:24:00,897] INFO [azure-sql-server-source|worker] Stopping connector azure-sql-server-source (org.apache.kafka.connect.runtime.Worker:451)
[2025-04-13 13:24:00,897] INFO [azure-sql-server-source|worker] Scheduled shutdown for WorkerConnector{id=azure-sql-server-source} (org.apache.kafka.connect.runtime.WorkerConnector:294)
[2025-04-13 13:24:00,898] INFO [azure-sql-server-source|worker] Completed shutdown for WorkerConnector{id=azure-sql-server-source} (org.apache.kafka.connect.runtime.WorkerConnector:314)
[2025-04-13 13:24:00,899] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-04-13 13:24:00,900] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-04-13 13:24:00,900] INFO 87.208.3.218 - - [13/Apr/2025:13:24:00 +0000] "DELETE /connectors/azure-sql-server-source/ HTTP/1.1" 204 0 "-" "PostmanRuntime/7.43.3" 15 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-04-13 13:24:00,902] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=4, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-04-13 13:24:00,905] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=4, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-04-13 13:24:00,907] INFO [azure-sql-server-source|worker] Stopping connector azure-sql-server-source (org.apache.kafka.connect.runtime.Worker:451)
[2025-04-13 13:24:00,907] WARN [azure-sql-server-source|worker] Ignoring stop request for unowned connector azure-sql-server-source (org.apache.kafka.connect.runtime.Worker:454)
[2025-04-13 13:24:00,907] WARN [azure-sql-server-source|worker] Ignoring await stop request for non-present connector azure-sql-server-source (org.apache.kafka.connect.runtime.Worker:475)
[2025-04-13 13:24:00,907] INFO [azure-sql-server-source|task-0] Stopping task azure-sql-server-source-0 (org.apache.kafka.connect.runtime.Worker:1047)
[2025-04-13 13:24:00,909] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2708)
[2025-04-13 13:24:00,911] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2729)
[2025-04-13 13:24:00,911] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Joined group at generation 4 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', leaderUrl='http://10.0.0.4:8083/', offset=6, connectorIds=[], taskIds=[], revokedConnectorIds=[azure-sql-server-source], revokedTaskIds=[azure-sql-server-source-0], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2621)
[2025-04-13 13:24:00,912] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 6 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1959)
[2025-04-13 13:24:00,912] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1988)
[2025-04-13 13:24:00,912] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-04-13 13:24:00,912] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-04-13 13:24:00,913] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=5, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-04-13 13:24:00,917] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=5, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-04-13 13:24:00,917] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Joined group at generation 5 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', leaderUrl='http://10.0.0.4:8083/', offset=6, connectorIds=[], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2621)
[2025-04-13 13:24:00,917] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 6 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1959)
[2025-04-13 13:24:00,917] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1988)
[2025-04-13 13:24:08,826] INFO Loading the custom source info struct maker plugin: io.debezium.connector.sqlserver.SqlServerSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1318)
[2025-04-13 13:24:08,913] INFO Checking if user has access to CDC table (io.debezium.connector.sqlserver.SqlServerConnector:128)
[2025-04-13 13:24:08,947] INFO Connection gracefully closed (io.debezium.jdbc.JdbcConnection:949)
[2025-04-13 13:24:08,948] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:372)
[2025-04-13 13:24:08,954] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Connector azure-sql-server-source config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2425)
[2025-04-13 13:24:08,954] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-04-13 13:24:08,954] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-04-13 13:24:08,956] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=6, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-04-13 13:24:08,958] INFO 87.208.3.218 - - [13/Apr/2025:13:24:08 +0000] "POST /connectors HTTP/1.1" 201 867 "-" "PostmanRuntime/7.43.3" 141 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-04-13 13:24:08,958] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=6, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-04-13 13:24:08,958] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Joined group at generation 6 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', leaderUrl='http://10.0.0.4:8083/', offset=7, connectorIds=[azure-sql-server-source], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2621)
[2025-04-13 13:24:08,958] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 7 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1959)
[2025-04-13 13:24:08,962] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Starting connector azure-sql-server-source (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2077)
[2025-04-13 13:24:08,963] INFO [azure-sql-server-source|worker] Creating connector azure-sql-server-source of type io.debezium.connector.sqlserver.SqlServerConnector (org.apache.kafka.connect.runtime.Worker:312)
[2025-04-13 13:24:08,963] INFO [azure-sql-server-source|worker] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.sqlserver.SqlServerConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = azure-sql-server-source
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [unwrap]
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2025-04-13 13:24:08,963] INFO [azure-sql-server-source|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.sqlserver.SqlServerConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = azure-sql-server-source
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.fields.from.key = false
	transforms.unwrap.drop.fields.header.name = null
	transforms.unwrap.drop.fields.keep.schema.compatible = true
	transforms.unwrap.drop.tombstones = true
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.transforms.ExtractNewRecordState
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-04-13 13:24:08,964] INFO [azure-sql-server-source|worker] Instantiated connector azure-sql-server-source with version 2.5.1.Final of type class io.debezium.connector.sqlserver.SqlServerConnector (org.apache.kafka.connect.runtime.Worker:334)
[2025-04-13 13:24:08,965] INFO [azure-sql-server-source|worker] Finished creating connector azure-sql-server-source (org.apache.kafka.connect.runtime.Worker:355)
[2025-04-13 13:24:08,965] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1988)
[2025-04-13 13:24:08,967] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.sqlserver.SqlServerConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = azure-sql-server-source
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [unwrap]
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2025-04-13 13:24:08,967] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.sqlserver.SqlServerConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = azure-sql-server-source
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.fields.from.key = false
	transforms.unwrap.drop.fields.header.name = null
	transforms.unwrap.drop.fields.keep.schema.compatible = true
	transforms.unwrap.drop.tombstones = true
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.transforms.ExtractNewRecordState
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-04-13 13:24:08,967] INFO [azure-sql-server-source|worker] Loading the custom source info struct maker plugin: io.debezium.connector.sqlserver.SqlServerSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1318)
[2025-04-13 13:24:09,033] INFO [azure-sql-server-source|worker] Connection gracefully closed (io.debezium.jdbc.JdbcConnection:949)
[2025-04-13 13:24:09,044] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Tasks [azure-sql-server-source-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2440)
[2025-04-13 13:24:09,045] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-04-13 13:24:09,045] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-04-13 13:24:09,046] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=7, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-04-13 13:24:09,048] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=7, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-04-13 13:24:09,048] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Joined group at generation 7 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', leaderUrl='http://10.0.0.4:8083/', offset=9, connectorIds=[azure-sql-server-source], taskIds=[azure-sql-server-source-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2621)
[2025-04-13 13:24:09,048] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 9 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1959)
[2025-04-13 13:24:09,048] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Starting task azure-sql-server-source-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2002)
[2025-04-13 13:24:09,049] INFO [azure-sql-server-source|task-0] Creating task azure-sql-server-source-0 (org.apache.kafka.connect.runtime.Worker:645)
[2025-04-13 13:24:09,049] INFO [azure-sql-server-source|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.sqlserver.SqlServerConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = azure-sql-server-source
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap]
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2025-04-13 13:24:09,049] INFO [azure-sql-server-source|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.sqlserver.SqlServerConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = azure-sql-server-source
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.fields.from.key = false
	transforms.unwrap.drop.fields.header.name = null
	transforms.unwrap.drop.fields.keep.schema.compatible = true
	transforms.unwrap.drop.tombstones = true
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.transforms.ExtractNewRecordState
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-04-13 13:24:09,050] INFO [azure-sql-server-source|task-0] TaskConfig values: 
	task.class = class io.debezium.connector.sqlserver.SqlServerConnectorTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2025-04-13 13:24:09,050] INFO [azure-sql-server-source|task-0] Instantiated task azure-sql-server-source-0 with version 2.5.1.Final of type io.debezium.connector.sqlserver.SqlServerConnectorTask (org.apache.kafka.connect.runtime.Worker:664)
[2025-04-13 13:24:09,051] INFO [azure-sql-server-source|task-0] JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-04-13 13:24:09,051] INFO [azure-sql-server-source|task-0] Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task azure-sql-server-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:677)
[2025-04-13 13:24:09,051] INFO [azure-sql-server-source|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-04-13 13:24:09,051] INFO [azure-sql-server-source|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task azure-sql-server-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:683)
[2025-04-13 13:24:09,051] INFO [azure-sql-server-source|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task azure-sql-server-source-0 using the worker config (org.apache.kafka.connect.runtime.Worker:690)
[2025-04-13 13:24:09,052] WARN [azure-sql-server-source|task-0] The deleted record handling configs "drop.tombstones" and "delete.handling.mode" have been deprecated, please use "delete.tombstone.handling.mode" instead. (io.debezium.transforms.AbstractExtractNewRecordState:101)
[2025-04-13 13:24:09,052] INFO [azure-sql-server-source|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{io.debezium.transforms.ExtractNewRecordState} (org.apache.kafka.connect.runtime.Worker:1794)
[2025-04-13 13:24:09,052] INFO [azure-sql-server-source|task-0] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.sqlserver.SqlServerConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = azure-sql-server-source
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [unwrap]
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2025-04-13 13:24:09,052] INFO [azure-sql-server-source|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.sqlserver.SqlServerConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = azure-sql-server-source
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.delete.handling.mode = drop
	transforms.unwrap.drop.fields.from.key = false
	transforms.unwrap.drop.fields.header.name = null
	transforms.unwrap.drop.fields.keep.schema.compatible = true
	transforms.unwrap.drop.tombstones = true
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.transforms.ExtractNewRecordState
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-04-13 13:24:09,053] INFO [azure-sql-server-source|task-0] ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connector-producer-azure-sql-server-source-0
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2025-04-13 13:24:09,053] INFO [azure-sql-server-source|task-0] initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-04-13 13:24:09,057] INFO [azure-sql-server-source|task-0] These configurations '[metrics.context.connect.kafka.cluster.id, metrics.context.connect.group.id]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:381)
[2025-04-13 13:24:09,057] INFO [azure-sql-server-source|task-0] Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-04-13 13:24:09,057] INFO [azure-sql-server-source|task-0] Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-04-13 13:24:09,057] INFO [azure-sql-server-source|task-0] Kafka startTimeMs: 1744550649057 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-04-13 13:24:09,060] INFO [azure-sql-server-source|task-0] [Producer clientId=connector-producer-azure-sql-server-source-0] Cluster ID: PRZJITuEQBeLmWOW7dnIsg (org.apache.kafka.clients.Metadata:364)
[2025-04-13 13:24:09,061] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1988)
[2025-04-13 13:24:09,062] INFO [azure-sql-server-source|task-0] Starting SqlServerConnectorTask with configuration: (io.debezium.connector.common.BaseSourceTask:135)
[2025-04-13 13:24:09,062] INFO [azure-sql-server-source|task-0]    connector.class = io.debezium.connector.sqlserver.SqlServerConnector (io.debezium.connector.common.BaseSourceTask:137)
[2025-04-13 13:24:09,062] INFO [azure-sql-server-source|task-0]    incrementing.column.name = ProductID (io.debezium.connector.common.BaseSourceTask:137)
[2025-04-13 13:24:09,062] INFO [azure-sql-server-source|task-0]    database.user = kafkadmin@kafkadatabase (io.debezium.connector.common.BaseSourceTask:137)
[2025-04-13 13:24:09,062] INFO [azure-sql-server-source|task-0]    database.dbname = database01 (io.debezium.connector.common.BaseSourceTask:137)
[2025-04-13 13:24:09,062] INFO [azure-sql-server-source|task-0]    database.names = database01 (io.debezium.connector.common.BaseSourceTask:137)
[2025-04-13 13:24:09,062] INFO [azure-sql-server-source|task-0]    tasks.max = 1 (io.debezium.connector.common.BaseSourceTask:137)
[2025-04-13 13:24:09,062] INFO [azure-sql-server-source|task-0]    transforms = unwrap (io.debezium.connector.common.BaseSourceTask:137)
[2025-04-13 13:24:09,062] INFO [azure-sql-server-source|task-0]    database.server.name = server1 (io.debezium.connector.common.BaseSourceTask:137)
[2025-04-13 13:24:09,062] INFO [azure-sql-server-source|task-0]    schema.history.internal.kafka.bootstrap.servers = localhost:9092 (io.debezium.connector.common.BaseSourceTask:137)
[2025-04-13 13:24:09,062] INFO [azure-sql-server-source|task-0]    database.port = 1433 (io.debezium.connector.common.BaseSourceTask:137)
[2025-04-13 13:24:09,062] INFO [azure-sql-server-source|task-0]    mode = incrementing (io.debezium.connector.common.BaseSourceTask:137)
[2025-04-13 13:24:09,062] INFO [azure-sql-server-source|task-0]    topic.prefix = azure-sql- (io.debezium.connector.common.BaseSourceTask:137)
[2025-04-13 13:24:09,062] INFO [azure-sql-server-source|task-0]    schema.history.internal.kafka.topic = schema-changes.database01 (io.debezium.connector.common.BaseSourceTask:137)
[2025-04-13 13:24:09,062] INFO [azure-sql-server-source|task-0]    task.class = io.debezium.connector.sqlserver.SqlServerConnectorTask (io.debezium.connector.common.BaseSourceTask:137)
[2025-04-13 13:24:09,062] INFO [azure-sql-server-source|task-0]    database.hostname = kafkadatabase.database.windows.net (io.debezium.connector.common.BaseSourceTask:137)
[2025-04-13 13:24:09,063] INFO [azure-sql-server-source|task-0]    database.password = ******** (io.debezium.connector.common.BaseSourceTask:137)
[2025-04-13 13:24:09,063] INFO [azure-sql-server-source|task-0]    poll.interval.ms = 10000 (io.debezium.connector.common.BaseSourceTask:137)
[2025-04-13 13:24:09,063] INFO [azure-sql-server-source|task-0]    transforms.unwrap.drop.tombstones = true (io.debezium.connector.common.BaseSourceTask:137)
[2025-04-13 13:24:09,063] INFO [azure-sql-server-source|task-0]    name = azure-sql-server-source (io.debezium.connector.common.BaseSourceTask:137)
[2025-04-13 13:24:09,063] INFO [azure-sql-server-source|task-0]    transforms.unwrap.type = io.debezium.transforms.ExtractNewRecordState (io.debezium.connector.common.BaseSourceTask:137)
[2025-04-13 13:24:09,063] INFO [azure-sql-server-source|task-0]    task.id = 0 (io.debezium.connector.common.BaseSourceTask:137)
[2025-04-13 13:24:09,063] INFO [azure-sql-server-source|task-0]    table.include.list = SalesLT.Product (io.debezium.connector.common.BaseSourceTask:137)
[2025-04-13 13:24:09,064] INFO [azure-sql-server-source|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.sqlserver.SqlServerSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1318)
[2025-04-13 13:24:09,065] INFO [azure-sql-server-source|task-0] Loading the custom topic naming strategy plugin: io.debezium.schema.SchemaTopicNamingStrategy (io.debezium.config.CommonConnectorConfig:1066)
[2025-04-13 13:24:09,068] INFO [azure-sql-server-source|task-0] KafkaSchemaHistory Consumer config: {key.deserializer=org.apache.kafka.common.serialization.StringDeserializer, value.deserializer=org.apache.kafka.common.serialization.StringDeserializer, enable.auto.commit=false, group.id=azure-sql--schemahistory, bootstrap.servers=localhost:9092, fetch.min.bytes=1, session.timeout.ms=10000, auto.offset.reset=earliest, client.id=azure-sql--schemahistory} (io.debezium.storage.kafka.history.KafkaSchemaHistory:245)
[2025-04-13 13:24:09,068] INFO [azure-sql-server-source|task-0] KafkaSchemaHistory Producer config: {retries=1, value.serializer=org.apache.kafka.common.serialization.StringSerializer, acks=1, batch.size=32768, max.block.ms=10000, bootstrap.servers=localhost:9092, buffer.memory=1048576, key.serializer=org.apache.kafka.common.serialization.StringSerializer, client.id=azure-sql--schemahistory, linger.ms=0} (io.debezium.storage.kafka.history.KafkaSchemaHistory:246)
[2025-04-13 13:24:09,069] INFO [azure-sql-server-source|task-0] Requested thread factory for connector SqlServerConnector, id = azure-sql- named = db-history-config-check (io.debezium.util.Threads:271)
[2025-04-13 13:24:09,072] INFO [azure-sql-server-source|task-0] Idempotence will be disabled because acks is set to 1, not set to 'all'. (org.apache.kafka.clients.producer.ProducerConfig:586)
[2025-04-13 13:24:09,072] INFO [azure-sql-server-source|task-0] ProducerConfig values: 
	acks = 1
	auto.include.jmx.reporter = true
	batch.size = 32768
	bootstrap.servers = [localhost:9092]
	buffer.memory = 1048576
	client.dns.lookup = use_all_dns_ips
	client.id = azure-sql--schemahistory
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 10000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 1
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2025-04-13 13:24:09,072] INFO [azure-sql-server-source|task-0] initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-04-13 13:24:09,077] INFO [azure-sql-server-source|task-0] Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-04-13 13:24:09,078] INFO [azure-sql-server-source|task-0] Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-04-13 13:24:09,078] INFO [azure-sql-server-source|task-0] Kafka startTimeMs: 1744550649077 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-04-13 13:24:09,078] INFO [azure-sql-server-source|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = azure-sql--schemahistory
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = azure-sql--schemahistory
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-04-13 13:24:09,078] INFO [azure-sql-server-source|task-0] initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-04-13 13:24:09,083] INFO [azure-sql-server-source|task-0] [Producer clientId=azure-sql--schemahistory] Cluster ID: PRZJITuEQBeLmWOW7dnIsg (org.apache.kafka.clients.Metadata:364)
[2025-04-13 13:24:09,084] INFO [azure-sql-server-source|task-0] Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-04-13 13:24:09,084] INFO [azure-sql-server-source|task-0] Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-04-13 13:24:09,084] INFO [azure-sql-server-source|task-0] Kafka startTimeMs: 1744550649084 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-04-13 13:24:09,090] INFO [azure-sql-server-source|task-0] [Consumer clientId=azure-sql--schemahistory, groupId=azure-sql--schemahistory] Cluster ID: PRZJITuEQBeLmWOW7dnIsg (org.apache.kafka.clients.Metadata:364)
[2025-04-13 13:24:09,092] INFO [azure-sql-server-source|task-0] [Consumer clientId=azure-sql--schemahistory, groupId=azure-sql--schemahistory] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2025-04-13 13:24:09,092] INFO [azure-sql-server-source|task-0] [Consumer clientId=azure-sql--schemahistory, groupId=azure-sql--schemahistory] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-04-13 13:24:09,094] INFO [azure-sql-server-source|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-04-13 13:24:09,094] INFO [azure-sql-server-source|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-04-13 13:24:09,094] INFO [azure-sql-server-source|task-0] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-04-13 13:24:09,094] INFO [azure-sql-server-source|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-04-13 13:24:09,097] INFO [azure-sql-server-source|task-0] App info kafka.consumer for azure-sql--schemahistory unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-04-13 13:24:09,098] INFO [azure-sql-server-source|task-0] AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.controllers = []
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = azure-sql--schemahistory
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	enable.metrics.push = true
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 1
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:372)
[2025-04-13 13:24:09,099] INFO [azure-sql-server-source|task-0] These configurations '[value.serializer, acks, batch.size, max.block.ms, buffer.memory, key.serializer, linger.ms]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:381)
[2025-04-13 13:24:09,099] INFO [azure-sql-server-source|task-0] Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-04-13 13:24:09,099] INFO [azure-sql-server-source|task-0] Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-04-13 13:24:09,100] INFO [azure-sql-server-source|task-0] Kafka startTimeMs: 1744550649099 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-04-13 13:24:09,141] INFO [azure-sql-server-source|task-0] Database schema history topic '(name=schema-changes.database01, numPartitions=1, replicationFactor=default, replicasAssignments=null, configs={cleanup.policy=delete, retention.ms=9223372036854775807, retention.bytes=-1})' created (io.debezium.storage.kafka.history.KafkaSchemaHistory:555)
[2025-04-13 13:24:09,142] INFO [azure-sql-server-source|task-0] App info kafka.admin.client for azure-sql--schemahistory unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-04-13 13:24:09,146] INFO [azure-sql-server-source|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-04-13 13:24:09,146] INFO [azure-sql-server-source|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-04-13 13:24:09,146] INFO [azure-sql-server-source|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-04-13 13:24:09,159] INFO [azure-sql-server-source|task-0] No previous offsets found (io.debezium.connector.common.BaseSourceTask:378)
[2025-04-13 13:24:09,167] INFO [azure-sql-server-source|task-0] Requested thread factory for connector SqlServerConnector, id = azure-sql- named = SignalProcessor (io.debezium.util.Threads:271)
[2025-04-13 13:24:09,176] INFO [azure-sql-server-source|task-0] Requested thread factory for connector SqlServerConnector, id = azure-sql- named = change-event-source-coordinator (io.debezium.util.Threads:271)
[2025-04-13 13:24:09,177] INFO [azure-sql-server-source|task-0] Requested thread factory for connector SqlServerConnector, id = azure-sql- named = blocking-snapshot (io.debezium.util.Threads:271)
[2025-04-13 13:24:09,181] INFO [azure-sql-server-source|task-0] Creating thread debezium-sqlserverconnector-azure-sql--change-event-source-coordinator (io.debezium.util.Threads:288)
[2025-04-13 13:24:09,186] INFO [azure-sql-server-source|task-0] Metrics registered (io.debezium.pipeline.ChangeEventSourceCoordinator:131)
[2025-04-13 13:24:09,186] INFO [azure-sql-server-source|task-0] Context created (io.debezium.pipeline.ChangeEventSourceCoordinator:134)
[2025-04-13 13:24:09,189] INFO [azure-sql-server-source|task-0] SignalProcessor started. Scheduling it every 5000ms (io.debezium.pipeline.signal.SignalProcessor:105)
[2025-04-13 13:24:09,189] INFO [azure-sql-server-source|task-0] Creating thread debezium-sqlserverconnector-azure-sql--SignalProcessor (io.debezium.util.Threads:288)
[2025-04-13 13:24:09,193] INFO [azure-sql-server-source|task-0] WorkerSourceTask{id=azure-sql-server-source-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.AbstractWorkerSourceTask:279)
[2025-04-13 13:24:09,196] INFO [azure-sql-server-source|task-0] No previous offset has been found (io.debezium.connector.sqlserver.SqlServerSnapshotChangeEventSource:78)
[2025-04-13 13:24:09,196] INFO [azure-sql-server-source|task-0] According to the connector configuration both schema and data will be snapshotted (io.debezium.connector.sqlserver.SqlServerSnapshotChangeEventSource:80)
[2025-04-13 13:24:09,198] INFO [azure-sql-server-source|task-0] Snapshot step 1 - Preparing (io.debezium.relational.RelationalSnapshotChangeEventSource:121)
[2025-04-13 13:24:09,258] INFO [azure-sql-server-source|task-0] Snapshot step 2 - Determining captured tables (io.debezium.relational.RelationalSnapshotChangeEventSource:130)
[2025-04-13 13:24:09,282] INFO [azure-sql-server-source|task-0] Adding table database01.SalesLT.ProductCategory to the list of capture schema tables (io.debezium.relational.RelationalSnapshotChangeEventSource:289)
[2025-04-13 13:24:09,282] INFO [azure-sql-server-source|task-0] Adding table database01.dbo.BuildVersion to the list of capture schema tables (io.debezium.relational.RelationalSnapshotChangeEventSource:289)
[2025-04-13 13:24:09,282] INFO [azure-sql-server-source|task-0] Adding table database01.SalesLT.ProductModelProductDescription to the list of capture schema tables (io.debezium.relational.RelationalSnapshotChangeEventSource:289)
[2025-04-13 13:24:09,282] INFO [azure-sql-server-source|task-0] Adding table database01.SalesLT.ProductModel to the list of capture schema tables (io.debezium.relational.RelationalSnapshotChangeEventSource:289)
[2025-04-13 13:24:09,282] INFO [azure-sql-server-source|task-0] Adding table database01.SalesLT.SalesOrderHeader to the list of capture schema tables (io.debezium.relational.RelationalSnapshotChangeEventSource:289)
[2025-04-13 13:24:09,282] INFO [azure-sql-server-source|task-0] Adding table database01.SalesLT.Address to the list of capture schema tables (io.debezium.relational.RelationalSnapshotChangeEventSource:289)
[2025-04-13 13:24:09,282] INFO [azure-sql-server-source|task-0] Adding table database01.SalesLT.ProductDescription to the list of capture schema tables (io.debezium.relational.RelationalSnapshotChangeEventSource:289)
[2025-04-13 13:24:09,283] INFO [azure-sql-server-source|task-0] Adding table database01.SalesLT.Customer to the list of capture schema tables (io.debezium.relational.RelationalSnapshotChangeEventSource:289)
[2025-04-13 13:24:09,283] INFO [azure-sql-server-source|task-0] Adding table database01.SalesLT.SalesOrderDetail to the list of capture schema tables (io.debezium.relational.RelationalSnapshotChangeEventSource:289)
[2025-04-13 13:24:09,283] INFO [azure-sql-server-source|task-0] Adding table database01.dbo.ErrorLog to the list of capture schema tables (io.debezium.relational.RelationalSnapshotChangeEventSource:289)
[2025-04-13 13:24:09,283] INFO [azure-sql-server-source|task-0] Adding table database01.SalesLT.CustomerAddress to the list of capture schema tables (io.debezium.relational.RelationalSnapshotChangeEventSource:289)
[2025-04-13 13:24:09,283] INFO [azure-sql-server-source|task-0] Adding table database01.SalesLT.Product to the list of capture schema tables (io.debezium.relational.RelationalSnapshotChangeEventSource:289)
[2025-04-13 13:24:09,286] INFO [azure-sql-server-source|task-0] Created connection pool with 1 threads (io.debezium.relational.RelationalSnapshotChangeEventSource:222)
[2025-04-13 13:24:09,286] INFO [azure-sql-server-source|task-0] Snapshot step 3 - Locking captured tables [database01.SalesLT.Product] (io.debezium.relational.RelationalSnapshotChangeEventSource:139)
[2025-04-13 13:24:09,286] INFO [azure-sql-server-source|task-0] Setting locking timeout to 10 s (io.debezium.connector.sqlserver.SqlServerSnapshotChangeEventSource:135)
[2025-04-13 13:24:09,299] INFO [azure-sql-server-source|task-0] Executing schema locking (io.debezium.connector.sqlserver.SqlServerSnapshotChangeEventSource:140)
[2025-04-13 13:24:09,299] INFO [azure-sql-server-source|task-0] Locking table database01.SalesLT.Product (io.debezium.connector.sqlserver.SqlServerSnapshotChangeEventSource:147)
[2025-04-13 13:24:09,303] INFO [azure-sql-server-source|task-0] Snapshot step 4 - Determining snapshot offset (io.debezium.relational.RelationalSnapshotChangeEventSource:145)
[2025-04-13 13:24:09,312] INFO [azure-sql-server-source|task-0] Snapshot step 5 - Reading structure of captured tables (io.debezium.relational.RelationalSnapshotChangeEventSource:148)
[2025-04-13 13:24:09,322] INFO [azure-sql-server-source|task-0] Reading structure of schema 'database01' (io.debezium.connector.sqlserver.SqlServerSnapshotChangeEventSource:209)
[2025-04-13 13:24:09,603] INFO [azure-sql-server-source|task-0] Snapshot step 6 - Persisting schema history (io.debezium.relational.RelationalSnapshotChangeEventSource:152)
[2025-04-13 13:24:09,604] INFO [azure-sql-server-source|task-0] Capturing structure of table database01.SalesLT.Product (io.debezium.relational.RelationalSnapshotChangeEventSource:367)
[2025-04-13 13:24:09,613] WARN [azure-sql-server-source|task-0] Mapper for type 'uniqueidentifier' not found. (io.debezium.connector.sqlserver.SqlServerDefaultValueConverter:68)
[2025-04-13 13:24:09,820] WARN [azure-sql-server-source|task-0] Cannot parse column default value '(getdate())' to type 'datetime'. Expression evaluation is not supported. (io.debezium.connector.sqlserver.SqlServerDefaultValueConverter:78)
[2025-04-13 13:24:09,866] INFO [azure-sql-server-source|task-0] Schema locks released. (io.debezium.connector.sqlserver.SqlServerSnapshotChangeEventSource:167)
[2025-04-13 13:24:09,866] INFO [azure-sql-server-source|task-0] Snapshot step 7 - Snapshotting data (io.debezium.relational.RelationalSnapshotChangeEventSource:164)
[2025-04-13 13:24:09,867] INFO [azure-sql-server-source|task-0] Creating snapshot worker pool with 1 worker thread(s) (io.debezium.relational.RelationalSnapshotChangeEventSource:414)
[2025-04-13 13:24:09,869] INFO [azure-sql-server-source|task-0] For table 'database01.SalesLT.Product' using select statement: 'SELECT [ProductID], [Name], [ProductNumber], [Color], [StandardCost], [ListPrice], [Size], [Weight], [ProductCategoryID], [ProductModelID], [SellStartDate], [SellEndDate], [DiscontinuedDate], [ThumbNailPhoto], [ThumbnailPhotoFileName], [rowguid], [ModifiedDate] FROM [database01].[SalesLT].[Product]' (io.debezium.relational.RelationalSnapshotChangeEventSource:423)
[2025-04-13 13:24:09,872] INFO [azure-sql-server-source|task-0] Exporting data from table 'database01.SalesLT.Product' (1 of 1 tables) (io.debezium.relational.RelationalSnapshotChangeEventSource:542)
[2025-04-13 13:24:10,054] INFO [azure-sql-server-source|task-0] 	 Finished exporting 295 records for table 'database01.SalesLT.Product' (1 of 1 tables); total duration '00:00:00.182' (io.debezium.relational.RelationalSnapshotChangeEventSource:588)
[2025-04-13 13:24:10,068] INFO [azure-sql-server-source|task-0] Snapshot - Final stage (io.debezium.pipeline.source.AbstractSnapshotChangeEventSource:104)
[2025-04-13 13:24:10,068] INFO [azure-sql-server-source|task-0] Snapshot completed (io.debezium.pipeline.source.AbstractSnapshotChangeEventSource:108)
[2025-04-13 13:24:10,070] INFO [azure-sql-server-source|task-0] Removing locking timeout (io.debezium.connector.sqlserver.SqlServerSnapshotChangeEventSource:262)
[2025-04-13 13:24:10,080] INFO [azure-sql-server-source|task-0] Snapshot ended with SnapshotResult [status=COMPLETED, offset=SqlServerOffsetContext [sourceInfoSchema=Schema{io.debezium.connector.sqlserver.Source:STRUCT}, sourceInfo=SourceInfo [serverName=azure-sql-, changeLsn=NULL, commitLsn=0000010f:000009e0:0004, eventSerialNo=null, snapshot=FALSE, sourceTime=2025-04-13T13:24:09.864126700Z], snapshotCompleted=true, eventSerialNo=1]] (io.debezium.pipeline.ChangeEventSourceCoordinator:254)
[2025-04-13 13:24:10,083] INFO [azure-sql-server-source|task-0] Connected metrics set to 'true' (io.debezium.pipeline.ChangeEventSourceCoordinator:425)
[2025-04-13 13:24:10,084] INFO [azure-sql-server-source|task-0] Starting streaming (io.debezium.connector.sqlserver.SqlServerChangeEventSourceCoordinator:101)
[2025-04-13 13:24:10,086] INFO [azure-sql-server-source|task-0] Last position recorded in offsets is 0000010f:000009e0:0004(NULL)[1] (io.debezium.connector.sqlserver.SqlServerStreamingChangeEventSource:160)
[2025-04-13 13:24:14,195] INFO [azure-sql-server-source|task-0] 296 records sent during previous 00:00:05.144, last recorded offset of {server=azure-sql-, database=database01} partition is {commit_lsn=0000010f:000009e0:0004, snapshot=true, snapshot_completed=true} (io.debezium.connector.common.BaseSourceTask:213)
[2025-04-13 13:24:14,204] WARN [azure-sql-server-source|task-0] [Producer clientId=connector-producer-azure-sql-server-source-0] Error while fetching metadata with correlation id 4 : {azure-sql-=UNKNOWN_TOPIC_OR_PARTITION} (org.apache.kafka.clients.NetworkClient:1213)
[2025-04-13 13:24:14,330] WARN [azure-sql-server-source|task-0] [Producer clientId=connector-producer-azure-sql-server-source-0] Error while fetching metadata with correlation id 7 : {azure-sql-.database01.SalesLT.Product=UNKNOWN_TOPIC_OR_PARTITION} (org.apache.kafka.clients.NetworkClient:1213)
[2025-04-13 13:24:33,872] INFO 87.208.3.218 - - [13/Apr/2025:13:24:33 +0000] "GET /connectors/azure-sql-server-source/status%20 HTTP/1.1" 404 49 "-" "PostmanRuntime/7.43.3" 3 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-04-13 13:24:38,037] INFO 87.208.3.218 - - [13/Apr/2025:13:24:38 +0000] "GET /connectors/azure-sql-server-source/status HTTP/1.1" 200 175 "-" "PostmanRuntime/7.43.3" 4 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-04-13 13:24:48,378] INFO 87.208.3.218 - - [13/Apr/2025:13:24:48 +0000] "GET /connectors HTTP/1.1" 200 27 "-" "PostmanRuntime/7.43.3" 3 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-04-13 13:25:09,061] INFO [azure-sql-server-source|task-0|offsets] WorkerSourceTask{id=azure-sql-server-source-0} Committing offsets for 296 acknowledged messages (org.apache.kafka.connect.runtime.WorkerSourceTask:235)
[2025-04-13 13:25:44,531] INFO 127.0.0.1 - - [13/Apr/2025:13:25:44 +0000] "GET /connectors/azure-sql-server-source/status HTTP/1.1" 200 175 "-" "curl/7.81.0" 4 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-04-13 13:27:32,324] INFO [Consumer clientId=connect-cluster-offsets, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-04-13 13:27:33,322] INFO [Consumer clientId=connect-cluster-statuses, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-04-13 13:27:33,418] INFO [Consumer clientId=connect-cluster-configs, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-04-13 13:31:11,049] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:372)
[2025-04-13 13:31:11,055] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Connector sink-to-database02 config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2425)
[2025-04-13 13:31:11,056] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-04-13 13:31:11,056] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-04-13 13:31:11,058] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=8, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-04-13 13:31:11,058] INFO 87.208.3.218 - - [13/Apr/2025:13:31:11 +0000] "POST /connectors HTTP/1.1" 201 495 "-" "PostmanRuntime/7.43.3" 33 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-04-13 13:31:11,061] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=8, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-04-13 13:31:11,061] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Joined group at generation 8 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', leaderUrl='http://10.0.0.4:8083/', offset=10, connectorIds=[sink-to-database02, azure-sql-server-source], taskIds=[azure-sql-server-source-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2621)
[2025-04-13 13:31:11,061] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 10 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1959)
[2025-04-13 13:31:11,061] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Starting connector sink-to-database02 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2077)
[2025-04-13 13:31:11,062] INFO [sink-to-database02|worker] Creating connector sink-to-database02 of type io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:312)
[2025-04-13 13:31:11,062] INFO [sink-to-database02|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-to-database02
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [azure-sql-.database01.SalesLT.Product]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-04-13 13:31:11,062] INFO [sink-to-database02|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-to-database02
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [azure-sql-.database01.SalesLT.Product]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-04-13 13:31:11,062] INFO [sink-to-database02|worker] Instantiated connector sink-to-database02 with version 10.7.0 of type class io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:334)
[2025-04-13 13:31:11,063] INFO [sink-to-database02|worker] Finished creating connector sink-to-database02 (org.apache.kafka.connect.runtime.Worker:355)
[2025-04-13 13:31:11,063] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1988)
[2025-04-13 13:31:11,065] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-to-database02
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [azure-sql-.database01.SalesLT.Product]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-04-13 13:31:11,065] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-to-database02
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [azure-sql-.database01.SalesLT.Product]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-04-13 13:31:11,065] INFO [sink-to-database02|worker] Setting task configurations for 1 workers. (io.confluent.connect.jdbc.JdbcSinkConnector:51)
[2025-04-13 13:31:11,077] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Tasks [sink-to-database02-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2440)
[2025-04-13 13:31:11,078] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-04-13 13:31:11,078] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-04-13 13:31:11,080] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=9, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-04-13 13:31:11,082] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=9, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-04-13 13:31:11,082] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Joined group at generation 9 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', leaderUrl='http://10.0.0.4:8083/', offset=12, connectorIds=[sink-to-database02, azure-sql-server-source], taskIds=[sink-to-database02-0, azure-sql-server-source-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2621)
[2025-04-13 13:31:11,082] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 12 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1959)
[2025-04-13 13:31:11,083] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Starting task sink-to-database02-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2002)
[2025-04-13 13:31:11,084] INFO [sink-to-database02|task-0] Creating task sink-to-database02-0 (org.apache.kafka.connect.runtime.Worker:645)
[2025-04-13 13:31:11,084] INFO [sink-to-database02|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-to-database02
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2025-04-13 13:31:11,085] INFO [sink-to-database02|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-to-database02
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-04-13 13:31:11,085] INFO [sink-to-database02|task-0] TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.sink.JdbcSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2025-04-13 13:31:11,085] INFO [sink-to-database02|task-0] Instantiated task sink-to-database02-0 with version 10.7.0 of type io.confluent.connect.jdbc.sink.JdbcSinkTask (org.apache.kafka.connect.runtime.Worker:664)
[2025-04-13 13:31:11,086] INFO [sink-to-database02|task-0] JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-04-13 13:31:11,086] INFO [sink-to-database02|task-0] Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task sink-to-database02-0 using the worker config (org.apache.kafka.connect.runtime.Worker:677)
[2025-04-13 13:31:11,086] INFO [sink-to-database02|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-04-13 13:31:11,086] INFO [sink-to-database02|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task sink-to-database02-0 using the worker config (org.apache.kafka.connect.runtime.Worker:683)
[2025-04-13 13:31:11,086] INFO [sink-to-database02|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task sink-to-database02-0 using the worker config (org.apache.kafka.connect.runtime.Worker:690)
[2025-04-13 13:31:11,086] INFO [sink-to-database02|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:1794)
[2025-04-13 13:31:11,087] INFO [sink-to-database02|task-0] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-to-database02
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [azure-sql-.database01.SalesLT.Product]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-04-13 13:31:11,087] INFO [sink-to-database02|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-to-database02
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [azure-sql-.database01.SalesLT.Product]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-04-13 13:31:11,087] INFO [sink-to-database02|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-sink-to-database02-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-sink-to-database02
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-04-13 13:31:11,087] INFO [sink-to-database02|task-0] initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-04-13 13:31:11,090] INFO [sink-to-database02|task-0] These configurations '[metrics.context.connect.kafka.cluster.id, metrics.context.connect.group.id]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-04-13 13:31:11,090] INFO [sink-to-database02|task-0] Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-04-13 13:31:11,090] INFO [sink-to-database02|task-0] Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-04-13 13:31:11,090] INFO [sink-to-database02|task-0] Kafka startTimeMs: 1744551071090 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-04-13 13:31:11,096] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1988)
[2025-04-13 13:31:11,097] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] Subscribed to topic(s): azure-sql-.database01.SalesLT.Product (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:476)
[2025-04-13 13:31:11,097] INFO [sink-to-database02|task-0] Starting JDBC Sink task (io.confluent.connect.jdbc.sink.JdbcSinkTask:51)
[2025-04-13 13:31:11,097] INFO [sink-to-database02|task-0] JdbcSinkConfig values: 
	auto.create = true
	auto.evolve = false
	batch.size = 3000
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlserver://kafkadatabase.database.windows.net:1433;databaseName=database02
	connection.user = kafkadmin@kafkadatabase
	db.timezone = UTC
	delete.enabled = false
	dialect.name = 
	fields.whitelist = []
	insert.mode = upsert
	max.retries = 10
	mssql.use.merge.holdlock = true
	pk.fields = [ProductID]
	pk.mode = record_value
	quote.sql.identifiers = ALWAYS
	retry.backoff.ms = 3000
	table.name.format = ${topic}
	table.types = [TABLE]
	trim.sensitive.log = false
 (io.confluent.connect.jdbc.sink.JdbcSinkConfig:372)
[2025-04-13 13:31:11,103] INFO [sink-to-database02|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:31:11,104] INFO [sink-to-database02|task-0] WorkerSinkTask{id=sink-to-database02-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:324)
[2025-04-13 13:31:11,104] INFO [sink-to-database02|task-0] WorkerSinkTask{id=sink-to-database02-0} Executing sink task (org.apache.kafka.connect.runtime.WorkerSinkTask:210)
[2025-04-13 13:31:11,111] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] Cluster ID: PRZJITuEQBeLmWOW7dnIsg (org.apache.kafka.clients.Metadata:364)
[2025-04-13 13:31:11,112] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] Discovered group coordinator localhost:9092 (id: 2147483646 rack: null) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:936)
[2025-04-13 13:31:11,115] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] (Re-)joining group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2025-04-13 13:31:11,123] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] Request joining group due to: need to re-join with the given member-id: connector-consumer-sink-to-database02-0-1d253333-ef42-47f0-9215-6e0c7694fd79 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-04-13 13:31:11,123] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] (Re-)joining group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2025-04-13 13:31:14,125] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] Successfully joined group with generation Generation{generationId=1, memberId='connector-consumer-sink-to-database02-0-1d253333-ef42-47f0-9215-6e0c7694fd79', protocol='range'} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:665)
[2025-04-13 13:31:14,133] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] Finished assignment for group at generation 1: {connector-consumer-sink-to-database02-0-1d253333-ef42-47f0-9215-6e0c7694fd79=Assignment(partitions=[azure-sql-.database01.SalesLT.Product-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:663)
[2025-04-13 13:31:14,137] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] Successfully synced group in generation Generation{generationId=1, memberId='connector-consumer-sink-to-database02-0-1d253333-ef42-47f0-9215-6e0c7694fd79', protocol='range'} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:842)
[2025-04-13 13:31:14,137] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] Notifying assignor about the new Assignment(partitions=[azure-sql-.database01.SalesLT.Product-0]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:323)
[2025-04-13 13:31:14,138] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] Adding newly assigned partitions: azure-sql-.database01.SalesLT.Product-0 (org.apache.kafka.clients.consumer.internals.ConsumerRebalanceListenerInvoker:57)
[2025-04-13 13:31:14,141] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] Found no committed offset for partition azure-sql-.database01.SalesLT.Product-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1506)
[2025-04-13 13:31:14,145] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] Resetting offset for partition azure-sql-.database01.SalesLT.Product-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-04-13 13:31:14,295] INFO [sink-to-database02|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:31:14,457] INFO [sink-to-database02|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:31:14,545] INFO [sink-to-database02|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:31:14,554] WARN [sink-to-database02|task-0] Write of 198 records failed, remainingRetries=10 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:31:14,555] INFO [sink-to-database02|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:31:14,555] INFO [sink-to-database02|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:31:14,555] ERROR [sink-to-database02|task-0] WorkerSinkTask{id=sink-to-database02-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:31:17,556] INFO [sink-to-database02|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:31:17,597] INFO [sink-to-database02|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:31:17,638] INFO [sink-to-database02|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:31:17,642] WARN [sink-to-database02|task-0] Write of 198 records failed, remainingRetries=9 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:31:17,642] INFO [sink-to-database02|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:31:17,643] INFO [sink-to-database02|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:31:17,643] ERROR [sink-to-database02|task-0] WorkerSinkTask{id=sink-to-database02-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:31:20,644] INFO [sink-to-database02|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:31:20,714] INFO [sink-to-database02|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:31:20,761] INFO [sink-to-database02|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:31:20,764] WARN [sink-to-database02|task-0] Write of 198 records failed, remainingRetries=8 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:31:20,765] INFO [sink-to-database02|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:31:20,765] INFO [sink-to-database02|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:31:20,765] ERROR [sink-to-database02|task-0] WorkerSinkTask{id=sink-to-database02-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:31:23,779] INFO [sink-to-database02|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:31:23,829] INFO [sink-to-database02|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:31:23,880] INFO [sink-to-database02|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:31:23,882] WARN [sink-to-database02|task-0] Write of 198 records failed, remainingRetries=7 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:31:23,882] INFO [sink-to-database02|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:31:23,883] INFO [sink-to-database02|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:31:23,883] ERROR [sink-to-database02|task-0] WorkerSinkTask{id=sink-to-database02-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:31:26,885] INFO [sink-to-database02|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:31:26,940] INFO [sink-to-database02|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:31:26,981] INFO [sink-to-database02|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:31:26,984] WARN [sink-to-database02|task-0] Write of 198 records failed, remainingRetries=6 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:31:26,984] INFO [sink-to-database02|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:31:26,985] INFO [sink-to-database02|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:31:26,987] ERROR [sink-to-database02|task-0] WorkerSinkTask{id=sink-to-database02-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:31:29,987] INFO [sink-to-database02|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:31:30,028] INFO [sink-to-database02|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:31:30,076] INFO [sink-to-database02|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:31:30,079] WARN [sink-to-database02|task-0] Write of 198 records failed, remainingRetries=5 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:31:30,079] INFO [sink-to-database02|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:31:30,079] INFO [sink-to-database02|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:31:30,079] ERROR [sink-to-database02|task-0] WorkerSinkTask{id=sink-to-database02-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:31:33,081] INFO [sink-to-database02|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:31:33,128] INFO [sink-to-database02|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:31:33,167] INFO [sink-to-database02|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:31:33,168] WARN [sink-to-database02|task-0] Write of 198 records failed, remainingRetries=4 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:31:33,169] INFO [sink-to-database02|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:31:33,169] INFO [sink-to-database02|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:31:33,169] ERROR [sink-to-database02|task-0] WorkerSinkTask{id=sink-to-database02-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:31:36,170] INFO [sink-to-database02|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:31:36,207] INFO [sink-to-database02|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:31:36,245] INFO [sink-to-database02|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:31:36,247] WARN [sink-to-database02|task-0] Write of 198 records failed, remainingRetries=3 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:31:36,247] INFO [sink-to-database02|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:31:36,248] INFO [sink-to-database02|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:31:36,249] ERROR [sink-to-database02|task-0] WorkerSinkTask{id=sink-to-database02-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:31:39,249] INFO [sink-to-database02|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:31:39,300] INFO [sink-to-database02|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:31:39,347] INFO [sink-to-database02|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:31:39,349] WARN [sink-to-database02|task-0] Write of 198 records failed, remainingRetries=2 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:31:39,350] INFO [sink-to-database02|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:31:39,350] INFO [sink-to-database02|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:31:39,350] ERROR [sink-to-database02|task-0] WorkerSinkTask{id=sink-to-database02-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:31:42,351] INFO [sink-to-database02|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:31:42,389] INFO [sink-to-database02|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:31:42,431] INFO [sink-to-database02|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:31:42,433] WARN [sink-to-database02|task-0] Write of 198 records failed, remainingRetries=1 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:31:42,434] INFO [sink-to-database02|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:31:42,434] INFO [sink-to-database02|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:31:42,434] ERROR [sink-to-database02|task-0] WorkerSinkTask{id=sink-to-database02-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:31:45,434] INFO [sink-to-database02|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:31:45,499] INFO [sink-to-database02|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:31:45,545] INFO [sink-to-database02|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:31:45,547] WARN [sink-to-database02|task-0] Write of 198 records failed, remainingRetries=0 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:31:45,548] ERROR [sink-to-database02|task-0] Failing task after exhausting retries; encountered 1 exceptions on last write attempt. For complete details on each exception, please enable DEBUG logging. (io.confluent.connect.jdbc.sink.JdbcSinkTask:119)
[2025-04-13 13:31:45,548] ERROR [sink-to-database02|task-0] WorkerSinkTask{id=sink-to-database02-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted. Error: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
 (org.apache.kafka.connect.runtime.WorkerSinkTask:633)
org.apache.kafka.connect.errors.ConnectException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:128)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:31:45,549] ERROR [sink-to-database02|task-0] WorkerSinkTask{id=sink-to-database02-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:233)
org.apache.kafka.connect.errors.ConnectException: Exiting WorkerSinkTask due to unrecoverable exception.
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:635)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: org.apache.kafka.connect.errors.ConnectException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:128)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	... 11 more
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:31:45,549] INFO [sink-to-database02|task-0] Stopping task (io.confluent.connect.jdbc.sink.JdbcSinkTask:170)
[2025-04-13 13:31:45,549] INFO [sink-to-database02|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:31:45,550] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] Revoke previously assigned partitions azure-sql-.database01.SalesLT.Product-0 (org.apache.kafka.clients.consumer.internals.ConsumerRebalanceListenerInvoker:79)
[2025-04-13 13:31:45,550] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] The pause flag in partitions [azure-sql-.database01.SalesLT.Product-0] will be removed due to revocation. (org.apache.kafka.clients.consumer.internals.ConsumerRebalanceListenerInvoker:83)
[2025-04-13 13:31:45,550] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] Member connector-consumer-sink-to-database02-0-1d253333-ef42-47f0-9215-6e0c7694fd79 sending LeaveGroup request to coordinator localhost:9092 (id: 2147483646 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1173)
[2025-04-13 13:31:45,551] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2025-04-13 13:31:45,551] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-04-13 13:31:45,554] INFO [sink-to-database02|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-04-13 13:31:45,554] INFO [sink-to-database02|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-04-13 13:31:45,554] INFO [sink-to-database02|task-0] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-04-13 13:31:45,554] INFO [sink-to-database02|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-04-13 13:31:45,557] INFO [sink-to-database02|task-0] App info kafka.consumer for connector-consumer-sink-to-database02-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-04-13 13:31:47,212] INFO 87.208.3.218 - - [13/Apr/2025:13:31:47 +0000] "GET /connectors/sink-to-database02/status HTTP/1.1" 200 2167 "-" "PostmanRuntime/7.43.3" 3 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-04-13 13:33:09,305] INFO [azure-sql-server-source|task-0] [Producer clientId=azure-sql--schemahistory] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-04-13 13:33:14,620] INFO [azure-sql-server-source|task-0] [Producer clientId=connector-producer-azure-sql-server-source-0] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-04-13 13:33:27,636] INFO Successfully processed removal of connector 'sink-to-database02' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1003)
[2025-04-13 13:33:27,636] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Connector sink-to-database02 config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2412)
[2025-04-13 13:33:27,636] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Handling connector-only config update by stopping connector sink-to-database02 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:716)
[2025-04-13 13:33:27,637] INFO [sink-to-database02|worker] Stopping connector sink-to-database02 (org.apache.kafka.connect.runtime.Worker:451)
[2025-04-13 13:33:27,637] INFO [sink-to-database02|worker] Scheduled shutdown for WorkerConnector{id=sink-to-database02} (org.apache.kafka.connect.runtime.WorkerConnector:294)
[2025-04-13 13:33:27,637] INFO 87.208.3.218 - - [13/Apr/2025:13:33:27 +0000] "DELETE /connectors/sink-to-database02/ HTTP/1.1" 204 0 "-" "PostmanRuntime/7.43.3" 8 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-04-13 13:33:27,638] INFO [sink-to-database02|worker] Completed shutdown for WorkerConnector{id=sink-to-database02} (org.apache.kafka.connect.runtime.WorkerConnector:314)
[2025-04-13 13:33:27,639] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-04-13 13:33:27,639] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-04-13 13:33:27,642] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=10, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-04-13 13:33:27,647] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=10, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-04-13 13:33:27,648] INFO [sink-to-database02|worker] Stopping connector sink-to-database02 (org.apache.kafka.connect.runtime.Worker:451)
[2025-04-13 13:33:27,648] WARN [sink-to-database02|worker] Ignoring stop request for unowned connector sink-to-database02 (org.apache.kafka.connect.runtime.Worker:454)
[2025-04-13 13:33:27,648] WARN [sink-to-database02|worker] Ignoring await stop request for non-present connector sink-to-database02 (org.apache.kafka.connect.runtime.Worker:475)
[2025-04-13 13:33:27,648] INFO [sink-to-database02|task-0] Stopping task sink-to-database02-0 (org.apache.kafka.connect.runtime.Worker:1047)
[2025-04-13 13:33:27,650] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2708)
[2025-04-13 13:33:27,652] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2729)
[2025-04-13 13:33:27,653] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Joined group at generation 10 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', leaderUrl='http://10.0.0.4:8083/', offset=14, connectorIds=[azure-sql-server-source], taskIds=[azure-sql-server-source-0], revokedConnectorIds=[sink-to-database02], revokedTaskIds=[sink-to-database02-0], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2621)
[2025-04-13 13:33:27,653] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 14 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1959)
[2025-04-13 13:33:27,653] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1988)
[2025-04-13 13:33:27,653] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-04-13 13:33:27,653] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-04-13 13:33:27,657] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=11, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-04-13 13:33:27,659] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=11, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-04-13 13:33:27,660] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Joined group at generation 11 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', leaderUrl='http://10.0.0.4:8083/', offset=14, connectorIds=[azure-sql-server-source], taskIds=[azure-sql-server-source-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2621)
[2025-04-13 13:33:27,660] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 14 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1959)
[2025-04-13 13:33:27,660] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1988)
[2025-04-13 13:33:36,579] INFO 87.208.3.218 - - [13/Apr/2025:13:33:36 +0000] "GET /connectors HTTP/1.1" 200 27 "-" "PostmanRuntime/7.43.3" 4 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-04-13 13:34:07,000] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:372)
[2025-04-13 13:34:07,004] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Connector sink-to-database02 config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2425)
[2025-04-13 13:34:07,006] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-04-13 13:34:07,006] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-04-13 13:34:07,008] INFO 87.208.3.218 - - [13/Apr/2025:13:34:06 +0000] "POST /connectors HTTP/1.1" 201 595 "-" "PostmanRuntime/7.43.3" 17 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-04-13 13:34:07,009] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=12, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-04-13 13:34:07,011] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=12, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-04-13 13:34:07,012] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Joined group at generation 12 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', leaderUrl='http://10.0.0.4:8083/', offset=15, connectorIds=[sink-to-database02, azure-sql-server-source], taskIds=[azure-sql-server-source-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2621)
[2025-04-13 13:34:07,012] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 15 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1959)
[2025-04-13 13:34:07,012] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Starting connector sink-to-database02 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2077)
[2025-04-13 13:34:07,012] INFO [sink-to-database02|worker] Creating connector sink-to-database02 of type io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:312)
[2025-04-13 13:34:07,013] INFO [sink-to-database02|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-to-database02
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [azure-sql-.database01.SalesLT.Product]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-04-13 13:34:07,013] INFO [sink-to-database02|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-to-database02
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [azure-sql-.database01.SalesLT.Product]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-04-13 13:34:07,013] INFO [sink-to-database02|worker] Instantiated connector sink-to-database02 with version 10.7.0 of type class io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:334)
[2025-04-13 13:34:07,013] INFO [sink-to-database02|worker] Finished creating connector sink-to-database02 (org.apache.kafka.connect.runtime.Worker:355)
[2025-04-13 13:34:07,013] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1988)
[2025-04-13 13:34:07,014] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-to-database02
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [azure-sql-.database01.SalesLT.Product]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-04-13 13:34:07,015] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-to-database02
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [azure-sql-.database01.SalesLT.Product]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-04-13 13:34:07,015] INFO [sink-to-database02|worker] Setting task configurations for 1 workers. (io.confluent.connect.jdbc.JdbcSinkConnector:51)
[2025-04-13 13:34:07,024] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Tasks [sink-to-database02-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2440)
[2025-04-13 13:34:07,027] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-04-13 13:34:07,027] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-04-13 13:34:07,028] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=13, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-04-13 13:34:07,029] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=13, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-04-13 13:34:07,030] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Joined group at generation 13 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', leaderUrl='http://10.0.0.4:8083/', offset=17, connectorIds=[sink-to-database02, azure-sql-server-source], taskIds=[sink-to-database02-0, azure-sql-server-source-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2621)
[2025-04-13 13:34:07,030] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 17 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1959)
[2025-04-13 13:34:07,030] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Starting task sink-to-database02-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2002)
[2025-04-13 13:34:07,030] INFO [sink-to-database02|task-0] Creating task sink-to-database02-0 (org.apache.kafka.connect.runtime.Worker:645)
[2025-04-13 13:34:07,031] INFO [sink-to-database02|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-to-database02
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2025-04-13 13:34:07,031] INFO [sink-to-database02|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-to-database02
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-04-13 13:34:07,031] INFO [sink-to-database02|task-0] TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.sink.JdbcSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2025-04-13 13:34:07,031] INFO [sink-to-database02|task-0] Instantiated task sink-to-database02-0 with version 10.7.0 of type io.confluent.connect.jdbc.sink.JdbcSinkTask (org.apache.kafka.connect.runtime.Worker:664)
[2025-04-13 13:34:07,031] INFO [sink-to-database02|task-0] JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-04-13 13:34:07,031] INFO [sink-to-database02|task-0] Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task sink-to-database02-0 using the worker config (org.apache.kafka.connect.runtime.Worker:677)
[2025-04-13 13:34:07,031] INFO [sink-to-database02|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-04-13 13:34:07,031] INFO [sink-to-database02|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task sink-to-database02-0 using the worker config (org.apache.kafka.connect.runtime.Worker:683)
[2025-04-13 13:34:07,031] INFO [sink-to-database02|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task sink-to-database02-0 using the worker config (org.apache.kafka.connect.runtime.Worker:690)
[2025-04-13 13:34:07,032] INFO [sink-to-database02|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:1794)
[2025-04-13 13:34:07,032] INFO [sink-to-database02|task-0] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-to-database02
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [azure-sql-.database01.SalesLT.Product]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-04-13 13:34:07,032] INFO [sink-to-database02|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-to-database02
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [azure-sql-.database01.SalesLT.Product]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-04-13 13:34:07,033] INFO [sink-to-database02|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-sink-to-database02-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-sink-to-database02
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-04-13 13:34:07,033] INFO [sink-to-database02|task-0] initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-04-13 13:34:07,037] INFO [sink-to-database02|task-0] These configurations '[metrics.context.connect.kafka.cluster.id, metrics.context.connect.group.id]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-04-13 13:34:07,038] INFO [sink-to-database02|task-0] Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-04-13 13:34:07,038] INFO [sink-to-database02|task-0] Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-04-13 13:34:07,038] INFO [sink-to-database02|task-0] Kafka startTimeMs: 1744551247038 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-04-13 13:34:07,039] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] Subscribed to topic(s): azure-sql-.database01.SalesLT.Product (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:476)
[2025-04-13 13:34:07,039] INFO [sink-to-database02|task-0] Starting JDBC Sink task (io.confluent.connect.jdbc.sink.JdbcSinkTask:51)
[2025-04-13 13:34:07,040] INFO [sink-to-database02|task-0] JdbcSinkConfig values: 
	auto.create = true
	auto.evolve = false
	batch.size = 3000
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlserver://kafkadatabase.database.windows.net:1433;database=database02;encrypt=true;trustServerCertificate=false;hostNameInCertificate=*.database.windows.net;loginTimeout=30;
	connection.user = kafkadmin@kafkadatabase
	db.timezone = UTC
	delete.enabled = false
	dialect.name = 
	fields.whitelist = []
	insert.mode = upsert
	max.retries = 10
	mssql.use.merge.holdlock = true
	pk.fields = [ProductID]
	pk.mode = record_value
	quote.sql.identifiers = ALWAYS
	retry.backoff.ms = 3000
	table.name.format = ${topic}
	table.types = [TABLE]
	trim.sensitive.log = false
 (io.confluent.connect.jdbc.sink.JdbcSinkConfig:372)
[2025-04-13 13:34:07,040] INFO [sink-to-database02|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:34:07,040] INFO [sink-to-database02|task-0] WorkerSinkTask{id=sink-to-database02-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:324)
[2025-04-13 13:34:07,040] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1988)
[2025-04-13 13:34:07,040] INFO [sink-to-database02|task-0] WorkerSinkTask{id=sink-to-database02-0} Executing sink task (org.apache.kafka.connect.runtime.WorkerSinkTask:210)
[2025-04-13 13:34:07,045] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] Cluster ID: PRZJITuEQBeLmWOW7dnIsg (org.apache.kafka.clients.Metadata:364)
[2025-04-13 13:34:07,046] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] Discovered group coordinator localhost:9092 (id: 2147483646 rack: null) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:936)
[2025-04-13 13:34:07,048] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] (Re-)joining group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2025-04-13 13:34:07,055] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] Request joining group due to: need to re-join with the given member-id: connector-consumer-sink-to-database02-0-e57c6e3f-b363-4d71-8ea2-a757a8f5268a (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-04-13 13:34:07,055] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] (Re-)joining group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2025-04-13 13:34:10,056] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] Successfully joined group with generation Generation{generationId=3, memberId='connector-consumer-sink-to-database02-0-e57c6e3f-b363-4d71-8ea2-a757a8f5268a', protocol='range'} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:665)
[2025-04-13 13:34:10,057] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] Finished assignment for group at generation 3: {connector-consumer-sink-to-database02-0-e57c6e3f-b363-4d71-8ea2-a757a8f5268a=Assignment(partitions=[azure-sql-.database01.SalesLT.Product-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:663)
[2025-04-13 13:34:10,059] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] Successfully synced group in generation Generation{generationId=3, memberId='connector-consumer-sink-to-database02-0-e57c6e3f-b363-4d71-8ea2-a757a8f5268a', protocol='range'} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:842)
[2025-04-13 13:34:10,059] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] Notifying assignor about the new Assignment(partitions=[azure-sql-.database01.SalesLT.Product-0]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:323)
[2025-04-13 13:34:10,059] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] Adding newly assigned partitions: azure-sql-.database01.SalesLT.Product-0 (org.apache.kafka.clients.consumer.internals.ConsumerRebalanceListenerInvoker:57)
[2025-04-13 13:34:10,060] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] Found no committed offset for partition azure-sql-.database01.SalesLT.Product-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1506)
[2025-04-13 13:34:10,063] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] Resetting offset for partition azure-sql-.database01.SalesLT.Product-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-04-13 13:34:10,144] INFO [sink-to-database02|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:34:10,206] INFO [sink-to-database02|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:34:10,256] INFO [sink-to-database02|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:34:10,259] WARN [sink-to-database02|task-0] Write of 198 records failed, remainingRetries=10 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:34:10,259] INFO [sink-to-database02|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:34:10,260] INFO [sink-to-database02|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:34:10,260] ERROR [sink-to-database02|task-0] WorkerSinkTask{id=sink-to-database02-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:34:13,260] INFO [sink-to-database02|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:34:13,299] INFO [sink-to-database02|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:34:13,354] INFO [sink-to-database02|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:34:13,356] WARN [sink-to-database02|task-0] Write of 198 records failed, remainingRetries=9 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:34:13,356] INFO [sink-to-database02|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:34:13,357] INFO [sink-to-database02|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:34:13,357] ERROR [sink-to-database02|task-0] WorkerSinkTask{id=sink-to-database02-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:34:15,707] INFO 87.208.3.218 - - [13/Apr/2025:13:34:15 +0000] "GET /connectors/sink-to-database02/status HTTP/1.1" 200 168 "-" "PostmanRuntime/7.43.3" 2 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-04-13 13:34:16,358] INFO [sink-to-database02|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:34:16,398] INFO [sink-to-database02|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:34:16,436] INFO [sink-to-database02|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:34:16,438] WARN [sink-to-database02|task-0] Write of 198 records failed, remainingRetries=8 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:34:16,439] INFO [sink-to-database02|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:34:16,439] INFO [sink-to-database02|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:34:16,439] ERROR [sink-to-database02|task-0] WorkerSinkTask{id=sink-to-database02-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:34:19,440] INFO [sink-to-database02|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:34:19,480] INFO [sink-to-database02|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:34:19,525] INFO [sink-to-database02|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:34:19,527] WARN [sink-to-database02|task-0] Write of 198 records failed, remainingRetries=7 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:34:19,527] INFO [sink-to-database02|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:34:19,528] INFO [sink-to-database02|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:34:19,528] ERROR [sink-to-database02|task-0] WorkerSinkTask{id=sink-to-database02-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:34:22,529] INFO [sink-to-database02|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:34:22,569] INFO [sink-to-database02|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:34:22,615] INFO [sink-to-database02|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:34:22,617] WARN [sink-to-database02|task-0] Write of 198 records failed, remainingRetries=6 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:34:22,617] INFO [sink-to-database02|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:34:22,618] INFO [sink-to-database02|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:34:22,618] ERROR [sink-to-database02|task-0] WorkerSinkTask{id=sink-to-database02-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:34:25,618] INFO [sink-to-database02|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:34:25,657] INFO [sink-to-database02|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:34:25,700] INFO [sink-to-database02|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:34:25,702] WARN [sink-to-database02|task-0] Write of 198 records failed, remainingRetries=5 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:34:25,703] INFO [sink-to-database02|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:34:25,703] INFO [sink-to-database02|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:34:25,703] ERROR [sink-to-database02|task-0] WorkerSinkTask{id=sink-to-database02-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:34:28,704] INFO [sink-to-database02|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:34:28,745] INFO [sink-to-database02|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:34:28,786] INFO [sink-to-database02|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:34:28,789] WARN [sink-to-database02|task-0] Write of 198 records failed, remainingRetries=4 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:34:28,789] INFO [sink-to-database02|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:34:28,790] INFO [sink-to-database02|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:34:28,790] ERROR [sink-to-database02|task-0] WorkerSinkTask{id=sink-to-database02-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:34:31,791] INFO [sink-to-database02|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:34:31,847] INFO [sink-to-database02|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:34:31,883] INFO [sink-to-database02|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:34:31,886] WARN [sink-to-database02|task-0] Write of 198 records failed, remainingRetries=3 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:34:31,886] INFO [sink-to-database02|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:34:31,887] INFO [sink-to-database02|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:34:31,887] ERROR [sink-to-database02|task-0] WorkerSinkTask{id=sink-to-database02-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:34:34,887] INFO [sink-to-database02|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:34:34,932] INFO [sink-to-database02|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:34:34,971] INFO [sink-to-database02|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:34:34,973] WARN [sink-to-database02|task-0] Write of 198 records failed, remainingRetries=2 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:34:34,974] INFO [sink-to-database02|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:34:34,974] INFO [sink-to-database02|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:34:34,974] ERROR [sink-to-database02|task-0] WorkerSinkTask{id=sink-to-database02-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:34:37,974] INFO [sink-to-database02|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:34:38,011] INFO [sink-to-database02|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:34:38,056] INFO [sink-to-database02|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:34:38,063] WARN [sink-to-database02|task-0] Write of 198 records failed, remainingRetries=1 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:34:38,063] INFO [sink-to-database02|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:34:38,063] INFO [sink-to-database02|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:34:38,063] ERROR [sink-to-database02|task-0] WorkerSinkTask{id=sink-to-database02-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:34:39,128] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:372)
[2025-04-13 13:34:39,130] INFO 87.208.3.218 - - [13/Apr/2025:13:34:39 +0000] "POST /connectors HTTP/1.1" 409 74 "-" "PostmanRuntime/7.43.3" 6 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-04-13 13:34:41,064] INFO [sink-to-database02|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:34:41,122] INFO [sink-to-database02|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:34:41,160] INFO [sink-to-database02|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:34:41,162] WARN [sink-to-database02|task-0] Write of 198 records failed, remainingRetries=0 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:34:41,162] ERROR [sink-to-database02|task-0] Failing task after exhausting retries; encountered 1 exceptions on last write attempt. For complete details on each exception, please enable DEBUG logging. (io.confluent.connect.jdbc.sink.JdbcSinkTask:119)
[2025-04-13 13:34:41,162] ERROR [sink-to-database02|task-0] WorkerSinkTask{id=sink-to-database02-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted. Error: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
 (org.apache.kafka.connect.runtime.WorkerSinkTask:633)
org.apache.kafka.connect.errors.ConnectException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:128)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:34:41,162] ERROR [sink-to-database02|task-0] WorkerSinkTask{id=sink-to-database02-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:233)
org.apache.kafka.connect.errors.ConnectException: Exiting WorkerSinkTask due to unrecoverable exception.
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:635)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: org.apache.kafka.connect.errors.ConnectException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:128)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	... 11 more
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:34:41,163] INFO [sink-to-database02|task-0] Stopping task (io.confluent.connect.jdbc.sink.JdbcSinkTask:170)
[2025-04-13 13:34:41,163] INFO [sink-to-database02|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:34:41,163] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] Revoke previously assigned partitions azure-sql-.database01.SalesLT.Product-0 (org.apache.kafka.clients.consumer.internals.ConsumerRebalanceListenerInvoker:79)
[2025-04-13 13:34:41,163] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] The pause flag in partitions [azure-sql-.database01.SalesLT.Product-0] will be removed due to revocation. (org.apache.kafka.clients.consumer.internals.ConsumerRebalanceListenerInvoker:83)
[2025-04-13 13:34:41,163] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] Member connector-consumer-sink-to-database02-0-e57c6e3f-b363-4d71-8ea2-a757a8f5268a sending LeaveGroup request to coordinator localhost:9092 (id: 2147483646 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1173)
[2025-04-13 13:34:41,164] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2025-04-13 13:34:41,164] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-04-13 13:34:41,166] INFO [sink-to-database02|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-04-13 13:34:41,166] INFO [sink-to-database02|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-04-13 13:34:41,166] INFO [sink-to-database02|task-0] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-04-13 13:34:41,166] INFO [sink-to-database02|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-04-13 13:34:41,169] INFO [sink-to-database02|task-0] App info kafka.consumer for connector-consumer-sink-to-database02-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-04-13 13:34:45,013] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:372)
[2025-04-13 13:34:45,018] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Connector sink-to-database03 config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2425)
[2025-04-13 13:34:45,018] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-04-13 13:34:45,019] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-04-13 13:34:45,020] INFO 87.208.3.218 - - [13/Apr/2025:13:34:45 +0000] "POST /connectors HTTP/1.1" 201 595 "-" "PostmanRuntime/7.43.3" 10 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-04-13 13:34:45,020] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=14, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-04-13 13:34:45,023] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=14, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-04-13 13:34:45,023] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Joined group at generation 14 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', leaderUrl='http://10.0.0.4:8083/', offset=18, connectorIds=[sink-to-database03, sink-to-database02, azure-sql-server-source], taskIds=[sink-to-database02-0, azure-sql-server-source-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2621)
[2025-04-13 13:34:45,023] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 18 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1959)
[2025-04-13 13:34:45,023] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Starting connector sink-to-database03 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2077)
[2025-04-13 13:34:45,024] INFO [sink-to-database03|worker] Creating connector sink-to-database03 of type io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:312)
[2025-04-13 13:34:45,024] INFO [sink-to-database03|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-to-database03
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [azure-sql-.database01.SalesLT.Product]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-04-13 13:34:45,024] INFO [sink-to-database03|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-to-database03
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [azure-sql-.database01.SalesLT.Product]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-04-13 13:34:45,024] INFO [sink-to-database03|worker] Instantiated connector sink-to-database03 with version 10.7.0 of type class io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:334)
[2025-04-13 13:34:45,024] INFO [sink-to-database03|worker] Finished creating connector sink-to-database03 (org.apache.kafka.connect.runtime.Worker:355)
[2025-04-13 13:34:45,024] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1988)
[2025-04-13 13:34:45,027] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-to-database03
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [azure-sql-.database01.SalesLT.Product]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-04-13 13:34:45,027] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-to-database03
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [azure-sql-.database01.SalesLT.Product]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-04-13 13:34:45,027] INFO [sink-to-database03|worker] Setting task configurations for 1 workers. (io.confluent.connect.jdbc.JdbcSinkConnector:51)
[2025-04-13 13:34:45,035] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Tasks [sink-to-database03-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2440)
[2025-04-13 13:34:45,036] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-04-13 13:34:45,036] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-04-13 13:34:45,037] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=15, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-04-13 13:34:45,038] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=15, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-04-13 13:34:45,039] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Joined group at generation 15 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', leaderUrl='http://10.0.0.4:8083/', offset=20, connectorIds=[sink-to-database03, sink-to-database02, azure-sql-server-source], taskIds=[sink-to-database03-0, sink-to-database02-0, azure-sql-server-source-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2621)
[2025-04-13 13:34:45,039] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 20 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1959)
[2025-04-13 13:34:45,039] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Starting task sink-to-database03-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2002)
[2025-04-13 13:34:45,039] INFO [sink-to-database03|task-0] Creating task sink-to-database03-0 (org.apache.kafka.connect.runtime.Worker:645)
[2025-04-13 13:34:45,039] INFO [sink-to-database03|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-to-database03
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2025-04-13 13:34:45,039] INFO [sink-to-database03|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-to-database03
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-04-13 13:34:45,040] INFO [sink-to-database03|task-0] TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.sink.JdbcSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2025-04-13 13:34:45,040] INFO [sink-to-database03|task-0] Instantiated task sink-to-database03-0 with version 10.7.0 of type io.confluent.connect.jdbc.sink.JdbcSinkTask (org.apache.kafka.connect.runtime.Worker:664)
[2025-04-13 13:34:45,040] INFO [sink-to-database03|task-0] JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-04-13 13:34:45,040] INFO [sink-to-database03|task-0] Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task sink-to-database03-0 using the worker config (org.apache.kafka.connect.runtime.Worker:677)
[2025-04-13 13:34:45,040] INFO [sink-to-database03|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-04-13 13:34:45,040] INFO [sink-to-database03|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task sink-to-database03-0 using the worker config (org.apache.kafka.connect.runtime.Worker:683)
[2025-04-13 13:34:45,040] INFO [sink-to-database03|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task sink-to-database03-0 using the worker config (org.apache.kafka.connect.runtime.Worker:690)
[2025-04-13 13:34:45,041] INFO [sink-to-database03|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:1794)
[2025-04-13 13:34:45,041] INFO [sink-to-database03|task-0] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-to-database03
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [azure-sql-.database01.SalesLT.Product]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-04-13 13:34:45,041] INFO [sink-to-database03|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-to-database03
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [azure-sql-.database01.SalesLT.Product]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-04-13 13:34:45,041] INFO [sink-to-database03|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-sink-to-database03-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-sink-to-database03
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-04-13 13:34:45,042] INFO [sink-to-database03|task-0] initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-04-13 13:34:45,044] INFO [sink-to-database03|task-0] These configurations '[metrics.context.connect.kafka.cluster.id, metrics.context.connect.group.id]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-04-13 13:34:45,044] INFO [sink-to-database03|task-0] Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-04-13 13:34:45,044] INFO [sink-to-database03|task-0] Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-04-13 13:34:45,044] INFO [sink-to-database03|task-0] Kafka startTimeMs: 1744551285044 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-04-13 13:34:45,045] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1988)
[2025-04-13 13:34:45,045] INFO [sink-to-database03|task-0] [Consumer clientId=connector-consumer-sink-to-database03-0, groupId=connect-sink-to-database03] Subscribed to topic(s): azure-sql-.database01.SalesLT.Product (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:476)
[2025-04-13 13:34:45,045] INFO [sink-to-database03|task-0] Starting JDBC Sink task (io.confluent.connect.jdbc.sink.JdbcSinkTask:51)
[2025-04-13 13:34:45,045] INFO [sink-to-database03|task-0] JdbcSinkConfig values: 
	auto.create = true
	auto.evolve = false
	batch.size = 3000
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlserver://kafkadatabase.database.windows.net:1433;database=database03;encrypt=true;trustServerCertificate=false;hostNameInCertificate=*.database.windows.net;loginTimeout=30;
	connection.user = kafkadmin@kafkadatabase
	db.timezone = UTC
	delete.enabled = false
	dialect.name = 
	fields.whitelist = []
	insert.mode = upsert
	max.retries = 10
	mssql.use.merge.holdlock = true
	pk.fields = [ProductID]
	pk.mode = record_value
	quote.sql.identifiers = ALWAYS
	retry.backoff.ms = 3000
	table.name.format = ${topic}
	table.types = [TABLE]
	trim.sensitive.log = false
 (io.confluent.connect.jdbc.sink.JdbcSinkConfig:372)
[2025-04-13 13:34:45,046] INFO [sink-to-database03|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:34:45,046] INFO [sink-to-database03|task-0] WorkerSinkTask{id=sink-to-database03-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:324)
[2025-04-13 13:34:45,046] INFO [sink-to-database03|task-0] WorkerSinkTask{id=sink-to-database03-0} Executing sink task (org.apache.kafka.connect.runtime.WorkerSinkTask:210)
[2025-04-13 13:34:45,051] INFO [sink-to-database03|task-0] [Consumer clientId=connector-consumer-sink-to-database03-0, groupId=connect-sink-to-database03] Cluster ID: PRZJITuEQBeLmWOW7dnIsg (org.apache.kafka.clients.Metadata:364)
[2025-04-13 13:34:45,052] INFO [sink-to-database03|task-0] [Consumer clientId=connector-consumer-sink-to-database03-0, groupId=connect-sink-to-database03] Discovered group coordinator localhost:9092 (id: 2147483646 rack: null) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:936)
[2025-04-13 13:34:45,053] INFO [sink-to-database03|task-0] [Consumer clientId=connector-consumer-sink-to-database03-0, groupId=connect-sink-to-database03] (Re-)joining group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2025-04-13 13:34:45,055] INFO [sink-to-database03|task-0] [Consumer clientId=connector-consumer-sink-to-database03-0, groupId=connect-sink-to-database03] Request joining group due to: need to re-join with the given member-id: connector-consumer-sink-to-database03-0-82f56663-5ed8-401e-9b6a-6571b6a3e6d8 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-04-13 13:34:45,055] INFO [sink-to-database03|task-0] [Consumer clientId=connector-consumer-sink-to-database03-0, groupId=connect-sink-to-database03] (Re-)joining group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2025-04-13 13:34:48,057] INFO [sink-to-database03|task-0] [Consumer clientId=connector-consumer-sink-to-database03-0, groupId=connect-sink-to-database03] Successfully joined group with generation Generation{generationId=1, memberId='connector-consumer-sink-to-database03-0-82f56663-5ed8-401e-9b6a-6571b6a3e6d8', protocol='range'} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:665)
[2025-04-13 13:34:48,057] INFO [sink-to-database03|task-0] [Consumer clientId=connector-consumer-sink-to-database03-0, groupId=connect-sink-to-database03] Finished assignment for group at generation 1: {connector-consumer-sink-to-database03-0-82f56663-5ed8-401e-9b6a-6571b6a3e6d8=Assignment(partitions=[azure-sql-.database01.SalesLT.Product-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:663)
[2025-04-13 13:34:48,058] INFO [sink-to-database03|task-0] [Consumer clientId=connector-consumer-sink-to-database03-0, groupId=connect-sink-to-database03] Successfully synced group in generation Generation{generationId=1, memberId='connector-consumer-sink-to-database03-0-82f56663-5ed8-401e-9b6a-6571b6a3e6d8', protocol='range'} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:842)
[2025-04-13 13:34:48,059] INFO [sink-to-database03|task-0] [Consumer clientId=connector-consumer-sink-to-database03-0, groupId=connect-sink-to-database03] Notifying assignor about the new Assignment(partitions=[azure-sql-.database01.SalesLT.Product-0]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:323)
[2025-04-13 13:34:48,059] INFO [sink-to-database03|task-0] [Consumer clientId=connector-consumer-sink-to-database03-0, groupId=connect-sink-to-database03] Adding newly assigned partitions: azure-sql-.database01.SalesLT.Product-0 (org.apache.kafka.clients.consumer.internals.ConsumerRebalanceListenerInvoker:57)
[2025-04-13 13:34:48,060] INFO [sink-to-database03|task-0] [Consumer clientId=connector-consumer-sink-to-database03-0, groupId=connect-sink-to-database03] Found no committed offset for partition azure-sql-.database01.SalesLT.Product-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1506)
[2025-04-13 13:34:48,063] INFO [sink-to-database03|task-0] [Consumer clientId=connector-consumer-sink-to-database03-0, groupId=connect-sink-to-database03] Resetting offset for partition azure-sql-.database01.SalesLT.Product-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-04-13 13:34:48,099] INFO [sink-to-database03|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:34:48,154] INFO [sink-to-database03|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:34:48,203] INFO [sink-to-database03|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:34:48,205] WARN [sink-to-database03|task-0] Write of 198 records failed, remainingRetries=10 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:34:48,205] INFO [sink-to-database03|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:34:48,206] INFO [sink-to-database03|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:34:48,206] ERROR [sink-to-database03|task-0] WorkerSinkTask{id=sink-to-database03-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:34:51,207] INFO [sink-to-database03|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:34:51,249] INFO [sink-to-database03|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:34:51,293] INFO [sink-to-database03|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:34:51,294] WARN [sink-to-database03|task-0] Write of 198 records failed, remainingRetries=9 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:34:51,295] INFO [sink-to-database03|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:34:51,295] INFO [sink-to-database03|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:34:51,295] ERROR [sink-to-database03|task-0] WorkerSinkTask{id=sink-to-database03-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:34:54,296] INFO [sink-to-database03|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:34:54,351] INFO [sink-to-database03|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:34:54,387] INFO [sink-to-database03|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:34:54,389] WARN [sink-to-database03|task-0] Write of 198 records failed, remainingRetries=8 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:34:54,389] INFO [sink-to-database03|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:34:54,389] INFO [sink-to-database03|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:34:54,390] ERROR [sink-to-database03|task-0] WorkerSinkTask{id=sink-to-database03-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:34:55,326] INFO 87.208.3.218 - - [13/Apr/2025:13:34:55 +0000] "GET /connectors/sink-to-database03/status HTTP/1.1" 200 168 "-" "PostmanRuntime/7.43.3" 2 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-04-13 13:34:57,390] INFO [sink-to-database03|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:34:57,434] INFO [sink-to-database03|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:34:57,471] INFO [sink-to-database03|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:34:57,473] WARN [sink-to-database03|task-0] Write of 198 records failed, remainingRetries=7 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:34:57,473] INFO [sink-to-database03|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:34:57,473] INFO [sink-to-database03|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:34:57,474] ERROR [sink-to-database03|task-0] WorkerSinkTask{id=sink-to-database03-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:35:00,474] INFO [sink-to-database03|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:35:00,521] INFO [sink-to-database03|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:35:00,558] INFO [sink-to-database03|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:35:00,561] WARN [sink-to-database03|task-0] Write of 198 records failed, remainingRetries=6 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:35:00,561] INFO [sink-to-database03|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:35:00,561] INFO [sink-to-database03|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:35:00,561] ERROR [sink-to-database03|task-0] WorkerSinkTask{id=sink-to-database03-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:35:01,150] INFO 87.208.3.218 - - [13/Apr/2025:13:35:01 +0000] "GET /connectors HTTP/1.1" 200 69 "-" "PostmanRuntime/7.43.3" 3 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-04-13 13:35:03,563] INFO [sink-to-database03|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:35:03,599] INFO [sink-to-database03|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:35:03,641] INFO [sink-to-database03|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:35:03,645] WARN [sink-to-database03|task-0] Write of 198 records failed, remainingRetries=5 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:35:03,645] INFO [sink-to-database03|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:35:03,645] INFO [sink-to-database03|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:35:03,645] ERROR [sink-to-database03|task-0] WorkerSinkTask{id=sink-to-database03-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:35:06,646] INFO [sink-to-database03|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:35:06,693] INFO [sink-to-database03|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:35:06,738] INFO [sink-to-database03|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:35:06,740] WARN [sink-to-database03|task-0] Write of 198 records failed, remainingRetries=4 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:35:06,741] INFO [sink-to-database03|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:35:06,741] INFO [sink-to-database03|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:35:06,741] ERROR [sink-to-database03|task-0] WorkerSinkTask{id=sink-to-database03-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:35:09,742] INFO [sink-to-database03|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:35:09,786] INFO [sink-to-database03|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:35:09,824] INFO [sink-to-database03|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:35:09,826] WARN [sink-to-database03|task-0] Write of 198 records failed, remainingRetries=3 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:35:09,826] INFO [sink-to-database03|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:35:09,826] INFO [sink-to-database03|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:35:09,826] ERROR [sink-to-database03|task-0] WorkerSinkTask{id=sink-to-database03-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:35:12,827] INFO [sink-to-database03|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:35:12,875] INFO [sink-to-database03|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:35:12,911] INFO [sink-to-database03|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:35:12,913] WARN [sink-to-database03|task-0] Write of 198 records failed, remainingRetries=2 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:35:12,913] INFO [sink-to-database03|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:35:12,914] INFO [sink-to-database03|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:35:12,914] ERROR [sink-to-database03|task-0] WorkerSinkTask{id=sink-to-database03-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:35:15,914] INFO [sink-to-database03|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:35:15,948] INFO [sink-to-database03|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:35:15,988] INFO [sink-to-database03|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:35:15,990] WARN [sink-to-database03|task-0] Write of 198 records failed, remainingRetries=1 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:35:15,990] INFO [sink-to-database03|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:35:15,990] INFO [sink-to-database03|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:35:15,990] ERROR [sink-to-database03|task-0] WorkerSinkTask{id=sink-to-database03-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:35:18,992] INFO [sink-to-database03|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:35:19,048] INFO [sink-to-database03|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:35:19,091] INFO [sink-to-database03|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:35:19,092] WARN [sink-to-database03|task-0] Write of 198 records failed, remainingRetries=0 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:35:19,093] ERROR [sink-to-database03|task-0] Failing task after exhausting retries; encountered 1 exceptions on last write attempt. For complete details on each exception, please enable DEBUG logging. (io.confluent.connect.jdbc.sink.JdbcSinkTask:119)
[2025-04-13 13:35:19,093] ERROR [sink-to-database03|task-0] WorkerSinkTask{id=sink-to-database03-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted. Error: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
 (org.apache.kafka.connect.runtime.WorkerSinkTask:633)
org.apache.kafka.connect.errors.ConnectException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:128)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:35:19,093] ERROR [sink-to-database03|task-0] WorkerSinkTask{id=sink-to-database03-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:233)
org.apache.kafka.connect.errors.ConnectException: Exiting WorkerSinkTask due to unrecoverable exception.
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:635)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: org.apache.kafka.connect.errors.ConnectException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:128)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	... 11 more
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:35:19,093] INFO [sink-to-database03|task-0] Stopping task (io.confluent.connect.jdbc.sink.JdbcSinkTask:170)
[2025-04-13 13:35:19,093] INFO [sink-to-database03|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:35:19,094] INFO [sink-to-database03|task-0] [Consumer clientId=connector-consumer-sink-to-database03-0, groupId=connect-sink-to-database03] Revoke previously assigned partitions azure-sql-.database01.SalesLT.Product-0 (org.apache.kafka.clients.consumer.internals.ConsumerRebalanceListenerInvoker:79)
[2025-04-13 13:35:19,094] INFO [sink-to-database03|task-0] [Consumer clientId=connector-consumer-sink-to-database03-0, groupId=connect-sink-to-database03] The pause flag in partitions [azure-sql-.database01.SalesLT.Product-0] will be removed due to revocation. (org.apache.kafka.clients.consumer.internals.ConsumerRebalanceListenerInvoker:83)
[2025-04-13 13:35:19,094] INFO [sink-to-database03|task-0] [Consumer clientId=connector-consumer-sink-to-database03-0, groupId=connect-sink-to-database03] Member connector-consumer-sink-to-database03-0-82f56663-5ed8-401e-9b6a-6571b6a3e6d8 sending LeaveGroup request to coordinator localhost:9092 (id: 2147483646 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1173)
[2025-04-13 13:35:19,094] INFO [sink-to-database03|task-0] [Consumer clientId=connector-consumer-sink-to-database03-0, groupId=connect-sink-to-database03] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2025-04-13 13:35:19,094] INFO [sink-to-database03|task-0] [Consumer clientId=connector-consumer-sink-to-database03-0, groupId=connect-sink-to-database03] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-04-13 13:35:19,096] INFO [sink-to-database03|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-04-13 13:35:19,096] INFO [sink-to-database03|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-04-13 13:35:19,096] INFO [sink-to-database03|task-0] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-04-13 13:35:19,096] INFO [sink-to-database03|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-04-13 13:35:19,098] INFO [sink-to-database03|task-0] App info kafka.consumer for connector-consumer-sink-to-database03-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-04-13 13:36:44,770] INFO [azure-sql-server-source|task-0] 1 records sent during previous 00:12:30.575, last recorded offset of {server=azure-sql-, database=database01} partition is {transaction_id=null, event_serial_no=1, commit_lsn=00000110:00000190:0025, change_lsn=00000110:00000190:0005} (io.debezium.connector.common.BaseSourceTask:213)
[2025-04-13 13:37:09,073] INFO [azure-sql-server-source|task-0|offsets] WorkerSourceTask{id=azure-sql-server-source-0} Committing offsets for 1 acknowledged messages (org.apache.kafka.connect.runtime.WorkerSourceTask:235)
[2025-04-13 13:41:00,290] INFO 87.208.3.218 - - [13/Apr/2025:13:41:00 +0000] "GET /connectors/sink-to-database03/status HTTP/1.1" 200 2167 "-" "PostmanRuntime/7.43.3" 2 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-04-13 13:41:05,696] INFO 87.208.3.218 - - [13/Apr/2025:13:41:05 +0000] "GET /connectors/sink-to-database02/status HTTP/1.1" 200 2167 "-" "PostmanRuntime/7.43.3" 3 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-04-13 13:41:57,423] INFO 87.208.3.218 - - [13/Apr/2025:13:41:57 +0000] "GET /connectors/sink-to-database01/status HTTP/1.1" 404 79 "-" "PostmanRuntime/7.43.3" 3 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-04-13 13:42:07,162] INFO 87.208.3.218 - - [13/Apr/2025:13:42:07 +0000] "GET /connectors/sink-to-database02/status HTTP/1.1" 200 2167 "-" "PostmanRuntime/7.43.3" 3 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-04-13 13:42:16,026] INFO 87.208.3.218 - - [13/Apr/2025:13:42:16 +0000] "GET /connectors/azure-sql-server-source/status HTTP/1.1" 200 175 "-" "PostmanRuntime/7.43.3" 3 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-04-13 13:42:46,096] INFO Successfully processed removal of connector 'sink-to-database02' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1003)
[2025-04-13 13:42:46,096] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Connector sink-to-database02 config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2412)
[2025-04-13 13:42:46,097] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Handling connector-only config update by stopping connector sink-to-database02 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:716)
[2025-04-13 13:42:46,097] INFO [sink-to-database02|worker] Stopping connector sink-to-database02 (org.apache.kafka.connect.runtime.Worker:451)
[2025-04-13 13:42:46,097] INFO [sink-to-database02|worker] Scheduled shutdown for WorkerConnector{id=sink-to-database02} (org.apache.kafka.connect.runtime.WorkerConnector:294)
[2025-04-13 13:42:46,097] INFO 87.208.3.218 - - [13/Apr/2025:13:42:46 +0000] "DELETE /connectors/sink-to-database02/ HTTP/1.1" 204 0 "-" "PostmanRuntime/7.43.3" 7 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-04-13 13:42:46,098] INFO [sink-to-database02|worker] Completed shutdown for WorkerConnector{id=sink-to-database02} (org.apache.kafka.connect.runtime.WorkerConnector:314)
[2025-04-13 13:42:46,098] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-04-13 13:42:46,098] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-04-13 13:42:46,100] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=16, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-04-13 13:42:46,102] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=16, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-04-13 13:42:46,103] INFO [sink-to-database02|worker] Stopping connector sink-to-database02 (org.apache.kafka.connect.runtime.Worker:451)
[2025-04-13 13:42:46,103] INFO [sink-to-database02|task-0] Stopping task sink-to-database02-0 (org.apache.kafka.connect.runtime.Worker:1047)
[2025-04-13 13:42:46,103] WARN [sink-to-database02|worker] Ignoring stop request for unowned connector sink-to-database02 (org.apache.kafka.connect.runtime.Worker:454)
[2025-04-13 13:42:46,103] WARN [sink-to-database02|worker] Ignoring await stop request for non-present connector sink-to-database02 (org.apache.kafka.connect.runtime.Worker:475)
[2025-04-13 13:42:46,104] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2708)
[2025-04-13 13:42:46,106] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2729)
[2025-04-13 13:42:46,106] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Joined group at generation 16 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', leaderUrl='http://10.0.0.4:8083/', offset=22, connectorIds=[sink-to-database03, azure-sql-server-source], taskIds=[sink-to-database03-0, azure-sql-server-source-0], revokedConnectorIds=[sink-to-database02], revokedTaskIds=[sink-to-database02-0], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2621)
[2025-04-13 13:42:46,107] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 22 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1959)
[2025-04-13 13:42:46,107] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1988)
[2025-04-13 13:42:46,107] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-04-13 13:42:46,107] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-04-13 13:42:46,108] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=17, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-04-13 13:42:46,111] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=17, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-04-13 13:42:46,113] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Joined group at generation 17 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', leaderUrl='http://10.0.0.4:8083/', offset=22, connectorIds=[sink-to-database03, azure-sql-server-source], taskIds=[sink-to-database03-0, azure-sql-server-source-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2621)
[2025-04-13 13:42:46,113] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 22 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1959)
[2025-04-13 13:42:46,113] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1988)
[2025-04-13 13:42:51,461] INFO Successfully processed removal of connector 'sink-to-database03' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1003)
[2025-04-13 13:42:51,461] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Connector sink-to-database03 config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2412)
[2025-04-13 13:42:51,464] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Handling connector-only config update by stopping connector sink-to-database03 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:716)
[2025-04-13 13:42:51,465] INFO [sink-to-database03|worker] Stopping connector sink-to-database03 (org.apache.kafka.connect.runtime.Worker:451)
[2025-04-13 13:42:51,465] INFO [sink-to-database03|worker] Scheduled shutdown for WorkerConnector{id=sink-to-database03} (org.apache.kafka.connect.runtime.WorkerConnector:294)
[2025-04-13 13:42:51,465] INFO [sink-to-database03|worker] Completed shutdown for WorkerConnector{id=sink-to-database03} (org.apache.kafka.connect.runtime.WorkerConnector:314)
[2025-04-13 13:42:51,466] INFO 87.208.3.218 - - [13/Apr/2025:13:42:51 +0000] "DELETE /connectors/sink-to-database03/ HTTP/1.1" 204 0 "-" "PostmanRuntime/7.43.3" 9 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-04-13 13:42:51,468] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-04-13 13:42:51,468] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-04-13 13:42:51,469] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=18, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-04-13 13:42:51,471] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=18, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-04-13 13:42:51,471] INFO [sink-to-database03|worker] Stopping connector sink-to-database03 (org.apache.kafka.connect.runtime.Worker:451)
[2025-04-13 13:42:51,472] WARN [sink-to-database03|worker] Ignoring stop request for unowned connector sink-to-database03 (org.apache.kafka.connect.runtime.Worker:454)
[2025-04-13 13:42:51,471] INFO [sink-to-database03|task-0] Stopping task sink-to-database03-0 (org.apache.kafka.connect.runtime.Worker:1047)
[2025-04-13 13:42:51,472] WARN [sink-to-database03|worker] Ignoring await stop request for non-present connector sink-to-database03 (org.apache.kafka.connect.runtime.Worker:475)
[2025-04-13 13:42:51,473] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2708)
[2025-04-13 13:42:51,476] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2729)
[2025-04-13 13:42:51,476] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Joined group at generation 18 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', leaderUrl='http://10.0.0.4:8083/', offset=24, connectorIds=[azure-sql-server-source], taskIds=[azure-sql-server-source-0], revokedConnectorIds=[sink-to-database03], revokedTaskIds=[sink-to-database03-0], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2621)
[2025-04-13 13:42:51,476] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 24 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1959)
[2025-04-13 13:42:51,476] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1988)
[2025-04-13 13:42:51,476] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-04-13 13:42:51,476] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-04-13 13:42:51,480] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=19, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-04-13 13:42:51,484] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=19, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-04-13 13:42:51,485] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Joined group at generation 19 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', leaderUrl='http://10.0.0.4:8083/', offset=24, connectorIds=[azure-sql-server-source], taskIds=[azure-sql-server-source-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2621)
[2025-04-13 13:42:51,485] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 24 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1959)
[2025-04-13 13:42:51,485] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1988)
[2025-04-13 13:42:56,234] INFO 87.208.3.218 - - [13/Apr/2025:13:42:56 +0000] "GET /connectors HTTP/1.1" 200 27 "-" "PostmanRuntime/7.43.3" 3 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-04-13 13:43:09,333] INFO [azure-sql-server-source|task-0] [Producer clientId=azure-sql--schemahistory] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-04-13 13:43:15,353] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:372)
[2025-04-13 13:43:15,358] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Connector sink-to-database02 config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2425)
[2025-04-13 13:43:15,361] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-04-13 13:43:15,361] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-04-13 13:43:15,363] INFO 87.208.3.218 - - [13/Apr/2025:13:43:15 +0000] "POST /connectors HTTP/1.1" 201 595 "-" "PostmanRuntime/7.43.3" 14 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-04-13 13:43:15,363] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=20, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-04-13 13:43:15,365] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=20, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-04-13 13:43:15,365] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Joined group at generation 20 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', leaderUrl='http://10.0.0.4:8083/', offset=25, connectorIds=[sink-to-database02, azure-sql-server-source], taskIds=[azure-sql-server-source-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2621)
[2025-04-13 13:43:15,365] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 25 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1959)
[2025-04-13 13:43:15,366] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Starting connector sink-to-database02 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2077)
[2025-04-13 13:43:15,366] INFO [sink-to-database02|worker] Creating connector sink-to-database02 of type io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:312)
[2025-04-13 13:43:15,366] INFO [sink-to-database02|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-to-database02
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [azure-sql-.database01.SalesLT.Product]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-04-13 13:43:15,366] INFO [sink-to-database02|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-to-database02
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [azure-sql-.database01.SalesLT.Product]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-04-13 13:43:15,366] INFO [sink-to-database02|worker] Instantiated connector sink-to-database02 with version 10.7.0 of type class io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:334)
[2025-04-13 13:43:15,366] INFO [sink-to-database02|worker] Finished creating connector sink-to-database02 (org.apache.kafka.connect.runtime.Worker:355)
[2025-04-13 13:43:15,367] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1988)
[2025-04-13 13:43:15,367] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-to-database02
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [azure-sql-.database01.SalesLT.Product]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-04-13 13:43:15,367] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-to-database02
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [azure-sql-.database01.SalesLT.Product]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-04-13 13:43:15,367] INFO [sink-to-database02|worker] Setting task configurations for 1 workers. (io.confluent.connect.jdbc.JdbcSinkConnector:51)
[2025-04-13 13:43:15,378] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Tasks [sink-to-database02-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2440)
[2025-04-13 13:43:15,379] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-04-13 13:43:15,379] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-04-13 13:43:15,380] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=21, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-04-13 13:43:15,382] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=21, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-04-13 13:43:15,383] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Joined group at generation 21 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', leaderUrl='http://10.0.0.4:8083/', offset=27, connectorIds=[sink-to-database02, azure-sql-server-source], taskIds=[sink-to-database02-0, azure-sql-server-source-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2621)
[2025-04-13 13:43:15,383] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 27 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1959)
[2025-04-13 13:43:15,383] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Starting task sink-to-database02-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2002)
[2025-04-13 13:43:15,385] INFO [sink-to-database02|task-0] Creating task sink-to-database02-0 (org.apache.kafka.connect.runtime.Worker:645)
[2025-04-13 13:43:15,386] INFO [sink-to-database02|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-to-database02
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2025-04-13 13:43:15,386] INFO [sink-to-database02|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-to-database02
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-04-13 13:43:15,386] INFO [sink-to-database02|task-0] TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.sink.JdbcSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2025-04-13 13:43:15,386] INFO [sink-to-database02|task-0] Instantiated task sink-to-database02-0 with version 10.7.0 of type io.confluent.connect.jdbc.sink.JdbcSinkTask (org.apache.kafka.connect.runtime.Worker:664)
[2025-04-13 13:43:15,386] INFO [sink-to-database02|task-0] JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-04-13 13:43:15,386] INFO [sink-to-database02|task-0] Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task sink-to-database02-0 using the worker config (org.apache.kafka.connect.runtime.Worker:677)
[2025-04-13 13:43:15,388] INFO [sink-to-database02|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-04-13 13:43:15,388] INFO [sink-to-database02|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task sink-to-database02-0 using the worker config (org.apache.kafka.connect.runtime.Worker:683)
[2025-04-13 13:43:15,388] INFO [sink-to-database02|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task sink-to-database02-0 using the worker config (org.apache.kafka.connect.runtime.Worker:690)
[2025-04-13 13:43:15,388] INFO [sink-to-database02|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:1794)
[2025-04-13 13:43:15,389] INFO [sink-to-database02|task-0] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-to-database02
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [azure-sql-.database01.SalesLT.Product]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-04-13 13:43:15,389] INFO [sink-to-database02|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-to-database02
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [azure-sql-.database01.SalesLT.Product]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-04-13 13:43:15,390] INFO [sink-to-database02|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-sink-to-database02-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-sink-to-database02
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-04-13 13:43:15,391] INFO [sink-to-database02|task-0] initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-04-13 13:43:15,394] INFO [sink-to-database02|task-0] These configurations '[metrics.context.connect.kafka.cluster.id, metrics.context.connect.group.id]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-04-13 13:43:15,394] INFO [sink-to-database02|task-0] Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-04-13 13:43:15,395] INFO [sink-to-database02|task-0] Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-04-13 13:43:15,395] INFO [sink-to-database02|task-0] Kafka startTimeMs: 1744551795394 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-04-13 13:43:15,396] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] Subscribed to topic(s): azure-sql-.database01.SalesLT.Product (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:476)
[2025-04-13 13:43:15,396] INFO [sink-to-database02|task-0] Starting JDBC Sink task (io.confluent.connect.jdbc.sink.JdbcSinkTask:51)
[2025-04-13 13:43:15,396] INFO [sink-to-database02|task-0] JdbcSinkConfig values: 
	auto.create = true
	auto.evolve = false
	batch.size = 3000
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlserver://kafkadatabase.database.windows.net:1433;database=database02;encrypt=true;trustServerCertificate=false;hostNameInCertificate=*.database.windows.net;loginTimeout=30;
	connection.user = kafkadmin@kafkadatabase
	db.timezone = UTC
	delete.enabled = false
	dialect.name = 
	fields.whitelist = []
	insert.mode = upsert
	max.retries = 10
	mssql.use.merge.holdlock = true
	pk.fields = [ProductID]
	pk.mode = record_value
	quote.sql.identifiers = ALWAYS
	retry.backoff.ms = 3000
	table.name.format = ${topic}
	table.types = [TABLE]
	trim.sensitive.log = false
 (io.confluent.connect.jdbc.sink.JdbcSinkConfig:372)
[2025-04-13 13:43:15,396] INFO [sink-to-database02|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:43:15,396] INFO [sink-to-database02|task-0] WorkerSinkTask{id=sink-to-database02-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:324)
[2025-04-13 13:43:15,396] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1988)
[2025-04-13 13:43:15,398] INFO [sink-to-database02|task-0] WorkerSinkTask{id=sink-to-database02-0} Executing sink task (org.apache.kafka.connect.runtime.WorkerSinkTask:210)
[2025-04-13 13:43:15,404] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] Cluster ID: PRZJITuEQBeLmWOW7dnIsg (org.apache.kafka.clients.Metadata:364)
[2025-04-13 13:43:15,405] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] Discovered group coordinator localhost:9092 (id: 2147483646 rack: null) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:936)
[2025-04-13 13:43:15,406] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] (Re-)joining group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2025-04-13 13:43:15,408] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] Request joining group due to: need to re-join with the given member-id: connector-consumer-sink-to-database02-0-728090de-1024-4dd6-bca2-1c7161637f14 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-04-13 13:43:15,409] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] (Re-)joining group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2025-04-13 13:43:18,411] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] Successfully joined group with generation Generation{generationId=1, memberId='connector-consumer-sink-to-database02-0-728090de-1024-4dd6-bca2-1c7161637f14', protocol='range'} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:665)
[2025-04-13 13:43:18,412] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] Finished assignment for group at generation 1: {connector-consumer-sink-to-database02-0-728090de-1024-4dd6-bca2-1c7161637f14=Assignment(partitions=[azure-sql-.database01.SalesLT.Product-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:663)
[2025-04-13 13:43:18,413] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] Successfully synced group in generation Generation{generationId=1, memberId='connector-consumer-sink-to-database02-0-728090de-1024-4dd6-bca2-1c7161637f14', protocol='range'} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:842)
[2025-04-13 13:43:18,413] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] Notifying assignor about the new Assignment(partitions=[azure-sql-.database01.SalesLT.Product-0]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:323)
[2025-04-13 13:43:18,413] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] Adding newly assigned partitions: azure-sql-.database01.SalesLT.Product-0 (org.apache.kafka.clients.consumer.internals.ConsumerRebalanceListenerInvoker:57)
[2025-04-13 13:43:18,414] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] Found no committed offset for partition azure-sql-.database01.SalesLT.Product-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1506)
[2025-04-13 13:43:18,418] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] Resetting offset for partition azure-sql-.database01.SalesLT.Product-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-04-13 13:43:18,464] INFO [sink-to-database02|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:43:18,518] INFO [sink-to-database02|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:43:18,564] INFO [sink-to-database02|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:43:18,565] WARN [sink-to-database02|task-0] Write of 198 records failed, remainingRetries=10 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:43:18,566] INFO [sink-to-database02|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:43:18,566] INFO [sink-to-database02|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:43:18,566] ERROR [sink-to-database02|task-0] WorkerSinkTask{id=sink-to-database02-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:43:21,566] INFO [sink-to-database02|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:43:21,605] INFO [sink-to-database02|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:43:21,648] INFO [sink-to-database02|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:43:21,651] WARN [sink-to-database02|task-0] Write of 198 records failed, remainingRetries=9 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:43:21,651] INFO [sink-to-database02|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:43:21,651] INFO [sink-to-database02|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:43:21,651] ERROR [sink-to-database02|task-0] WorkerSinkTask{id=sink-to-database02-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:43:24,651] INFO [sink-to-database02|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:43:24,701] INFO [sink-to-database02|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:43:24,739] INFO [sink-to-database02|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:43:24,742] WARN [sink-to-database02|task-0] Write of 198 records failed, remainingRetries=8 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:43:24,742] INFO [sink-to-database02|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:43:24,742] INFO [sink-to-database02|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:43:24,742] ERROR [sink-to-database02|task-0] WorkerSinkTask{id=sink-to-database02-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:43:27,742] INFO [sink-to-database02|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:43:27,783] INFO [sink-to-database02|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:43:27,818] INFO [sink-to-database02|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:43:27,820] WARN [sink-to-database02|task-0] Write of 198 records failed, remainingRetries=7 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:43:27,820] INFO [sink-to-database02|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:43:27,820] INFO [sink-to-database02|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:43:27,821] ERROR [sink-to-database02|task-0] WorkerSinkTask{id=sink-to-database02-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:43:28,100] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:372)
[2025-04-13 13:43:28,102] INFO 87.208.3.218 - - [13/Apr/2025:13:43:28 +0000] "POST /connectors HTTP/1.1" 409 74 "-" "PostmanRuntime/7.43.3" 9 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-04-13 13:43:30,821] INFO [sink-to-database02|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:43:30,876] INFO [sink-to-database02|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:43:30,917] INFO [sink-to-database02|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:43:30,919] WARN [sink-to-database02|task-0] Write of 198 records failed, remainingRetries=6 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:43:30,919] INFO [sink-to-database02|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:43:30,920] INFO [sink-to-database02|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:43:30,920] ERROR [sink-to-database02|task-0] WorkerSinkTask{id=sink-to-database02-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:43:33,920] INFO [sink-to-database02|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:43:33,963] INFO [sink-to-database02|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:43:34,000] INFO [sink-to-database02|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:43:34,002] WARN [sink-to-database02|task-0] Write of 198 records failed, remainingRetries=5 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:43:34,003] INFO [sink-to-database02|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:43:34,003] INFO [sink-to-database02|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:43:34,003] ERROR [sink-to-database02|task-0] WorkerSinkTask{id=sink-to-database02-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:43:34,680] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:372)
[2025-04-13 13:43:34,685] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Connector sink-to-database03 config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2425)
[2025-04-13 13:43:34,685] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-04-13 13:43:34,685] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-04-13 13:43:34,686] INFO 87.208.3.218 - - [13/Apr/2025:13:43:34 +0000] "POST /connectors HTTP/1.1" 201 595 "-" "PostmanRuntime/7.43.3" 9 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-04-13 13:43:34,687] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=22, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-04-13 13:43:34,689] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=22, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-04-13 13:43:34,689] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Joined group at generation 22 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', leaderUrl='http://10.0.0.4:8083/', offset=28, connectorIds=[sink-to-database03, sink-to-database02, azure-sql-server-source], taskIds=[sink-to-database02-0, azure-sql-server-source-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2621)
[2025-04-13 13:43:34,689] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 28 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1959)
[2025-04-13 13:43:34,689] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Starting connector sink-to-database03 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2077)
[2025-04-13 13:43:34,689] INFO [sink-to-database03|worker] Creating connector sink-to-database03 of type io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:312)
[2025-04-13 13:43:34,690] INFO [sink-to-database03|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-to-database03
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [azure-sql-.database01.SalesLT.Product]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-04-13 13:43:34,690] INFO [sink-to-database03|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-to-database03
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [azure-sql-.database01.SalesLT.Product]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-04-13 13:43:34,690] INFO [sink-to-database03|worker] Instantiated connector sink-to-database03 with version 10.7.0 of type class io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:334)
[2025-04-13 13:43:34,690] INFO [sink-to-database03|worker] Finished creating connector sink-to-database03 (org.apache.kafka.connect.runtime.Worker:355)
[2025-04-13 13:43:34,691] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1988)
[2025-04-13 13:43:34,692] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-to-database03
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [azure-sql-.database01.SalesLT.Product]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-04-13 13:43:34,692] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-to-database03
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [azure-sql-.database01.SalesLT.Product]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-04-13 13:43:34,692] INFO [sink-to-database03|worker] Setting task configurations for 1 workers. (io.confluent.connect.jdbc.JdbcSinkConnector:51)
[2025-04-13 13:43:34,710] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Tasks [sink-to-database03-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2440)
[2025-04-13 13:43:34,710] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-04-13 13:43:34,710] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-04-13 13:43:34,713] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=23, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-04-13 13:43:34,716] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=23, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-04-13 13:43:34,716] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Joined group at generation 23 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', leaderUrl='http://10.0.0.4:8083/', offset=30, connectorIds=[sink-to-database03, sink-to-database02, azure-sql-server-source], taskIds=[sink-to-database03-0, sink-to-database02-0, azure-sql-server-source-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2621)
[2025-04-13 13:43:34,716] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 30 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1959)
[2025-04-13 13:43:34,717] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Starting task sink-to-database03-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2002)
[2025-04-13 13:43:34,717] INFO [sink-to-database03|task-0] Creating task sink-to-database03-0 (org.apache.kafka.connect.runtime.Worker:645)
[2025-04-13 13:43:34,717] INFO [sink-to-database03|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-to-database03
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2025-04-13 13:43:34,717] INFO [sink-to-database03|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-to-database03
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-04-13 13:43:34,717] INFO [sink-to-database03|task-0] TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.sink.JdbcSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2025-04-13 13:43:34,718] INFO [sink-to-database03|task-0] Instantiated task sink-to-database03-0 with version 10.7.0 of type io.confluent.connect.jdbc.sink.JdbcSinkTask (org.apache.kafka.connect.runtime.Worker:664)
[2025-04-13 13:43:34,718] INFO [sink-to-database03|task-0] JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-04-13 13:43:34,718] INFO [sink-to-database03|task-0] Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task sink-to-database03-0 using the worker config (org.apache.kafka.connect.runtime.Worker:677)
[2025-04-13 13:43:34,718] INFO [sink-to-database03|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-04-13 13:43:34,718] INFO [sink-to-database03|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task sink-to-database03-0 using the worker config (org.apache.kafka.connect.runtime.Worker:683)
[2025-04-13 13:43:34,718] INFO [sink-to-database03|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task sink-to-database03-0 using the worker config (org.apache.kafka.connect.runtime.Worker:690)
[2025-04-13 13:43:34,718] INFO [sink-to-database03|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:1794)
[2025-04-13 13:43:34,719] INFO [sink-to-database03|task-0] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-to-database03
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [azure-sql-.database01.SalesLT.Product]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-04-13 13:43:34,719] INFO [sink-to-database03|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-to-database03
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [azure-sql-.database01.SalesLT.Product]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-04-13 13:43:34,720] INFO [sink-to-database03|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-sink-to-database03-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-sink-to-database03
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-04-13 13:43:34,721] INFO [sink-to-database03|task-0] initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-04-13 13:43:34,724] INFO [sink-to-database03|task-0] These configurations '[metrics.context.connect.kafka.cluster.id, metrics.context.connect.group.id]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-04-13 13:43:34,724] INFO [sink-to-database03|task-0] Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-04-13 13:43:34,724] INFO [sink-to-database03|task-0] Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-04-13 13:43:34,724] INFO [sink-to-database03|task-0] Kafka startTimeMs: 1744551814724 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-04-13 13:43:34,726] INFO [sink-to-database03|task-0] [Consumer clientId=connector-consumer-sink-to-database03-0, groupId=connect-sink-to-database03] Subscribed to topic(s): azure-sql-.database01.SalesLT.Product (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:476)
[2025-04-13 13:43:34,726] INFO [sink-to-database03|task-0] Starting JDBC Sink task (io.confluent.connect.jdbc.sink.JdbcSinkTask:51)
[2025-04-13 13:43:34,726] INFO [sink-to-database03|task-0] JdbcSinkConfig values: 
	auto.create = true
	auto.evolve = false
	batch.size = 3000
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlserver://kafkadatabase.database.windows.net:1433;database=database03;encrypt=true;trustServerCertificate=false;hostNameInCertificate=*.database.windows.net;loginTimeout=30;
	connection.user = kafkadmin@kafkadatabase
	db.timezone = UTC
	delete.enabled = false
	dialect.name = 
	fields.whitelist = []
	insert.mode = upsert
	max.retries = 10
	mssql.use.merge.holdlock = true
	pk.fields = [ProductID]
	pk.mode = record_value
	quote.sql.identifiers = ALWAYS
	retry.backoff.ms = 3000
	table.name.format = ${topic}
	table.types = [TABLE]
	trim.sensitive.log = false
 (io.confluent.connect.jdbc.sink.JdbcSinkConfig:372)
[2025-04-13 13:43:34,727] INFO [sink-to-database03|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:43:34,727] INFO [sink-to-database03|task-0] WorkerSinkTask{id=sink-to-database03-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:324)
[2025-04-13 13:43:34,727] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1988)
[2025-04-13 13:43:34,728] INFO [sink-to-database03|task-0] WorkerSinkTask{id=sink-to-database03-0} Executing sink task (org.apache.kafka.connect.runtime.WorkerSinkTask:210)
[2025-04-13 13:43:34,735] INFO [sink-to-database03|task-0] [Consumer clientId=connector-consumer-sink-to-database03-0, groupId=connect-sink-to-database03] Cluster ID: PRZJITuEQBeLmWOW7dnIsg (org.apache.kafka.clients.Metadata:364)
[2025-04-13 13:43:34,735] INFO [sink-to-database03|task-0] [Consumer clientId=connector-consumer-sink-to-database03-0, groupId=connect-sink-to-database03] Discovered group coordinator localhost:9092 (id: 2147483646 rack: null) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:936)
[2025-04-13 13:43:34,736] INFO [sink-to-database03|task-0] [Consumer clientId=connector-consumer-sink-to-database03-0, groupId=connect-sink-to-database03] (Re-)joining group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2025-04-13 13:43:34,740] INFO [sink-to-database03|task-0] [Consumer clientId=connector-consumer-sink-to-database03-0, groupId=connect-sink-to-database03] Request joining group due to: need to re-join with the given member-id: connector-consumer-sink-to-database03-0-0efbf40a-7062-430f-8a5c-43390add0972 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-04-13 13:43:34,740] INFO [sink-to-database03|task-0] [Consumer clientId=connector-consumer-sink-to-database03-0, groupId=connect-sink-to-database03] (Re-)joining group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2025-04-13 13:43:37,003] INFO [sink-to-database02|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:43:37,044] INFO [sink-to-database02|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:43:37,089] INFO [sink-to-database02|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:43:37,091] WARN [sink-to-database02|task-0] Write of 198 records failed, remainingRetries=4 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:43:37,091] INFO [sink-to-database02|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:43:37,092] INFO [sink-to-database02|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:43:37,092] ERROR [sink-to-database02|task-0] WorkerSinkTask{id=sink-to-database02-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:43:37,743] INFO [sink-to-database03|task-0] [Consumer clientId=connector-consumer-sink-to-database03-0, groupId=connect-sink-to-database03] Successfully joined group with generation Generation{generationId=1, memberId='connector-consumer-sink-to-database03-0-0efbf40a-7062-430f-8a5c-43390add0972', protocol='range'} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:665)
[2025-04-13 13:43:37,743] INFO [sink-to-database03|task-0] [Consumer clientId=connector-consumer-sink-to-database03-0, groupId=connect-sink-to-database03] Finished assignment for group at generation 1: {connector-consumer-sink-to-database03-0-0efbf40a-7062-430f-8a5c-43390add0972=Assignment(partitions=[azure-sql-.database01.SalesLT.Product-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:663)
[2025-04-13 13:43:37,744] INFO [sink-to-database03|task-0] [Consumer clientId=connector-consumer-sink-to-database03-0, groupId=connect-sink-to-database03] Successfully synced group in generation Generation{generationId=1, memberId='connector-consumer-sink-to-database03-0-0efbf40a-7062-430f-8a5c-43390add0972', protocol='range'} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:842)
[2025-04-13 13:43:37,745] INFO [sink-to-database03|task-0] [Consumer clientId=connector-consumer-sink-to-database03-0, groupId=connect-sink-to-database03] Notifying assignor about the new Assignment(partitions=[azure-sql-.database01.SalesLT.Product-0]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:323)
[2025-04-13 13:43:37,745] INFO [sink-to-database03|task-0] [Consumer clientId=connector-consumer-sink-to-database03-0, groupId=connect-sink-to-database03] Adding newly assigned partitions: azure-sql-.database01.SalesLT.Product-0 (org.apache.kafka.clients.consumer.internals.ConsumerRebalanceListenerInvoker:57)
[2025-04-13 13:43:37,746] INFO [sink-to-database03|task-0] [Consumer clientId=connector-consumer-sink-to-database03-0, groupId=connect-sink-to-database03] Found no committed offset for partition azure-sql-.database01.SalesLT.Product-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1506)
[2025-04-13 13:43:37,754] INFO [sink-to-database03|task-0] [Consumer clientId=connector-consumer-sink-to-database03-0, groupId=connect-sink-to-database03] Resetting offset for partition azure-sql-.database01.SalesLT.Product-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-04-13 13:43:37,790] INFO [sink-to-database03|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:43:37,843] INFO [sink-to-database03|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:43:37,887] INFO [sink-to-database03|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:43:37,889] WARN [sink-to-database03|task-0] Write of 198 records failed, remainingRetries=10 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:43:37,889] INFO [sink-to-database03|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:43:37,889] INFO [sink-to-database03|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:43:37,889] ERROR [sink-to-database03|task-0] WorkerSinkTask{id=sink-to-database03-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:43:39,845] INFO 87.208.3.218 - - [13/Apr/2025:13:43:39 +0000] "GET /connectors/sink-to-database02/status HTTP/1.1" 200 168 "-" "PostmanRuntime/7.43.3" 2 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-04-13 13:43:40,093] INFO [sink-to-database02|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:43:40,128] INFO [sink-to-database02|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:43:40,168] INFO [sink-to-database02|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:43:40,171] WARN [sink-to-database02|task-0] Write of 198 records failed, remainingRetries=3 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:43:40,174] INFO [sink-to-database02|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:43:40,175] INFO [sink-to-database02|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:43:40,175] ERROR [sink-to-database02|task-0] WorkerSinkTask{id=sink-to-database02-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:43:40,890] INFO [sink-to-database03|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:43:40,923] INFO [sink-to-database03|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:43:40,967] INFO [sink-to-database03|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:43:40,968] WARN [sink-to-database03|task-0] Write of 198 records failed, remainingRetries=9 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:43:40,969] INFO [sink-to-database03|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:43:40,969] INFO [sink-to-database03|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:43:40,969] ERROR [sink-to-database03|task-0] WorkerSinkTask{id=sink-to-database03-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:43:43,176] INFO [sink-to-database02|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:43:43,218] INFO [sink-to-database02|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:43:43,261] INFO [sink-to-database02|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:43:43,268] WARN [sink-to-database02|task-0] Write of 198 records failed, remainingRetries=2 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:43:43,269] INFO [sink-to-database02|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:43:43,269] INFO [sink-to-database02|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:43:43,269] ERROR [sink-to-database02|task-0] WorkerSinkTask{id=sink-to-database02-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:43:43,969] INFO [sink-to-database03|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:43:44,002] INFO [sink-to-database03|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:43:44,044] INFO [sink-to-database03|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:43:44,046] WARN [sink-to-database03|task-0] Write of 198 records failed, remainingRetries=8 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:43:44,046] INFO [sink-to-database03|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:43:44,046] INFO [sink-to-database03|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:43:44,046] ERROR [sink-to-database03|task-0] WorkerSinkTask{id=sink-to-database03-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:43:44,955] INFO 87.208.3.218 - - [13/Apr/2025:13:43:44 +0000] "GET /connectors/sink-to-database03/status HTTP/1.1" 200 168 "-" "PostmanRuntime/7.43.3" 2 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-04-13 13:43:46,269] INFO [sink-to-database02|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:43:46,303] INFO [sink-to-database02|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:43:46,357] INFO [sink-to-database02|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:43:46,359] WARN [sink-to-database02|task-0] Write of 198 records failed, remainingRetries=1 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:43:46,359] INFO [sink-to-database02|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:43:46,359] INFO [sink-to-database02|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:43:46,359] ERROR [sink-to-database02|task-0] WorkerSinkTask{id=sink-to-database02-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:43:47,047] INFO [sink-to-database03|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:43:47,098] INFO [sink-to-database03|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:43:47,134] INFO [sink-to-database03|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:43:47,136] WARN [sink-to-database03|task-0] Write of 198 records failed, remainingRetries=7 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:43:47,137] INFO [sink-to-database03|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:43:47,137] INFO [sink-to-database03|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:43:47,137] ERROR [sink-to-database03|task-0] WorkerSinkTask{id=sink-to-database03-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:43:49,361] INFO [sink-to-database02|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:43:49,410] INFO [sink-to-database02|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:43:49,451] INFO [sink-to-database02|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:43:49,455] WARN [sink-to-database02|task-0] Write of 198 records failed, remainingRetries=0 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:43:49,455] ERROR [sink-to-database02|task-0] Failing task after exhausting retries; encountered 1 exceptions on last write attempt. For complete details on each exception, please enable DEBUG logging. (io.confluent.connect.jdbc.sink.JdbcSinkTask:119)
[2025-04-13 13:43:49,455] ERROR [sink-to-database02|task-0] WorkerSinkTask{id=sink-to-database02-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted. Error: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
 (org.apache.kafka.connect.runtime.WorkerSinkTask:633)
org.apache.kafka.connect.errors.ConnectException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:128)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:43:49,456] ERROR [sink-to-database02|task-0] WorkerSinkTask{id=sink-to-database02-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:233)
org.apache.kafka.connect.errors.ConnectException: Exiting WorkerSinkTask due to unrecoverable exception.
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:635)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: org.apache.kafka.connect.errors.ConnectException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:128)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	... 11 more
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:43:49,456] INFO [sink-to-database02|task-0] Stopping task (io.confluent.connect.jdbc.sink.JdbcSinkTask:170)
[2025-04-13 13:43:49,456] INFO [sink-to-database02|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:43:49,456] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] Revoke previously assigned partitions azure-sql-.database01.SalesLT.Product-0 (org.apache.kafka.clients.consumer.internals.ConsumerRebalanceListenerInvoker:79)
[2025-04-13 13:43:49,456] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] The pause flag in partitions [azure-sql-.database01.SalesLT.Product-0] will be removed due to revocation. (org.apache.kafka.clients.consumer.internals.ConsumerRebalanceListenerInvoker:83)
[2025-04-13 13:43:49,456] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] Member connector-consumer-sink-to-database02-0-728090de-1024-4dd6-bca2-1c7161637f14 sending LeaveGroup request to coordinator localhost:9092 (id: 2147483646 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1173)
[2025-04-13 13:43:49,457] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2025-04-13 13:43:49,457] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-04-13 13:43:49,463] INFO [sink-to-database02|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-04-13 13:43:49,463] INFO [sink-to-database02|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-04-13 13:43:49,463] INFO [sink-to-database02|task-0] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-04-13 13:43:49,463] INFO [sink-to-database02|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-04-13 13:43:49,466] INFO [sink-to-database02|task-0] App info kafka.consumer for connector-consumer-sink-to-database02-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-04-13 13:43:50,138] INFO [sink-to-database03|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:43:50,182] INFO [sink-to-database03|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:43:50,215] INFO [sink-to-database03|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:43:50,216] WARN [sink-to-database03|task-0] Write of 198 records failed, remainingRetries=6 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:43:50,217] INFO [sink-to-database03|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:43:50,217] INFO [sink-to-database03|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:43:50,217] ERROR [sink-to-database03|task-0] WorkerSinkTask{id=sink-to-database03-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:43:53,217] INFO [sink-to-database03|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:43:53,270] INFO [sink-to-database03|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:43:53,309] INFO [sink-to-database03|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:43:53,311] WARN [sink-to-database03|task-0] Write of 198 records failed, remainingRetries=5 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:43:53,311] INFO [sink-to-database03|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:43:53,311] INFO [sink-to-database03|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:43:53,311] ERROR [sink-to-database03|task-0] WorkerSinkTask{id=sink-to-database03-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:43:56,311] INFO [sink-to-database03|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:43:56,350] INFO [sink-to-database03|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:43:56,386] INFO [sink-to-database03|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:43:56,388] WARN [sink-to-database03|task-0] Write of 198 records failed, remainingRetries=4 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:43:56,389] INFO [sink-to-database03|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:43:56,389] INFO [sink-to-database03|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:43:56,389] ERROR [sink-to-database03|task-0] WorkerSinkTask{id=sink-to-database03-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:43:59,389] INFO [sink-to-database03|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:43:59,424] INFO [sink-to-database03|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:43:59,469] INFO [sink-to-database03|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:43:59,471] WARN [sink-to-database03|task-0] Write of 198 records failed, remainingRetries=3 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:43:59,472] INFO [sink-to-database03|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:43:59,472] INFO [sink-to-database03|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:43:59,472] ERROR [sink-to-database03|task-0] WorkerSinkTask{id=sink-to-database03-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:44:02,472] INFO [sink-to-database03|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:44:02,511] INFO [sink-to-database03|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:44:02,551] INFO [sink-to-database03|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:44:02,553] WARN [sink-to-database03|task-0] Write of 198 records failed, remainingRetries=2 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:44:02,554] INFO [sink-to-database03|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:44:02,554] INFO [sink-to-database03|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:44:02,554] ERROR [sink-to-database03|task-0] WorkerSinkTask{id=sink-to-database03-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:44:05,554] INFO [sink-to-database03|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:44:05,595] INFO [sink-to-database03|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:44:05,629] INFO [sink-to-database03|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:44:05,631] WARN [sink-to-database03|task-0] Write of 198 records failed, remainingRetries=1 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:44:05,631] INFO [sink-to-database03|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:44:05,631] INFO [sink-to-database03|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:44:05,631] ERROR [sink-to-database03|task-0] WorkerSinkTask{id=sink-to-database03-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:44:08,632] INFO [sink-to-database03|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:44:08,698] INFO [sink-to-database03|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:44:08,742] INFO [sink-to-database03|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:44:08,744] WARN [sink-to-database03|task-0] Write of 198 records failed, remainingRetries=0 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:44:08,744] ERROR [sink-to-database03|task-0] Failing task after exhausting retries; encountered 1 exceptions on last write attempt. For complete details on each exception, please enable DEBUG logging. (io.confluent.connect.jdbc.sink.JdbcSinkTask:119)
[2025-04-13 13:44:08,744] ERROR [sink-to-database03|task-0] WorkerSinkTask{id=sink-to-database03-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted. Error: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
 (org.apache.kafka.connect.runtime.WorkerSinkTask:633)
org.apache.kafka.connect.errors.ConnectException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:128)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:44:08,744] ERROR [sink-to-database03|task-0] WorkerSinkTask{id=sink-to-database03-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:233)
org.apache.kafka.connect.errors.ConnectException: Exiting WorkerSinkTask due to unrecoverable exception.
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:635)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: org.apache.kafka.connect.errors.ConnectException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:128)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	... 11 more
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:44:08,744] INFO [sink-to-database03|task-0] Stopping task (io.confluent.connect.jdbc.sink.JdbcSinkTask:170)
[2025-04-13 13:44:08,744] INFO [sink-to-database03|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:44:08,745] INFO [sink-to-database03|task-0] [Consumer clientId=connector-consumer-sink-to-database03-0, groupId=connect-sink-to-database03] Revoke previously assigned partitions azure-sql-.database01.SalesLT.Product-0 (org.apache.kafka.clients.consumer.internals.ConsumerRebalanceListenerInvoker:79)
[2025-04-13 13:44:08,745] INFO [sink-to-database03|task-0] [Consumer clientId=connector-consumer-sink-to-database03-0, groupId=connect-sink-to-database03] The pause flag in partitions [azure-sql-.database01.SalesLT.Product-0] will be removed due to revocation. (org.apache.kafka.clients.consumer.internals.ConsumerRebalanceListenerInvoker:83)
[2025-04-13 13:44:08,745] INFO [sink-to-database03|task-0] [Consumer clientId=connector-consumer-sink-to-database03-0, groupId=connect-sink-to-database03] Member connector-consumer-sink-to-database03-0-0efbf40a-7062-430f-8a5c-43390add0972 sending LeaveGroup request to coordinator localhost:9092 (id: 2147483646 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1173)
[2025-04-13 13:44:08,745] INFO [sink-to-database03|task-0] [Consumer clientId=connector-consumer-sink-to-database03-0, groupId=connect-sink-to-database03] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2025-04-13 13:44:08,745] INFO [sink-to-database03|task-0] [Consumer clientId=connector-consumer-sink-to-database03-0, groupId=connect-sink-to-database03] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-04-13 13:44:08,750] INFO [sink-to-database03|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-04-13 13:44:08,750] INFO [sink-to-database03|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-04-13 13:44:08,750] INFO [sink-to-database03|task-0] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-04-13 13:44:08,750] INFO [sink-to-database03|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-04-13 13:44:08,752] INFO [sink-to-database03|task-0] App info kafka.consumer for connector-consumer-sink-to-database03-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-04-13 13:45:24,680] INFO 87.208.3.218 - - [13/Apr/2025:13:45:24 +0000] "GET /connectors/sink-to-database03/status HTTP/1.1" 200 2167 "-" "PostmanRuntime/7.43.3" 2 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-04-13 13:46:09,080] INFO [azure-sql-server-source|task-0|offsets] WorkerSourceTask{id=azure-sql-server-source-0} Committing offsets for 1 acknowledged messages (org.apache.kafka.connect.runtime.WorkerSourceTask:235)
[2025-04-13 13:51:15,282] INFO Successfully processed removal of connector 'sink-to-database03' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1003)
[2025-04-13 13:51:15,282] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Connector sink-to-database03 config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2412)
[2025-04-13 13:51:15,282] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Handling connector-only config update by stopping connector sink-to-database03 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:716)
[2025-04-13 13:51:15,282] INFO [sink-to-database03|worker] Stopping connector sink-to-database03 (org.apache.kafka.connect.runtime.Worker:451)
[2025-04-13 13:51:15,282] INFO [sink-to-database03|worker] Scheduled shutdown for WorkerConnector{id=sink-to-database03} (org.apache.kafka.connect.runtime.WorkerConnector:294)
[2025-04-13 13:51:15,282] INFO [sink-to-database03|worker] Completed shutdown for WorkerConnector{id=sink-to-database03} (org.apache.kafka.connect.runtime.WorkerConnector:314)
[2025-04-13 13:51:15,283] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-04-13 13:51:15,283] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-04-13 13:51:15,283] INFO 87.208.3.218 - - [13/Apr/2025:13:51:15 +0000] "DELETE /connectors/sink-to-database03/ HTTP/1.1" 204 0 "-" "PostmanRuntime/7.43.3" 8 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-04-13 13:51:15,285] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=24, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-04-13 13:51:15,287] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=24, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-04-13 13:51:15,287] INFO [sink-to-database03|worker] Stopping connector sink-to-database03 (org.apache.kafka.connect.runtime.Worker:451)
[2025-04-13 13:51:15,288] WARN [sink-to-database03|worker] Ignoring stop request for unowned connector sink-to-database03 (org.apache.kafka.connect.runtime.Worker:454)
[2025-04-13 13:51:15,288] WARN [sink-to-database03|worker] Ignoring await stop request for non-present connector sink-to-database03 (org.apache.kafka.connect.runtime.Worker:475)
[2025-04-13 13:51:15,288] INFO [sink-to-database03|task-0] Stopping task sink-to-database03-0 (org.apache.kafka.connect.runtime.Worker:1047)
[2025-04-13 13:51:15,289] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2708)
[2025-04-13 13:51:15,290] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2729)
[2025-04-13 13:51:15,290] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Joined group at generation 24 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', leaderUrl='http://10.0.0.4:8083/', offset=32, connectorIds=[sink-to-database02, azure-sql-server-source], taskIds=[sink-to-database02-0, azure-sql-server-source-0], revokedConnectorIds=[sink-to-database03], revokedTaskIds=[sink-to-database03-0], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2621)
[2025-04-13 13:51:15,292] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 32 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1959)
[2025-04-13 13:51:15,292] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1988)
[2025-04-13 13:51:15,292] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-04-13 13:51:15,292] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-04-13 13:51:15,294] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=25, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-04-13 13:51:15,296] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=25, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-04-13 13:51:15,296] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Joined group at generation 25 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', leaderUrl='http://10.0.0.4:8083/', offset=32, connectorIds=[sink-to-database02, azure-sql-server-source], taskIds=[sink-to-database02-0, azure-sql-server-source-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2621)
[2025-04-13 13:51:15,296] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 32 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1959)
[2025-04-13 13:51:15,297] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1988)
[2025-04-13 13:51:19,083] INFO Successfully processed removal of connector 'sink-to-database02' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1003)
[2025-04-13 13:51:19,083] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Connector sink-to-database02 config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2412)
[2025-04-13 13:51:19,083] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Handling connector-only config update by stopping connector sink-to-database02 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:716)
[2025-04-13 13:51:19,083] INFO [sink-to-database02|worker] Stopping connector sink-to-database02 (org.apache.kafka.connect.runtime.Worker:451)
[2025-04-13 13:51:19,083] INFO [sink-to-database02|worker] Scheduled shutdown for WorkerConnector{id=sink-to-database02} (org.apache.kafka.connect.runtime.WorkerConnector:294)
[2025-04-13 13:51:19,083] INFO [sink-to-database02|worker] Completed shutdown for WorkerConnector{id=sink-to-database02} (org.apache.kafka.connect.runtime.WorkerConnector:314)
[2025-04-13 13:51:19,084] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-04-13 13:51:19,084] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-04-13 13:51:19,084] INFO 87.208.3.218 - - [13/Apr/2025:13:51:19 +0000] "DELETE /connectors/sink-to-database02/ HTTP/1.1" 204 0 "-" "PostmanRuntime/7.43.3" 7 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-04-13 13:51:19,085] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=26, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-04-13 13:51:19,088] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=26, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-04-13 13:51:19,088] INFO [sink-to-database02|worker] Stopping connector sink-to-database02 (org.apache.kafka.connect.runtime.Worker:451)
[2025-04-13 13:51:19,088] WARN [sink-to-database02|worker] Ignoring stop request for unowned connector sink-to-database02 (org.apache.kafka.connect.runtime.Worker:454)
[2025-04-13 13:51:19,088] WARN [sink-to-database02|worker] Ignoring await stop request for non-present connector sink-to-database02 (org.apache.kafka.connect.runtime.Worker:475)
[2025-04-13 13:51:19,089] INFO [sink-to-database02|task-0] Stopping task sink-to-database02-0 (org.apache.kafka.connect.runtime.Worker:1047)
[2025-04-13 13:51:19,089] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2708)
[2025-04-13 13:51:19,092] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2729)
[2025-04-13 13:51:19,092] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Joined group at generation 26 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', leaderUrl='http://10.0.0.4:8083/', offset=34, connectorIds=[azure-sql-server-source], taskIds=[azure-sql-server-source-0], revokedConnectorIds=[sink-to-database02], revokedTaskIds=[sink-to-database02-0], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2621)
[2025-04-13 13:51:19,092] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 34 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1959)
[2025-04-13 13:51:19,092] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1988)
[2025-04-13 13:51:19,092] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-04-13 13:51:19,092] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-04-13 13:51:19,096] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=27, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-04-13 13:51:19,098] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=27, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-04-13 13:51:19,099] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Joined group at generation 27 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', leaderUrl='http://10.0.0.4:8083/', offset=34, connectorIds=[azure-sql-server-source], taskIds=[azure-sql-server-source-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2621)
[2025-04-13 13:51:19,099] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 34 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1959)
[2025-04-13 13:51:19,099] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1988)
[2025-04-13 13:51:23,306] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:372)
[2025-04-13 13:51:23,311] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Connector sink-to-database03 config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2425)
[2025-04-13 13:51:23,311] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-04-13 13:51:23,311] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-04-13 13:51:23,312] INFO 87.208.3.218 - - [13/Apr/2025:13:51:23 +0000] "POST /connectors HTTP/1.1" 201 599 "-" "PostmanRuntime/7.43.3" 9 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-04-13 13:51:23,313] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=28, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-04-13 13:51:23,315] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=28, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-04-13 13:51:23,315] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Joined group at generation 28 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', leaderUrl='http://10.0.0.4:8083/', offset=35, connectorIds=[sink-to-database03, azure-sql-server-source], taskIds=[azure-sql-server-source-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2621)
[2025-04-13 13:51:23,315] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 35 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1959)
[2025-04-13 13:51:23,315] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Starting connector sink-to-database03 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2077)
[2025-04-13 13:51:23,315] INFO [sink-to-database03|worker] Creating connector sink-to-database03 of type io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:312)
[2025-04-13 13:51:23,316] INFO [sink-to-database03|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-to-database03
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [azure-sql-.database01.SalesLT.Product]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-04-13 13:51:23,316] INFO [sink-to-database03|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-to-database03
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [azure-sql-.database01.SalesLT.Product]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-04-13 13:51:23,316] INFO [sink-to-database03|worker] Instantiated connector sink-to-database03 with version 10.7.0 of type class io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:334)
[2025-04-13 13:51:23,316] INFO [sink-to-database03|worker] Finished creating connector sink-to-database03 (org.apache.kafka.connect.runtime.Worker:355)
[2025-04-13 13:51:23,316] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1988)
[2025-04-13 13:51:23,317] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-to-database03
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [azure-sql-.database01.SalesLT.Product]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-04-13 13:51:23,317] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-to-database03
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [azure-sql-.database01.SalesLT.Product]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-04-13 13:51:23,317] INFO [sink-to-database03|worker] Setting task configurations for 1 workers. (io.confluent.connect.jdbc.JdbcSinkConnector:51)
[2025-04-13 13:51:23,327] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Tasks [sink-to-database03-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2440)
[2025-04-13 13:51:23,328] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-04-13 13:51:23,328] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-04-13 13:51:23,330] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=29, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-04-13 13:51:23,332] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=29, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-04-13 13:51:23,332] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Joined group at generation 29 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', leaderUrl='http://10.0.0.4:8083/', offset=37, connectorIds=[sink-to-database03, azure-sql-server-source], taskIds=[sink-to-database03-0, azure-sql-server-source-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2621)
[2025-04-13 13:51:23,332] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 37 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1959)
[2025-04-13 13:51:23,332] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Starting task sink-to-database03-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2002)
[2025-04-13 13:51:23,332] INFO [sink-to-database03|task-0] Creating task sink-to-database03-0 (org.apache.kafka.connect.runtime.Worker:645)
[2025-04-13 13:51:23,332] INFO [sink-to-database03|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-to-database03
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2025-04-13 13:51:23,333] INFO [sink-to-database03|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-to-database03
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-04-13 13:51:23,333] INFO [sink-to-database03|task-0] TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.sink.JdbcSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2025-04-13 13:51:23,333] INFO [sink-to-database03|task-0] Instantiated task sink-to-database03-0 with version 10.7.0 of type io.confluent.connect.jdbc.sink.JdbcSinkTask (org.apache.kafka.connect.runtime.Worker:664)
[2025-04-13 13:51:23,333] INFO [sink-to-database03|task-0] JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-04-13 13:51:23,333] INFO [sink-to-database03|task-0] Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task sink-to-database03-0 using the worker config (org.apache.kafka.connect.runtime.Worker:677)
[2025-04-13 13:51:23,333] INFO [sink-to-database03|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-04-13 13:51:23,333] INFO [sink-to-database03|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task sink-to-database03-0 using the worker config (org.apache.kafka.connect.runtime.Worker:683)
[2025-04-13 13:51:23,333] INFO [sink-to-database03|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task sink-to-database03-0 using the worker config (org.apache.kafka.connect.runtime.Worker:690)
[2025-04-13 13:51:23,334] INFO [sink-to-database03|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:1794)
[2025-04-13 13:51:23,334] INFO [sink-to-database03|task-0] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-to-database03
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [azure-sql-.database01.SalesLT.Product]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-04-13 13:51:23,334] INFO [sink-to-database03|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-to-database03
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [azure-sql-.database01.SalesLT.Product]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-04-13 13:51:23,336] INFO [sink-to-database03|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-sink-to-database03-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-sink-to-database03
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-04-13 13:51:23,336] INFO [sink-to-database03|task-0] initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-04-13 13:51:23,338] INFO [sink-to-database03|task-0] These configurations '[metrics.context.connect.kafka.cluster.id, metrics.context.connect.group.id]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-04-13 13:51:23,338] INFO [sink-to-database03|task-0] Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-04-13 13:51:23,338] INFO [sink-to-database03|task-0] Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-04-13 13:51:23,338] INFO [sink-to-database03|task-0] Kafka startTimeMs: 1744552283338 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-04-13 13:51:23,339] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1988)
[2025-04-13 13:51:23,340] INFO [sink-to-database03|task-0] [Consumer clientId=connector-consumer-sink-to-database03-0, groupId=connect-sink-to-database03] Subscribed to topic(s): azure-sql-.database01.SalesLT.Product (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:476)
[2025-04-13 13:51:23,340] INFO [sink-to-database03|task-0] Starting JDBC Sink task (io.confluent.connect.jdbc.sink.JdbcSinkTask:51)
[2025-04-13 13:51:23,340] INFO [sink-to-database03|task-0] JdbcSinkConfig values: 
	auto.create = true
	auto.evolve = false
	batch.size = 3000
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlserver://kafkadatabase.database.windows.net:1433;databaseName=database03;encrypt=true;trustServerCertificate=false;hostNameInCertificate=*.database.windows.net;loginTimeout=30;
	connection.user = kafkadmin@kafkadatabase
	db.timezone = UTC
	delete.enabled = false
	dialect.name = 
	fields.whitelist = []
	insert.mode = upsert
	max.retries = 10
	mssql.use.merge.holdlock = true
	pk.fields = [ProductID]
	pk.mode = record_value
	quote.sql.identifiers = ALWAYS
	retry.backoff.ms = 3000
	table.name.format = ${topic}
	table.types = [TABLE]
	trim.sensitive.log = false
 (io.confluent.connect.jdbc.sink.JdbcSinkConfig:372)
[2025-04-13 13:51:23,340] INFO [sink-to-database03|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:51:23,340] INFO [sink-to-database03|task-0] WorkerSinkTask{id=sink-to-database03-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:324)
[2025-04-13 13:51:23,341] INFO [sink-to-database03|task-0] WorkerSinkTask{id=sink-to-database03-0} Executing sink task (org.apache.kafka.connect.runtime.WorkerSinkTask:210)
[2025-04-13 13:51:23,349] INFO [sink-to-database03|task-0] [Consumer clientId=connector-consumer-sink-to-database03-0, groupId=connect-sink-to-database03] Cluster ID: PRZJITuEQBeLmWOW7dnIsg (org.apache.kafka.clients.Metadata:364)
[2025-04-13 13:51:23,350] INFO [sink-to-database03|task-0] [Consumer clientId=connector-consumer-sink-to-database03-0, groupId=connect-sink-to-database03] Discovered group coordinator localhost:9092 (id: 2147483646 rack: null) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:936)
[2025-04-13 13:51:23,352] INFO [sink-to-database03|task-0] [Consumer clientId=connector-consumer-sink-to-database03-0, groupId=connect-sink-to-database03] (Re-)joining group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2025-04-13 13:51:23,356] INFO [sink-to-database03|task-0] [Consumer clientId=connector-consumer-sink-to-database03-0, groupId=connect-sink-to-database03] Request joining group due to: need to re-join with the given member-id: connector-consumer-sink-to-database03-0-440ae676-2531-45f8-937f-c42c790c8929 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-04-13 13:51:23,357] INFO [sink-to-database03|task-0] [Consumer clientId=connector-consumer-sink-to-database03-0, groupId=connect-sink-to-database03] (Re-)joining group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2025-04-13 13:51:26,358] INFO [sink-to-database03|task-0] [Consumer clientId=connector-consumer-sink-to-database03-0, groupId=connect-sink-to-database03] Successfully joined group with generation Generation{generationId=1, memberId='connector-consumer-sink-to-database03-0-440ae676-2531-45f8-937f-c42c790c8929', protocol='range'} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:665)
[2025-04-13 13:51:26,359] INFO [sink-to-database03|task-0] [Consumer clientId=connector-consumer-sink-to-database03-0, groupId=connect-sink-to-database03] Finished assignment for group at generation 1: {connector-consumer-sink-to-database03-0-440ae676-2531-45f8-937f-c42c790c8929=Assignment(partitions=[azure-sql-.database01.SalesLT.Product-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:663)
[2025-04-13 13:51:26,360] INFO [sink-to-database03|task-0] [Consumer clientId=connector-consumer-sink-to-database03-0, groupId=connect-sink-to-database03] Successfully synced group in generation Generation{generationId=1, memberId='connector-consumer-sink-to-database03-0-440ae676-2531-45f8-937f-c42c790c8929', protocol='range'} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:842)
[2025-04-13 13:51:26,360] INFO [sink-to-database03|task-0] [Consumer clientId=connector-consumer-sink-to-database03-0, groupId=connect-sink-to-database03] Notifying assignor about the new Assignment(partitions=[azure-sql-.database01.SalesLT.Product-0]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:323)
[2025-04-13 13:51:26,361] INFO [sink-to-database03|task-0] [Consumer clientId=connector-consumer-sink-to-database03-0, groupId=connect-sink-to-database03] Adding newly assigned partitions: azure-sql-.database01.SalesLT.Product-0 (org.apache.kafka.clients.consumer.internals.ConsumerRebalanceListenerInvoker:57)
[2025-04-13 13:51:26,361] INFO [sink-to-database03|task-0] [Consumer clientId=connector-consumer-sink-to-database03-0, groupId=connect-sink-to-database03] Found no committed offset for partition azure-sql-.database01.SalesLT.Product-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1506)
[2025-04-13 13:51:26,364] INFO [sink-to-database03|task-0] [Consumer clientId=connector-consumer-sink-to-database03-0, groupId=connect-sink-to-database03] Resetting offset for partition azure-sql-.database01.SalesLT.Product-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-04-13 13:51:26,402] INFO [sink-to-database03|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:51:26,466] INFO [sink-to-database03|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:51:26,500] INFO [sink-to-database03|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:51:26,501] WARN [sink-to-database03|task-0] Write of 198 records failed, remainingRetries=10 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:51:26,502] INFO [sink-to-database03|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:51:26,502] INFO [sink-to-database03|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:51:26,504] ERROR [sink-to-database03|task-0] WorkerSinkTask{id=sink-to-database03-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:51:29,504] INFO [sink-to-database03|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:51:29,541] INFO [sink-to-database03|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:51:29,579] INFO [sink-to-database03|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:51:29,581] WARN [sink-to-database03|task-0] Write of 198 records failed, remainingRetries=9 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:51:29,581] INFO [sink-to-database03|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:51:29,581] INFO [sink-to-database03|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:51:29,581] ERROR [sink-to-database03|task-0] WorkerSinkTask{id=sink-to-database03-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:51:31,113] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:372)
[2025-04-13 13:51:31,116] INFO 87.208.3.218 - - [13/Apr/2025:13:51:31 +0000] "POST /connectors HTTP/1.1" 409 74 "-" "PostmanRuntime/7.43.3" 6 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-04-13 13:51:32,581] INFO [sink-to-database03|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:51:32,617] INFO [sink-to-database03|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:51:32,654] INFO [sink-to-database03|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:51:32,656] WARN [sink-to-database03|task-0] Write of 198 records failed, remainingRetries=8 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:51:32,657] INFO [sink-to-database03|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:51:32,657] INFO [sink-to-database03|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:51:32,657] ERROR [sink-to-database03|task-0] WorkerSinkTask{id=sink-to-database03-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:51:35,658] INFO [sink-to-database03|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:51:35,698] INFO [sink-to-database03|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:51:35,733] INFO [sink-to-database03|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:51:35,735] WARN [sink-to-database03|task-0] Write of 198 records failed, remainingRetries=7 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:51:35,735] INFO [sink-to-database03|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:51:35,736] INFO [sink-to-database03|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:51:35,736] ERROR [sink-to-database03|task-0] WorkerSinkTask{id=sink-to-database03-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:51:37,479] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:372)
[2025-04-13 13:51:37,483] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Connector sink-to-database02 config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2425)
[2025-04-13 13:51:37,484] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-04-13 13:51:37,484] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-04-13 13:51:37,485] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=30, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-04-13 13:51:37,487] INFO 87.208.3.218 - - [13/Apr/2025:13:51:37 +0000] "POST /connectors HTTP/1.1" 201 599 "-" "PostmanRuntime/7.43.3" 10 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-04-13 13:51:37,488] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=30, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-04-13 13:51:37,489] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Joined group at generation 30 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', leaderUrl='http://10.0.0.4:8083/', offset=38, connectorIds=[sink-to-database02, sink-to-database03, azure-sql-server-source], taskIds=[sink-to-database03-0, azure-sql-server-source-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2621)
[2025-04-13 13:51:37,489] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 38 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1959)
[2025-04-13 13:51:37,489] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Starting connector sink-to-database02 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2077)
[2025-04-13 13:51:37,489] INFO [sink-to-database02|worker] Creating connector sink-to-database02 of type io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:312)
[2025-04-13 13:51:37,489] INFO [sink-to-database02|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-to-database02
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [azure-sql-.database01.SalesLT.Product]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-04-13 13:51:37,489] INFO [sink-to-database02|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-to-database02
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [azure-sql-.database01.SalesLT.Product]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-04-13 13:51:37,490] INFO [sink-to-database02|worker] Instantiated connector sink-to-database02 with version 10.7.0 of type class io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:334)
[2025-04-13 13:51:37,492] INFO [sink-to-database02|worker] Finished creating connector sink-to-database02 (org.apache.kafka.connect.runtime.Worker:355)
[2025-04-13 13:51:37,493] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1988)
[2025-04-13 13:51:37,493] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-to-database02
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [azure-sql-.database01.SalesLT.Product]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-04-13 13:51:37,493] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-to-database02
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [azure-sql-.database01.SalesLT.Product]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-04-13 13:51:37,493] INFO [sink-to-database02|worker] Setting task configurations for 1 workers. (io.confluent.connect.jdbc.JdbcSinkConnector:51)
[2025-04-13 13:51:37,501] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Tasks [sink-to-database02-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2440)
[2025-04-13 13:51:37,501] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-04-13 13:51:37,501] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-04-13 13:51:37,503] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=31, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-04-13 13:51:37,504] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=31, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-04-13 13:51:37,504] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Joined group at generation 31 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', leaderUrl='http://10.0.0.4:8083/', offset=40, connectorIds=[sink-to-database02, sink-to-database03, azure-sql-server-source], taskIds=[sink-to-database02-0, sink-to-database03-0, azure-sql-server-source-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2621)
[2025-04-13 13:51:37,504] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 40 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1959)
[2025-04-13 13:51:37,504] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Starting task sink-to-database02-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2002)
[2025-04-13 13:51:37,505] INFO [sink-to-database02|task-0] Creating task sink-to-database02-0 (org.apache.kafka.connect.runtime.Worker:645)
[2025-04-13 13:51:37,505] INFO [sink-to-database02|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-to-database02
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2025-04-13 13:51:37,505] INFO [sink-to-database02|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-to-database02
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-04-13 13:51:37,505] INFO [sink-to-database02|task-0] TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.sink.JdbcSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2025-04-13 13:51:37,505] INFO [sink-to-database02|task-0] Instantiated task sink-to-database02-0 with version 10.7.0 of type io.confluent.connect.jdbc.sink.JdbcSinkTask (org.apache.kafka.connect.runtime.Worker:664)
[2025-04-13 13:51:37,506] INFO [sink-to-database02|task-0] JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-04-13 13:51:37,506] INFO [sink-to-database02|task-0] Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task sink-to-database02-0 using the worker config (org.apache.kafka.connect.runtime.Worker:677)
[2025-04-13 13:51:37,506] INFO [sink-to-database02|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-04-13 13:51:37,506] INFO [sink-to-database02|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task sink-to-database02-0 using the worker config (org.apache.kafka.connect.runtime.Worker:683)
[2025-04-13 13:51:37,506] INFO [sink-to-database02|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task sink-to-database02-0 using the worker config (org.apache.kafka.connect.runtime.Worker:690)
[2025-04-13 13:51:37,506] INFO [sink-to-database02|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:1794)
[2025-04-13 13:51:37,506] INFO [sink-to-database02|task-0] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-to-database02
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [azure-sql-.database01.SalesLT.Product]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-04-13 13:51:37,506] INFO [sink-to-database02|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-to-database02
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [azure-sql-.database01.SalesLT.Product]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-04-13 13:51:37,507] INFO [sink-to-database02|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-sink-to-database02-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-sink-to-database02
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-04-13 13:51:37,507] INFO [sink-to-database02|task-0] initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-04-13 13:51:37,509] INFO [sink-to-database02|task-0] These configurations '[metrics.context.connect.kafka.cluster.id, metrics.context.connect.group.id]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-04-13 13:51:37,509] INFO [sink-to-database02|task-0] Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-04-13 13:51:37,509] INFO [sink-to-database02|task-0] Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-04-13 13:51:37,509] INFO [sink-to-database02|task-0] Kafka startTimeMs: 1744552297509 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-04-13 13:51:37,510] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] Subscribed to topic(s): azure-sql-.database01.SalesLT.Product (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:476)
[2025-04-13 13:51:37,510] INFO [sink-to-database02|task-0] Starting JDBC Sink task (io.confluent.connect.jdbc.sink.JdbcSinkTask:51)
[2025-04-13 13:51:37,510] INFO [sink-to-database02|task-0] JdbcSinkConfig values: 
	auto.create = true
	auto.evolve = false
	batch.size = 3000
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlserver://kafkadatabase.database.windows.net:1433;databaseName=database02;encrypt=true;trustServerCertificate=false;hostNameInCertificate=*.database.windows.net;loginTimeout=30;
	connection.user = kafkadmin@kafkadatabase
	db.timezone = UTC
	delete.enabled = false
	dialect.name = 
	fields.whitelist = []
	insert.mode = upsert
	max.retries = 10
	mssql.use.merge.holdlock = true
	pk.fields = [ProductID]
	pk.mode = record_value
	quote.sql.identifiers = ALWAYS
	retry.backoff.ms = 3000
	table.name.format = ${topic}
	table.types = [TABLE]
	trim.sensitive.log = false
 (io.confluent.connect.jdbc.sink.JdbcSinkConfig:372)
[2025-04-13 13:51:37,511] INFO [sink-to-database02|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:51:37,511] INFO [sink-to-database02|task-0] WorkerSinkTask{id=sink-to-database02-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:324)
[2025-04-13 13:51:37,511] INFO [sink-to-database02|task-0] WorkerSinkTask{id=sink-to-database02-0} Executing sink task (org.apache.kafka.connect.runtime.WorkerSinkTask:210)
[2025-04-13 13:51:37,511] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1988)
[2025-04-13 13:51:37,514] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] Cluster ID: PRZJITuEQBeLmWOW7dnIsg (org.apache.kafka.clients.Metadata:364)
[2025-04-13 13:51:37,515] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] Discovered group coordinator localhost:9092 (id: 2147483646 rack: null) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:936)
[2025-04-13 13:51:37,516] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] (Re-)joining group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2025-04-13 13:51:37,518] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] Request joining group due to: need to re-join with the given member-id: connector-consumer-sink-to-database02-0-651876a6-64f0-4736-b6b1-2cc870980fb6 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-04-13 13:51:37,518] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] (Re-)joining group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2025-04-13 13:51:38,737] INFO [sink-to-database03|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:51:38,785] INFO [sink-to-database03|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:51:38,819] INFO [sink-to-database03|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:51:38,822] WARN [sink-to-database03|task-0] Write of 198 records failed, remainingRetries=6 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:51:38,822] INFO [sink-to-database03|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:51:38,823] INFO [sink-to-database03|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:51:38,823] ERROR [sink-to-database03|task-0] WorkerSinkTask{id=sink-to-database03-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:51:40,519] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] Successfully joined group with generation Generation{generationId=1, memberId='connector-consumer-sink-to-database02-0-651876a6-64f0-4736-b6b1-2cc870980fb6', protocol='range'} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:665)
[2025-04-13 13:51:40,520] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] Finished assignment for group at generation 1: {connector-consumer-sink-to-database02-0-651876a6-64f0-4736-b6b1-2cc870980fb6=Assignment(partitions=[azure-sql-.database01.SalesLT.Product-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:663)
[2025-04-13 13:51:40,521] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] Successfully synced group in generation Generation{generationId=1, memberId='connector-consumer-sink-to-database02-0-651876a6-64f0-4736-b6b1-2cc870980fb6', protocol='range'} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:842)
[2025-04-13 13:51:40,521] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] Notifying assignor about the new Assignment(partitions=[azure-sql-.database01.SalesLT.Product-0]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:323)
[2025-04-13 13:51:40,522] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] Adding newly assigned partitions: azure-sql-.database01.SalesLT.Product-0 (org.apache.kafka.clients.consumer.internals.ConsumerRebalanceListenerInvoker:57)
[2025-04-13 13:51:40,523] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] Found no committed offset for partition azure-sql-.database01.SalesLT.Product-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1506)
[2025-04-13 13:51:40,526] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] Resetting offset for partition azure-sql-.database01.SalesLT.Product-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-04-13 13:51:40,556] INFO [sink-to-database02|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:51:40,602] INFO [sink-to-database02|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:51:40,647] INFO [sink-to-database02|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:51:40,648] WARN [sink-to-database02|task-0] Write of 198 records failed, remainingRetries=10 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:51:40,649] INFO [sink-to-database02|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:51:40,649] INFO [sink-to-database02|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:51:40,649] ERROR [sink-to-database02|task-0] WorkerSinkTask{id=sink-to-database02-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:51:41,823] INFO [sink-to-database03|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:51:41,868] INFO [sink-to-database03|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:51:41,902] INFO [sink-to-database03|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:51:41,903] WARN [sink-to-database03|task-0] Write of 198 records failed, remainingRetries=5 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:51:41,904] INFO [sink-to-database03|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:51:41,904] INFO [sink-to-database03|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:51:41,904] ERROR [sink-to-database03|task-0] WorkerSinkTask{id=sink-to-database03-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:51:42,326] INFO 87.208.3.218 - - [13/Apr/2025:13:51:42 +0000] "GET /connectors/sink-to-database03/status HTTP/1.1" 200 168 "-" "PostmanRuntime/7.43.3" 2 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-04-13 13:51:43,650] INFO [sink-to-database02|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:51:43,686] INFO [sink-to-database02|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:51:43,723] INFO [sink-to-database02|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:51:43,725] WARN [sink-to-database02|task-0] Write of 198 records failed, remainingRetries=9 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:51:43,725] INFO [sink-to-database02|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:51:43,725] INFO [sink-to-database02|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:51:43,725] ERROR [sink-to-database02|task-0] WorkerSinkTask{id=sink-to-database02-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:51:44,904] INFO [sink-to-database03|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:51:44,948] INFO [sink-to-database03|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:51:44,999] INFO [sink-to-database03|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:51:45,002] WARN [sink-to-database03|task-0] Write of 198 records failed, remainingRetries=4 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:51:45,002] INFO [sink-to-database03|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:51:45,002] INFO [sink-to-database03|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:51:45,002] ERROR [sink-to-database03|task-0] WorkerSinkTask{id=sink-to-database03-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:51:46,726] INFO [sink-to-database02|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:51:46,766] INFO [sink-to-database02|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:51:46,808] INFO [sink-to-database02|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:51:46,809] WARN [sink-to-database02|task-0] Write of 198 records failed, remainingRetries=8 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:51:46,809] INFO [sink-to-database02|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:51:46,809] INFO [sink-to-database02|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:51:46,810] ERROR [sink-to-database02|task-0] WorkerSinkTask{id=sink-to-database02-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:51:48,003] INFO [sink-to-database03|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:51:48,044] INFO [sink-to-database03|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:51:48,079] INFO [sink-to-database03|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:51:48,080] WARN [sink-to-database03|task-0] Write of 198 records failed, remainingRetries=3 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:51:48,081] INFO [sink-to-database03|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:51:48,081] INFO [sink-to-database03|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:51:48,081] ERROR [sink-to-database03|task-0] WorkerSinkTask{id=sink-to-database03-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:51:49,810] INFO [sink-to-database02|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:51:49,843] INFO [sink-to-database02|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:51:49,876] INFO [sink-to-database02|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:51:49,878] WARN [sink-to-database02|task-0] Write of 198 records failed, remainingRetries=7 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:51:49,878] INFO [sink-to-database02|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:51:49,879] INFO [sink-to-database02|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:51:49,879] ERROR [sink-to-database02|task-0] WorkerSinkTask{id=sink-to-database02-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:51:51,082] INFO [sink-to-database03|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:51:51,124] INFO [sink-to-database03|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:51:51,161] INFO [sink-to-database03|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:51:51,163] WARN [sink-to-database03|task-0] Write of 198 records failed, remainingRetries=2 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:51:51,163] INFO [sink-to-database03|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:51:51,164] INFO [sink-to-database03|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:51:51,164] ERROR [sink-to-database03|task-0] WorkerSinkTask{id=sink-to-database03-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:51:52,879] INFO [sink-to-database02|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:51:52,928] INFO [sink-to-database02|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:51:52,968] INFO [sink-to-database02|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:51:52,970] WARN [sink-to-database02|task-0] Write of 198 records failed, remainingRetries=6 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:51:52,970] INFO [sink-to-database02|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:51:52,970] INFO [sink-to-database02|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:51:52,970] ERROR [sink-to-database02|task-0] WorkerSinkTask{id=sink-to-database02-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:51:54,164] INFO [sink-to-database03|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:51:54,197] INFO [sink-to-database03|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:51:54,236] INFO [sink-to-database03|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:51:54,238] WARN [sink-to-database03|task-0] Write of 198 records failed, remainingRetries=1 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:51:54,238] INFO [sink-to-database03|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:51:54,239] INFO [sink-to-database03|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:51:54,239] ERROR [sink-to-database03|task-0] WorkerSinkTask{id=sink-to-database03-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:51:55,971] INFO [sink-to-database02|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:51:56,012] INFO [sink-to-database02|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:51:56,051] INFO [sink-to-database02|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:51:56,053] WARN [sink-to-database02|task-0] Write of 198 records failed, remainingRetries=5 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:51:56,053] INFO [sink-to-database02|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:51:56,054] INFO [sink-to-database02|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:51:56,054] ERROR [sink-to-database02|task-0] WorkerSinkTask{id=sink-to-database02-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:51:57,239] INFO [sink-to-database03|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:51:57,296] INFO [sink-to-database03|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:51:57,336] INFO [sink-to-database03|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:51:57,339] WARN [sink-to-database03|task-0] Write of 198 records failed, remainingRetries=0 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:51:57,340] ERROR [sink-to-database03|task-0] Failing task after exhausting retries; encountered 1 exceptions on last write attempt. For complete details on each exception, please enable DEBUG logging. (io.confluent.connect.jdbc.sink.JdbcSinkTask:119)
[2025-04-13 13:51:57,340] ERROR [sink-to-database03|task-0] WorkerSinkTask{id=sink-to-database03-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted. Error: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
 (org.apache.kafka.connect.runtime.WorkerSinkTask:633)
org.apache.kafka.connect.errors.ConnectException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:128)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:51:57,340] ERROR [sink-to-database03|task-0] WorkerSinkTask{id=sink-to-database03-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:233)
org.apache.kafka.connect.errors.ConnectException: Exiting WorkerSinkTask due to unrecoverable exception.
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:635)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: org.apache.kafka.connect.errors.ConnectException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:128)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	... 11 more
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:51:57,340] INFO [sink-to-database03|task-0] Stopping task (io.confluent.connect.jdbc.sink.JdbcSinkTask:170)
[2025-04-13 13:51:57,340] INFO [sink-to-database03|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:51:57,340] INFO [sink-to-database03|task-0] [Consumer clientId=connector-consumer-sink-to-database03-0, groupId=connect-sink-to-database03] Revoke previously assigned partitions azure-sql-.database01.SalesLT.Product-0 (org.apache.kafka.clients.consumer.internals.ConsumerRebalanceListenerInvoker:79)
[2025-04-13 13:51:57,341] INFO [sink-to-database03|task-0] [Consumer clientId=connector-consumer-sink-to-database03-0, groupId=connect-sink-to-database03] The pause flag in partitions [azure-sql-.database01.SalesLT.Product-0] will be removed due to revocation. (org.apache.kafka.clients.consumer.internals.ConsumerRebalanceListenerInvoker:83)
[2025-04-13 13:51:57,341] INFO [sink-to-database03|task-0] [Consumer clientId=connector-consumer-sink-to-database03-0, groupId=connect-sink-to-database03] Member connector-consumer-sink-to-database03-0-440ae676-2531-45f8-937f-c42c790c8929 sending LeaveGroup request to coordinator localhost:9092 (id: 2147483646 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1173)
[2025-04-13 13:51:57,341] INFO [sink-to-database03|task-0] [Consumer clientId=connector-consumer-sink-to-database03-0, groupId=connect-sink-to-database03] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2025-04-13 13:51:57,341] INFO [sink-to-database03|task-0] [Consumer clientId=connector-consumer-sink-to-database03-0, groupId=connect-sink-to-database03] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-04-13 13:51:57,344] INFO [sink-to-database03|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-04-13 13:51:57,344] INFO [sink-to-database03|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-04-13 13:51:57,344] INFO [sink-to-database03|task-0] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-04-13 13:51:57,344] INFO [sink-to-database03|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-04-13 13:51:57,347] INFO [sink-to-database03|task-0] App info kafka.consumer for connector-consumer-sink-to-database03-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-04-13 13:51:59,055] INFO [sink-to-database02|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:51:59,089] INFO [sink-to-database02|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:51:59,133] INFO [sink-to-database02|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:51:59,134] WARN [sink-to-database02|task-0] Write of 198 records failed, remainingRetries=4 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:51:59,134] INFO [sink-to-database02|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:51:59,135] INFO [sink-to-database02|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:51:59,135] ERROR [sink-to-database02|task-0] WorkerSinkTask{id=sink-to-database02-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:52:02,135] INFO [sink-to-database02|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:52:02,174] INFO [sink-to-database02|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:52:02,208] INFO [sink-to-database02|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:52:02,210] WARN [sink-to-database02|task-0] Write of 198 records failed, remainingRetries=3 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:52:02,210] INFO [sink-to-database02|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:52:02,211] INFO [sink-to-database02|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:52:02,211] ERROR [sink-to-database02|task-0] WorkerSinkTask{id=sink-to-database02-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:52:04,958] INFO [azure-sql-server-source|task-0] 2 records sent during previous 00:15:20.188, last recorded offset of {server=azure-sql-, database=database01} partition is {transaction_id=null, event_serial_no=1, commit_lsn=00000110:00000968:000c, change_lsn=00000110:00000968:0004} (io.debezium.connector.common.BaseSourceTask:213)
[2025-04-13 13:52:05,211] INFO [sink-to-database02|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:52:05,248] INFO [sink-to-database02|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:52:05,292] INFO [sink-to-database02|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:52:05,294] WARN [sink-to-database02|task-0] Write of 198 records failed, remainingRetries=2 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:52:05,294] INFO [sink-to-database02|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:52:05,295] INFO [sink-to-database02|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:52:05,295] ERROR [sink-to-database02|task-0] WorkerSinkTask{id=sink-to-database02-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:52:08,295] INFO [sink-to-database02|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:52:08,328] INFO [sink-to-database02|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:52:08,374] INFO [sink-to-database02|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:52:08,378] WARN [sink-to-database02|task-0] Write of 198 records failed, remainingRetries=1 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:52:08,378] INFO [sink-to-database02|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:52:08,378] INFO [sink-to-database02|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:52:08,378] ERROR [sink-to-database02|task-0] WorkerSinkTask{id=sink-to-database02-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:52:09,088] INFO [azure-sql-server-source|task-0|offsets] WorkerSourceTask{id=azure-sql-server-source-0} Committing offsets for 0 acknowledged messages (org.apache.kafka.connect.runtime.WorkerSourceTask:235)
[2025-04-13 13:52:11,379] INFO [sink-to-database02|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:52:11,425] INFO [sink-to-database02|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:52:11,473] INFO [sink-to-database02|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:52:11,475] WARN [sink-to-database02|task-0] Write of 198 records failed, remainingRetries=0 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:52:11,475] ERROR [sink-to-database02|task-0] Failing task after exhausting retries; encountered 1 exceptions on last write attempt. For complete details on each exception, please enable DEBUG logging. (io.confluent.connect.jdbc.sink.JdbcSinkTask:119)
[2025-04-13 13:52:11,475] ERROR [sink-to-database02|task-0] WorkerSinkTask{id=sink-to-database02-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted. Error: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
 (org.apache.kafka.connect.runtime.WorkerSinkTask:633)
org.apache.kafka.connect.errors.ConnectException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:128)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:52:11,475] ERROR [sink-to-database02|task-0] WorkerSinkTask{id=sink-to-database02-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:233)
org.apache.kafka.connect.errors.ConnectException: Exiting WorkerSinkTask due to unrecoverable exception.
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:635)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: org.apache.kafka.connect.errors.ConnectException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:128)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	... 11 more
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:52:11,475] INFO [sink-to-database02|task-0] Stopping task (io.confluent.connect.jdbc.sink.JdbcSinkTask:170)
[2025-04-13 13:52:11,475] INFO [sink-to-database02|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:52:11,476] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] Revoke previously assigned partitions azure-sql-.database01.SalesLT.Product-0 (org.apache.kafka.clients.consumer.internals.ConsumerRebalanceListenerInvoker:79)
[2025-04-13 13:52:11,476] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] The pause flag in partitions [azure-sql-.database01.SalesLT.Product-0] will be removed due to revocation. (org.apache.kafka.clients.consumer.internals.ConsumerRebalanceListenerInvoker:83)
[2025-04-13 13:52:11,476] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] Member connector-consumer-sink-to-database02-0-651876a6-64f0-4736-b6b1-2cc870980fb6 sending LeaveGroup request to coordinator localhost:9092 (id: 2147483646 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1173)
[2025-04-13 13:52:11,476] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2025-04-13 13:52:11,476] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-04-13 13:52:11,478] INFO [sink-to-database02|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-04-13 13:52:11,478] INFO [sink-to-database02|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-04-13 13:52:11,478] INFO [sink-to-database02|task-0] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-04-13 13:52:11,478] INFO [sink-to-database02|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-04-13 13:52:11,479] INFO [sink-to-database02|task-0] App info kafka.consumer for connector-consumer-sink-to-database02-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-04-13 13:52:15,967] INFO 87.208.3.218 - - [13/Apr/2025:13:52:15 +0000] "GET /connectors/sink-to-database03/status HTTP/1.1" 200 2167 "-" "PostmanRuntime/7.43.3" 2 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-04-13 13:53:09,088] INFO [azure-sql-server-source|task-0|offsets] WorkerSourceTask{id=azure-sql-server-source-0} Committing offsets for 1 acknowledged messages (org.apache.kafka.connect.runtime.WorkerSourceTask:235)
[2025-04-13 13:55:40,367] INFO Successfully processed removal of connector 'sink-to-database02' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1003)
[2025-04-13 13:55:40,367] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Connector sink-to-database02 config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2412)
[2025-04-13 13:55:40,368] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Handling connector-only config update by stopping connector sink-to-database02 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:716)
[2025-04-13 13:55:40,368] INFO [sink-to-database02|worker] Stopping connector sink-to-database02 (org.apache.kafka.connect.runtime.Worker:451)
[2025-04-13 13:55:40,368] INFO [sink-to-database02|worker] Scheduled shutdown for WorkerConnector{id=sink-to-database02} (org.apache.kafka.connect.runtime.WorkerConnector:294)
[2025-04-13 13:55:40,369] INFO 87.208.3.218 - - [13/Apr/2025:13:55:40 +0000] "DELETE /connectors/sink-to-database02/ HTTP/1.1" 204 0 "-" "PostmanRuntime/7.43.3" 6 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-04-13 13:55:40,369] INFO [sink-to-database02|worker] Completed shutdown for WorkerConnector{id=sink-to-database02} (org.apache.kafka.connect.runtime.WorkerConnector:314)
[2025-04-13 13:55:40,369] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-04-13 13:55:40,369] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-04-13 13:55:40,372] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=32, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-04-13 13:55:40,374] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=32, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-04-13 13:55:40,374] INFO [sink-to-database02|worker] Stopping connector sink-to-database02 (org.apache.kafka.connect.runtime.Worker:451)
[2025-04-13 13:55:40,374] WARN [sink-to-database02|worker] Ignoring stop request for unowned connector sink-to-database02 (org.apache.kafka.connect.runtime.Worker:454)
[2025-04-13 13:55:40,374] INFO [sink-to-database02|task-0] Stopping task sink-to-database02-0 (org.apache.kafka.connect.runtime.Worker:1047)
[2025-04-13 13:55:40,374] WARN [sink-to-database02|worker] Ignoring await stop request for non-present connector sink-to-database02 (org.apache.kafka.connect.runtime.Worker:475)
[2025-04-13 13:55:40,376] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2708)
[2025-04-13 13:55:40,377] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2729)
[2025-04-13 13:55:40,377] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Joined group at generation 32 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', leaderUrl='http://10.0.0.4:8083/', offset=42, connectorIds=[sink-to-database03, azure-sql-server-source], taskIds=[sink-to-database03-0, azure-sql-server-source-0], revokedConnectorIds=[sink-to-database02], revokedTaskIds=[sink-to-database02-0], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2621)
[2025-04-13 13:55:40,378] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 42 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1959)
[2025-04-13 13:55:40,378] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1988)
[2025-04-13 13:55:40,378] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-04-13 13:55:40,378] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-04-13 13:55:40,381] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=33, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-04-13 13:55:40,382] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=33, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-04-13 13:55:40,382] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Joined group at generation 33 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', leaderUrl='http://10.0.0.4:8083/', offset=42, connectorIds=[sink-to-database03, azure-sql-server-source], taskIds=[sink-to-database03-0, azure-sql-server-source-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2621)
[2025-04-13 13:55:40,382] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 42 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1959)
[2025-04-13 13:55:40,382] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1988)
[2025-04-13 13:55:44,555] INFO Successfully processed removal of connector 'sink-to-database03' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1003)
[2025-04-13 13:55:44,555] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Connector sink-to-database03 config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2412)
[2025-04-13 13:55:44,555] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Handling connector-only config update by stopping connector sink-to-database03 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:716)
[2025-04-13 13:55:44,556] INFO [sink-to-database03|worker] Stopping connector sink-to-database03 (org.apache.kafka.connect.runtime.Worker:451)
[2025-04-13 13:55:44,556] INFO [sink-to-database03|worker] Scheduled shutdown for WorkerConnector{id=sink-to-database03} (org.apache.kafka.connect.runtime.WorkerConnector:294)
[2025-04-13 13:55:44,556] INFO [sink-to-database03|worker] Completed shutdown for WorkerConnector{id=sink-to-database03} (org.apache.kafka.connect.runtime.WorkerConnector:314)
[2025-04-13 13:55:44,556] INFO 87.208.3.218 - - [13/Apr/2025:13:55:44 +0000] "DELETE /connectors/sink-to-database03/ HTTP/1.1" 204 0 "-" "PostmanRuntime/7.43.3" 8 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-04-13 13:55:44,556] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-04-13 13:55:44,556] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-04-13 13:55:44,559] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=34, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-04-13 13:55:44,561] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=34, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-04-13 13:55:44,561] INFO [sink-to-database03|worker] Stopping connector sink-to-database03 (org.apache.kafka.connect.runtime.Worker:451)
[2025-04-13 13:55:44,561] WARN [sink-to-database03|worker] Ignoring stop request for unowned connector sink-to-database03 (org.apache.kafka.connect.runtime.Worker:454)
[2025-04-13 13:55:44,561] WARN [sink-to-database03|worker] Ignoring await stop request for non-present connector sink-to-database03 (org.apache.kafka.connect.runtime.Worker:475)
[2025-04-13 13:55:44,561] INFO [sink-to-database03|task-0] Stopping task sink-to-database03-0 (org.apache.kafka.connect.runtime.Worker:1047)
[2025-04-13 13:55:44,562] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2708)
[2025-04-13 13:55:44,565] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2729)
[2025-04-13 13:55:44,565] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Joined group at generation 34 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', leaderUrl='http://10.0.0.4:8083/', offset=44, connectorIds=[azure-sql-server-source], taskIds=[azure-sql-server-source-0], revokedConnectorIds=[sink-to-database03], revokedTaskIds=[sink-to-database03-0], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2621)
[2025-04-13 13:55:44,565] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 44 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1959)
[2025-04-13 13:55:44,565] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1988)
[2025-04-13 13:55:44,565] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-04-13 13:55:44,565] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-04-13 13:55:44,566] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=35, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-04-13 13:55:44,567] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=35, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-04-13 13:55:44,567] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Joined group at generation 35 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', leaderUrl='http://10.0.0.4:8083/', offset=44, connectorIds=[azure-sql-server-source], taskIds=[azure-sql-server-source-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2621)
[2025-04-13 13:55:44,568] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 44 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1959)
[2025-04-13 13:55:44,568] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1988)
[2025-04-13 13:58:53,574] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:372)
[2025-04-13 13:58:53,579] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Connector sink-to-database02 config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2425)
[2025-04-13 13:58:53,579] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-04-13 13:58:53,579] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-04-13 13:58:53,580] INFO 87.208.3.218 - - [13/Apr/2025:13:58:53 +0000] "POST /connectors HTTP/1.1" 201 599 "-" "PostmanRuntime/7.43.3" 9 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-04-13 13:58:53,581] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=36, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-04-13 13:58:53,583] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=36, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-04-13 13:58:53,583] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Joined group at generation 36 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', leaderUrl='http://10.0.0.4:8083/', offset=45, connectorIds=[sink-to-database02, azure-sql-server-source], taskIds=[azure-sql-server-source-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2621)
[2025-04-13 13:58:53,584] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 45 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1959)
[2025-04-13 13:58:53,584] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Starting connector sink-to-database02 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2077)
[2025-04-13 13:58:53,584] INFO [sink-to-database02|worker] Creating connector sink-to-database02 of type io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:312)
[2025-04-13 13:58:53,584] INFO [sink-to-database02|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-to-database02
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [azure-sql-.database01.SalesLT.Product]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-04-13 13:58:53,584] INFO [sink-to-database02|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-to-database02
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [azure-sql-.database01.SalesLT.Product]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-04-13 13:58:53,584] INFO [sink-to-database02|worker] Instantiated connector sink-to-database02 with version 10.7.0 of type class io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:334)
[2025-04-13 13:58:53,585] INFO [sink-to-database02|worker] Finished creating connector sink-to-database02 (org.apache.kafka.connect.runtime.Worker:355)
[2025-04-13 13:58:53,585] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1988)
[2025-04-13 13:58:53,586] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-to-database02
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [azure-sql-.database01.SalesLT.Product]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-04-13 13:58:53,586] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-to-database02
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [azure-sql-.database01.SalesLT.Product]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-04-13 13:58:53,586] INFO [sink-to-database02|worker] Setting task configurations for 1 workers. (io.confluent.connect.jdbc.JdbcSinkConnector:51)
[2025-04-13 13:58:53,592] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Tasks [sink-to-database02-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2440)
[2025-04-13 13:58:53,593] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-04-13 13:58:53,593] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-04-13 13:58:53,594] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=37, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-04-13 13:58:53,596] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=37, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-04-13 13:58:53,596] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Joined group at generation 37 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', leaderUrl='http://10.0.0.4:8083/', offset=47, connectorIds=[sink-to-database02, azure-sql-server-source], taskIds=[sink-to-database02-0, azure-sql-server-source-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2621)
[2025-04-13 13:58:53,596] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 47 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1959)
[2025-04-13 13:58:53,596] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Starting task sink-to-database02-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2002)
[2025-04-13 13:58:53,596] INFO [sink-to-database02|task-0] Creating task sink-to-database02-0 (org.apache.kafka.connect.runtime.Worker:645)
[2025-04-13 13:58:53,597] INFO [sink-to-database02|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-to-database02
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2025-04-13 13:58:53,597] INFO [sink-to-database02|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-to-database02
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-04-13 13:58:53,597] INFO [sink-to-database02|task-0] TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.sink.JdbcSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2025-04-13 13:58:53,597] INFO [sink-to-database02|task-0] Instantiated task sink-to-database02-0 with version 10.7.0 of type io.confluent.connect.jdbc.sink.JdbcSinkTask (org.apache.kafka.connect.runtime.Worker:664)
[2025-04-13 13:58:53,597] INFO [sink-to-database02|task-0] JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-04-13 13:58:53,597] INFO [sink-to-database02|task-0] Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task sink-to-database02-0 using the worker config (org.apache.kafka.connect.runtime.Worker:677)
[2025-04-13 13:58:53,598] INFO [sink-to-database02|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-04-13 13:58:53,598] INFO [sink-to-database02|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task sink-to-database02-0 using the worker config (org.apache.kafka.connect.runtime.Worker:683)
[2025-04-13 13:58:53,598] INFO [sink-to-database02|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task sink-to-database02-0 using the worker config (org.apache.kafka.connect.runtime.Worker:690)
[2025-04-13 13:58:53,598] INFO [sink-to-database02|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:1794)
[2025-04-13 13:58:53,599] INFO [sink-to-database02|task-0] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-to-database02
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [azure-sql-.database01.SalesLT.Product]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2025-04-13 13:58:53,599] INFO [sink-to-database02|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = sink-to-database02
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topics = [azure-sql-.database01.SalesLT.Product]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-04-13 13:58:53,599] INFO [sink-to-database02|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-sink-to-database02-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	enable.metrics.push = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-sink-to-database02
	group.instance.id = null
	group.protocol = classic
	group.remote.assignor = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2025-04-13 13:58:53,599] INFO [sink-to-database02|task-0] initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-04-13 13:58:53,602] INFO [sink-to-database02|task-0] These configurations '[metrics.context.connect.kafka.cluster.id, metrics.context.connect.group.id]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:381)
[2025-04-13 13:58:53,602] INFO [sink-to-database02|task-0] Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-04-13 13:58:53,602] INFO [sink-to-database02|task-0] Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-04-13 13:58:53,602] INFO [sink-to-database02|task-0] Kafka startTimeMs: 1744552733602 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-04-13 13:58:53,603] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1988)
[2025-04-13 13:58:53,603] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] Subscribed to topic(s): azure-sql-.database01.SalesLT.Product (org.apache.kafka.clients.consumer.internals.LegacyKafkaConsumer:476)
[2025-04-13 13:58:53,603] INFO [sink-to-database02|task-0] Starting JDBC Sink task (io.confluent.connect.jdbc.sink.JdbcSinkTask:51)
[2025-04-13 13:58:53,603] INFO [sink-to-database02|task-0] JdbcSinkConfig values: 
	auto.create = true
	auto.evolve = false
	batch.size = 3000
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:sqlserver://kafkadatabase.database.windows.net:1433;databaseName=database02;encrypt=true;trustServerCertificate=false;hostNameInCertificate=*.database.windows.net;loginTimeout=30;
	connection.user = kafkadmin@kafkadatabase
	db.timezone = UTC
	delete.enabled = false
	dialect.name = 
	fields.whitelist = []
	insert.mode = upsert
	max.retries = 10
	mssql.use.merge.holdlock = true
	pk.fields = [ProductID]
	pk.mode = record_value
	quote.sql.identifiers = ALWAYS
	retry.backoff.ms = 3000
	table.name.format = ${topic}
	table.types = [TABLE]
	trim.sensitive.log = false
 (io.confluent.connect.jdbc.sink.JdbcSinkConfig:372)
[2025-04-13 13:58:53,603] INFO [sink-to-database02|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:58:53,603] INFO [sink-to-database02|task-0] WorkerSinkTask{id=sink-to-database02-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:324)
[2025-04-13 13:58:53,604] INFO [sink-to-database02|task-0] WorkerSinkTask{id=sink-to-database02-0} Executing sink task (org.apache.kafka.connect.runtime.WorkerSinkTask:210)
[2025-04-13 13:58:53,613] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] Cluster ID: PRZJITuEQBeLmWOW7dnIsg (org.apache.kafka.clients.Metadata:364)
[2025-04-13 13:58:53,613] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] Discovered group coordinator localhost:9092 (id: 2147483646 rack: null) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:936)
[2025-04-13 13:58:53,614] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] (Re-)joining group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2025-04-13 13:58:53,616] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] Request joining group due to: need to re-join with the given member-id: connector-consumer-sink-to-database02-0-915c300b-6f85-4e90-adf6-f4e5ef734984 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-04-13 13:58:53,617] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] (Re-)joining group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:604)
[2025-04-13 13:58:56,619] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] Successfully joined group with generation Generation{generationId=1, memberId='connector-consumer-sink-to-database02-0-915c300b-6f85-4e90-adf6-f4e5ef734984', protocol='range'} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:665)
[2025-04-13 13:58:56,619] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] Finished assignment for group at generation 1: {connector-consumer-sink-to-database02-0-915c300b-6f85-4e90-adf6-f4e5ef734984=Assignment(partitions=[azure-sql-.database01.SalesLT.Product-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:663)
[2025-04-13 13:58:56,621] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] Successfully synced group in generation Generation{generationId=1, memberId='connector-consumer-sink-to-database02-0-915c300b-6f85-4e90-adf6-f4e5ef734984', protocol='range'} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:842)
[2025-04-13 13:58:56,621] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] Notifying assignor about the new Assignment(partitions=[azure-sql-.database01.SalesLT.Product-0]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:323)
[2025-04-13 13:58:56,621] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] Adding newly assigned partitions: azure-sql-.database01.SalesLT.Product-0 (org.apache.kafka.clients.consumer.internals.ConsumerRebalanceListenerInvoker:57)
[2025-04-13 13:58:56,622] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] Found no committed offset for partition azure-sql-.database01.SalesLT.Product-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1506)
[2025-04-13 13:58:56,625] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] Resetting offset for partition azure-sql-.database01.SalesLT.Product-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 1 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2025-04-13 13:58:56,661] INFO [sink-to-database02|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:58:56,773] INFO [sink-to-database02|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:58:56,811] INFO [sink-to-database02|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:58:56,813] WARN [sink-to-database02|task-0] Write of 198 records failed, remainingRetries=10 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:58:56,814] INFO [sink-to-database02|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:58:56,814] INFO [sink-to-database02|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:58:56,814] ERROR [sink-to-database02|task-0] WorkerSinkTask{id=sink-to-database02-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:58:59,815] INFO [sink-to-database02|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:58:59,858] INFO [sink-to-database02|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:58:59,890] INFO [sink-to-database02|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:58:59,892] WARN [sink-to-database02|task-0] Write of 198 records failed, remainingRetries=9 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:58:59,892] INFO [sink-to-database02|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:58:59,892] INFO [sink-to-database02|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:58:59,892] ERROR [sink-to-database02|task-0] WorkerSinkTask{id=sink-to-database02-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:59:00,933] INFO 87.208.3.218 - - [13/Apr/2025:13:59:00 +0000] "GET /connectors/sink-to-database02/status HTTP/1.1" 200 168 "-" "PostmanRuntime/7.43.3" 4 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-04-13 13:59:02,893] INFO [sink-to-database02|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:59:02,936] INFO [sink-to-database02|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:59:02,978] INFO [sink-to-database02|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:59:02,980] WARN [sink-to-database02|task-0] Write of 198 records failed, remainingRetries=8 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:59:02,981] INFO [sink-to-database02|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:59:02,981] INFO [sink-to-database02|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:59:02,981] ERROR [sink-to-database02|task-0] WorkerSinkTask{id=sink-to-database02-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:59:05,982] INFO [sink-to-database02|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:59:06,019] INFO [sink-to-database02|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:59:06,054] INFO [sink-to-database02|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:59:06,056] WARN [sink-to-database02|task-0] Write of 198 records failed, remainingRetries=7 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:59:06,056] INFO [sink-to-database02|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:59:06,057] INFO [sink-to-database02|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:59:06,057] ERROR [sink-to-database02|task-0] WorkerSinkTask{id=sink-to-database02-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:59:09,058] INFO [sink-to-database02|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:59:09,095] INFO [sink-to-database02|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:59:09,135] INFO [sink-to-database02|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:59:09,137] WARN [sink-to-database02|task-0] Write of 198 records failed, remainingRetries=6 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:59:09,137] INFO [sink-to-database02|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:59:09,137] INFO [sink-to-database02|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:59:09,137] ERROR [sink-to-database02|task-0] WorkerSinkTask{id=sink-to-database02-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:59:12,137] INFO [sink-to-database02|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:59:12,168] INFO [sink-to-database02|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:59:12,201] INFO [sink-to-database02|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:59:12,202] WARN [sink-to-database02|task-0] Write of 198 records failed, remainingRetries=5 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:59:12,202] INFO [sink-to-database02|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:59:12,203] INFO [sink-to-database02|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:59:12,203] ERROR [sink-to-database02|task-0] WorkerSinkTask{id=sink-to-database02-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:59:15,204] INFO [sink-to-database02|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:59:15,251] INFO [sink-to-database02|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:59:15,284] INFO [sink-to-database02|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:59:15,286] WARN [sink-to-database02|task-0] Write of 198 records failed, remainingRetries=4 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:59:15,286] INFO [sink-to-database02|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:59:15,286] INFO [sink-to-database02|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:59:15,286] ERROR [sink-to-database02|task-0] WorkerSinkTask{id=sink-to-database02-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:59:18,287] INFO [sink-to-database02|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:59:18,319] INFO [sink-to-database02|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:59:18,354] INFO [sink-to-database02|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:59:18,356] WARN [sink-to-database02|task-0] Write of 198 records failed, remainingRetries=3 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:59:18,356] INFO [sink-to-database02|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:59:18,357] INFO [sink-to-database02|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:59:18,357] ERROR [sink-to-database02|task-0] WorkerSinkTask{id=sink-to-database02-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:59:21,357] INFO [sink-to-database02|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:59:21,398] INFO [sink-to-database02|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:59:21,432] INFO [sink-to-database02|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:59:21,434] WARN [sink-to-database02|task-0] Write of 198 records failed, remainingRetries=2 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:59:21,434] INFO [sink-to-database02|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:59:21,434] INFO [sink-to-database02|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:59:21,434] ERROR [sink-to-database02|task-0] WorkerSinkTask{id=sink-to-database02-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:59:24,435] INFO [sink-to-database02|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:59:24,476] INFO [sink-to-database02|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:59:24,515] INFO [sink-to-database02|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:59:24,518] WARN [sink-to-database02|task-0] Write of 198 records failed, remainingRetries=1 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:59:24,518] INFO [sink-to-database02|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:59:24,519] INFO [sink-to-database02|task-0] Initializing writer using SQL dialect: SqlServerDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:71)
[2025-04-13 13:59:24,519] ERROR [sink-to-database02|task-0] WorkerSinkTask{id=sink-to-database02-0} RetriableException from SinkTask: (org.apache.kafka.connect.runtime.WorkerSinkTask:624)
org.apache.kafka.connect.errors.RetriableException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:114)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:59:27,519] INFO [sink-to-database02|task-0] Attempting to open connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:80)
[2025-04-13 13:59:27,570] INFO [sink-to-database02|task-0] JdbcDbWriter Connected (io.confluent.connect.jdbc.sink.JdbcDbWriter:56)
[2025-04-13 13:59:27,608] INFO [sink-to-database02|task-0] Checking SqlServer dialect for existence of TABLE "azure-sql-"."dbo"."database01" (io.confluent.connect.jdbc.dialect.GenericDatabaseDialect:589)
[2025-04-13 13:59:27,610] WARN [sink-to-database02|task-0] Write of 198 records failed, remainingRetries=0 (io.confluent.connect.jdbc.sink.JdbcSinkTask:98)
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
	at com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:265)
	at com.microsoft.sqlserver.jdbc.TDSTokenHandler.onEOF(tdsparser.java:300)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:133)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:37)
	at com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:26)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection$1ConnectionCommand.doExecute(SQLServerConnection.java:4023)
	at com.microsoft.sqlserver.jdbc.TDSCommand.execute(IOBuffer.java:7627)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.executeCommand(SQLServerConnection.java:3912)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.connectionCommand(SQLServerConnection.java:4031)
	at com.microsoft.sqlserver.jdbc.SQLServerConnection.setCatalog(SQLServerConnection.java:4397)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.switchCatalogs(SQLServerDatabaseMetaData.java:400)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetFromStoredProc(SQLServerDatabaseMetaData.java:349)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getResultSetWithProvidedColumnNames(SQLServerDatabaseMetaData.java:374)
	at com.microsoft.sqlserver.jdbc.SQLServerDatabaseMetaData.getTables(SQLServerDatabaseMetaData.java:561)
	at io.confluent.connect.jdbc.dialect.GenericDatabaseDialect.tableExists(GenericDatabaseDialect.java:590)
	at io.confluent.connect.jdbc.util.TableDefinitions.get(TableDefinitions.java:61)
	at io.confluent.connect.jdbc.sink.DbStructure.createOrAmendIfNecessary(DbStructure.java:64)
	at io.confluent.connect.jdbc.sink.BufferedRecords.add(BufferedRecords.java:122)
	at io.confluent.connect.jdbc.sink.JdbcDbWriter.write(JdbcDbWriter.java:74)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:88)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
[2025-04-13 13:59:27,611] ERROR [sink-to-database02|task-0] Failing task after exhausting retries; encountered 1 exceptions on last write attempt. For complete details on each exception, please enable DEBUG logging. (io.confluent.connect.jdbc.sink.JdbcSinkTask:119)
[2025-04-13 13:59:27,611] ERROR [sink-to-database02|task-0] WorkerSinkTask{id=sink-to-database02-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted. Error: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.
 (org.apache.kafka.connect.runtime.WorkerSinkTask:633)
org.apache.kafka.connect.errors.ConnectException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:128)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:59:27,611] ERROR [sink-to-database02|task-0] WorkerSinkTask{id=sink-to-database02-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:233)
org.apache.kafka.connect.errors.ConnectException: Exiting WorkerSinkTask due to unrecoverable exception.
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:635)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.poll(WorkerSinkTask.java:344)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.iteration(WorkerSinkTask.java:246)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.execute(WorkerSinkTask.java:215)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:225)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:280)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:237)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: org.apache.kafka.connect.errors.ConnectException: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:128)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.deliverMessages(WorkerSinkTask.java:605)
	... 11 more
Caused by: java.sql.SQLException: Exception chain:
com.microsoft.sqlserver.jdbc.SQLServerException: USE statement is not supported to switch between databases. Use a new connection to connect to a different database.

	at io.confluent.connect.jdbc.sink.JdbcSinkTask.getAllMessagesException(JdbcSinkTask.java:159)
	at io.confluent.connect.jdbc.sink.JdbcSinkTask.put(JdbcSinkTask.java:108)
	... 12 more
[2025-04-13 13:59:27,611] INFO [sink-to-database02|task-0] Stopping task (io.confluent.connect.jdbc.sink.JdbcSinkTask:170)
[2025-04-13 13:59:27,611] INFO [sink-to-database02|task-0] Closing connection #1 to SqlServer (io.confluent.connect.jdbc.util.CachedConnectionProvider:111)
[2025-04-13 13:59:27,611] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] Revoke previously assigned partitions azure-sql-.database01.SalesLT.Product-0 (org.apache.kafka.clients.consumer.internals.ConsumerRebalanceListenerInvoker:79)
[2025-04-13 13:59:27,612] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] The pause flag in partitions [azure-sql-.database01.SalesLT.Product-0] will be removed due to revocation. (org.apache.kafka.clients.consumer.internals.ConsumerRebalanceListenerInvoker:83)
[2025-04-13 13:59:27,612] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] Member connector-consumer-sink-to-database02-0-915c300b-6f85-4e90-adf6-f4e5ef734984 sending LeaveGroup request to coordinator localhost:9092 (id: 2147483646 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1173)
[2025-04-13 13:59:27,612] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1055)
[2025-04-13 13:59:27,612] INFO [sink-to-database02|task-0] [Consumer clientId=connector-consumer-sink-to-database02-0, groupId=connect-sink-to-database02] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1102)
[2025-04-13 13:59:27,614] INFO [sink-to-database02|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:684)
[2025-04-13 13:59:27,614] INFO [sink-to-database02|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-04-13 13:59:27,614] INFO [sink-to-database02|task-0] Closing reporter org.apache.kafka.common.telemetry.internals.ClientTelemetryReporter (org.apache.kafka.common.metrics.Metrics:688)
[2025-04-13 13:59:27,614] INFO [sink-to-database02|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:694)
[2025-04-13 13:59:27,615] INFO [sink-to-database02|task-0] App info kafka.consumer for connector-consumer-sink-to-database02-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:88)
[2025-04-13 13:59:36,391] INFO 87.208.3.218 - - [13/Apr/2025:13:59:36 +0000] "GET /connectors HTTP/1.1" 200 48 "-" "PostmanRuntime/7.43.3" 3 (org.apache.kafka.connect.runtime.rest.RestServer:62)

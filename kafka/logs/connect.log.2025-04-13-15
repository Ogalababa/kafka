[2025-04-13 15:03:33,758] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-04-13 15:08:33,964] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-04-13 15:13:34,162] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-04-13 15:15:05,876] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Session key updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2483)
[2025-04-13 15:23:34,464] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-04-13 15:28:34,660] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-04-13 15:33:34,864] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-04-13 15:38:35,066] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-04-13 15:43:35,272] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-04-13 15:48:35,472] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-04-13 15:53:09,625] INFO 87.208.3.218 - - [13/Apr/2025:15:53:09 +0000] "GET /connectors/sink-to-database02/status HTTP/1.1" 200 2167 "-" "PostmanRuntime/7.43.3" 5 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-04-13 15:53:19,702] INFO Successfully processed removal of connector 'sink-to-database02' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:1003)
[2025-04-13 15:53:19,702] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Connector sink-to-database02 config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2412)
[2025-04-13 15:53:19,702] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Handling connector-only config update by stopping connector sink-to-database02 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:716)
[2025-04-13 15:53:19,702] INFO [sink-to-database02|worker] Stopping connector sink-to-database02 (org.apache.kafka.connect.runtime.Worker:451)
[2025-04-13 15:53:19,702] INFO [sink-to-database02|worker] Scheduled shutdown for WorkerConnector{id=sink-to-database02} (org.apache.kafka.connect.runtime.WorkerConnector:294)
[2025-04-13 15:53:19,703] INFO 87.208.3.218 - - [13/Apr/2025:15:53:19 +0000] "DELETE /connectors/sink-to-database02/ HTTP/1.1" 204 0 "-" "PostmanRuntime/7.43.3" 7 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-04-13 15:53:19,703] INFO [sink-to-database02|worker] Completed shutdown for WorkerConnector{id=sink-to-database02} (org.apache.kafka.connect.runtime.WorkerConnector:314)
[2025-04-13 15:53:19,703] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-04-13 15:53:19,703] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-04-13 15:53:19,705] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=78, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-04-13 15:53:19,707] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=78, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-04-13 15:53:19,707] INFO [sink-to-database02|worker] Stopping connector sink-to-database02 (org.apache.kafka.connect.runtime.Worker:451)
[2025-04-13 15:53:19,707] WARN [sink-to-database02|worker] Ignoring stop request for unowned connector sink-to-database02 (org.apache.kafka.connect.runtime.Worker:454)
[2025-04-13 15:53:19,707] WARN [sink-to-database02|worker] Ignoring await stop request for non-present connector sink-to-database02 (org.apache.kafka.connect.runtime.Worker:475)
[2025-04-13 15:53:19,707] INFO [sink-to-database02|task-0] Stopping task sink-to-database02-0 (org.apache.kafka.connect.runtime.Worker:1047)
[2025-04-13 15:53:19,707] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2708)
[2025-04-13 15:53:19,708] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2729)
[2025-04-13 15:53:19,708] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Joined group at generation 78 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', leaderUrl='http://10.0.0.4:8083/', offset=101, connectorIds=[azure-sql-server-source], taskIds=[azure-sql-server-source-0], revokedConnectorIds=[sink-to-database02], revokedTaskIds=[sink-to-database02-0], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2621)
[2025-04-13 15:53:19,709] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 101 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1959)
[2025-04-13 15:53:19,709] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1988)
[2025-04-13 15:53:19,709] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-04-13 15:53:19,709] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-04-13 15:53:19,710] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=79, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-04-13 15:53:19,712] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=79, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-04-13 15:53:19,712] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Joined group at generation 79 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', leaderUrl='http://10.0.0.4:8083/', offset=101, connectorIds=[azure-sql-server-source], taskIds=[azure-sql-server-source-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2621)
[2025-04-13 15:53:19,712] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 101 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1959)
[2025-04-13 15:53:19,712] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1988)
[2025-04-13 15:58:35,679] INFO [AdminClient clientId=connect-cluster-shared-admin] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient:1017)
[2025-04-13 15:59:39,628] INFO Loading the custom source info struct maker plugin: io.debezium.connector.sqlserver.SqlServerSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1318)
[2025-04-13 15:59:39,700] INFO Checking if user has access to CDC table (io.debezium.connector.sqlserver.SqlServerConnector:128)
[2025-04-13 15:59:39,726] INFO Connection gracefully closed (io.debezium.jdbc.JdbcConnection:949)
[2025-04-13 15:59:39,726] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:372)
[2025-04-13 15:59:39,730] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Connector azure-sql-server-source-adress config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2425)
[2025-04-13 15:59:39,730] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-04-13 15:59:39,730] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-04-13 15:59:39,731] INFO 87.208.3.218 - - [13/Apr/2025:15:59:39 +0000] "POST /connectors HTTP/1.1" 201 999 "-" "PostmanRuntime/7.43.3" 107 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2025-04-13 15:59:39,731] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=80, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-04-13 15:59:39,733] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=80, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-04-13 15:59:39,733] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Joined group at generation 80 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', leaderUrl='http://10.0.0.4:8083/', offset=102, connectorIds=[azure-sql-server-source-adress, azure-sql-server-source], taskIds=[azure-sql-server-source-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2621)
[2025-04-13 15:59:39,733] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 102 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1959)
[2025-04-13 15:59:39,733] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Starting connector azure-sql-server-source-adress (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2077)
[2025-04-13 15:59:39,733] INFO [azure-sql-server-source-adress|worker] Creating connector azure-sql-server-source-adress of type io.debezium.connector.sqlserver.SqlServerConnector (org.apache.kafka.connect.runtime.Worker:312)
[2025-04-13 15:59:39,734] INFO [azure-sql-server-source-adress|worker] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.sqlserver.SqlServerConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = azure-sql-server-source-adress
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [unwrap]
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2025-04-13 15:59:39,734] INFO [azure-sql-server-source-adress|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.sqlserver.SqlServerConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = azure-sql-server-source-adress
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.delete.handling.mode = rewrite
	transforms.unwrap.drop.fields.from.key = false
	transforms.unwrap.drop.fields.header.name = null
	transforms.unwrap.drop.fields.keep.schema.compatible = true
	transforms.unwrap.drop.tombstones = true
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.transforms.ExtractNewRecordState
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-04-13 15:59:39,735] INFO [azure-sql-server-source-adress|worker] Instantiated connector azure-sql-server-source-adress with version 2.5.1.Final of type class io.debezium.connector.sqlserver.SqlServerConnector (org.apache.kafka.connect.runtime.Worker:334)
[2025-04-13 15:59:39,735] INFO [azure-sql-server-source-adress|worker] Finished creating connector azure-sql-server-source-adress (org.apache.kafka.connect.runtime.Worker:355)
[2025-04-13 15:59:39,735] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1988)
[2025-04-13 15:59:39,736] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.sqlserver.SqlServerConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = azure-sql-server-source-adress
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [unwrap]
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2025-04-13 15:59:39,736] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.sqlserver.SqlServerConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = azure-sql-server-source-adress
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.delete.handling.mode = rewrite
	transforms.unwrap.drop.fields.from.key = false
	transforms.unwrap.drop.fields.header.name = null
	transforms.unwrap.drop.fields.keep.schema.compatible = true
	transforms.unwrap.drop.tombstones = true
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.transforms.ExtractNewRecordState
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-04-13 15:59:39,737] INFO [azure-sql-server-source-adress|worker] Loading the custom source info struct maker plugin: io.debezium.connector.sqlserver.SqlServerSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1318)
[2025-04-13 15:59:39,777] INFO [azure-sql-server-source-adress|worker] Connection gracefully closed (io.debezium.jdbc.JdbcConnection:949)
[2025-04-13 15:59:39,785] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Tasks [azure-sql-server-source-adress-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2440)
[2025-04-13 15:59:39,786] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:242)
[2025-04-13 15:59:39,786] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:604)
[2025-04-13 15:59:39,787] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=81, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:665)
[2025-04-13 15:59:39,790] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=81, memberId='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:842)
[2025-04-13 15:59:39,790] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Joined group at generation 81 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-10.0.0.4:8083-ea5c92aa-0cbc-4ec7-a84a-56e0f7e3d7e1', leaderUrl='http://10.0.0.4:8083/', offset=104, connectorIds=[azure-sql-server-source-adress, azure-sql-server-source], taskIds=[azure-sql-server-source-adress-0, azure-sql-server-source-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2621)
[2025-04-13 15:59:39,790] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Starting connectors and tasks using config offset 104 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1959)
[2025-04-13 15:59:39,790] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Starting task azure-sql-server-source-adress-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2002)
[2025-04-13 15:59:39,791] INFO [azure-sql-server-source-adress|task-0] Creating task azure-sql-server-source-adress-0 (org.apache.kafka.connect.runtime.Worker:645)
[2025-04-13 15:59:39,791] INFO [azure-sql-server-source-adress|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.sqlserver.SqlServerConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = azure-sql-server-source-adress
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap]
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2025-04-13 15:59:39,792] INFO [azure-sql-server-source-adress|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.sqlserver.SqlServerConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = azure-sql-server-source-adress
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.delete.handling.mode = rewrite
	transforms.unwrap.drop.fields.from.key = false
	transforms.unwrap.drop.fields.header.name = null
	transforms.unwrap.drop.fields.keep.schema.compatible = true
	transforms.unwrap.drop.tombstones = true
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.transforms.ExtractNewRecordState
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-04-13 15:59:39,792] INFO [azure-sql-server-source-adress|task-0] TaskConfig values: 
	task.class = class io.debezium.connector.sqlserver.SqlServerConnectorTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2025-04-13 15:59:39,793] INFO [azure-sql-server-source-adress|task-0] Instantiated task azure-sql-server-source-adress-0 with version 2.5.1.Final of type io.debezium.connector.sqlserver.SqlServerConnectorTask (org.apache.kafka.connect.runtime.Worker:664)
[2025-04-13 15:59:39,794] INFO [azure-sql-server-source-adress|task-0] JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-04-13 15:59:39,794] INFO [azure-sql-server-source-adress|task-0] Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task azure-sql-server-source-adress-0 using the worker config (org.apache.kafka.connect.runtime.Worker:677)
[2025-04-13 15:59:39,794] INFO [azure-sql-server-source-adress|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2025-04-13 15:59:39,794] INFO [azure-sql-server-source-adress|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task azure-sql-server-source-adress-0 using the worker config (org.apache.kafka.connect.runtime.Worker:683)
[2025-04-13 15:59:39,794] INFO [azure-sql-server-source-adress|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task azure-sql-server-source-adress-0 using the worker config (org.apache.kafka.connect.runtime.Worker:690)
[2025-04-13 15:59:39,794] WARN [azure-sql-server-source-adress|task-0] The deleted record handling configs "drop.tombstones" and "delete.handling.mode" have been deprecated, please use "delete.tombstone.handling.mode" instead. (io.debezium.transforms.AbstractExtractNewRecordState:101)
[2025-04-13 15:59:39,794] INFO [azure-sql-server-source-adress|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{io.debezium.transforms.ExtractNewRecordState} (org.apache.kafka.connect.runtime.Worker:1794)
[2025-04-13 15:59:39,795] INFO [azure-sql-server-source-adress|task-0] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.sqlserver.SqlServerConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = azure-sql-server-source-adress
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [unwrap]
	value.converter = null
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:372)
[2025-04-13 15:59:39,795] INFO [azure-sql-server-source-adress|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.debezium.connector.sqlserver.SqlServerConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = null
	name = azure-sql-server-source-adress
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	tasks.max.enforce = true
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = [unwrap]
	transforms.unwrap.add.fields = []
	transforms.unwrap.add.fields.prefix = __
	transforms.unwrap.add.headers = []
	transforms.unwrap.add.headers.prefix = __
	transforms.unwrap.delete.handling.mode = rewrite
	transforms.unwrap.drop.fields.from.key = false
	transforms.unwrap.drop.fields.header.name = null
	transforms.unwrap.drop.fields.keep.schema.compatible = true
	transforms.unwrap.drop.tombstones = true
	transforms.unwrap.negate = false
	transforms.unwrap.predicate = null
	transforms.unwrap.route.by.field = 
	transforms.unwrap.type = class io.debezium.transforms.ExtractNewRecordState
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2025-04-13 15:59:39,796] INFO [azure-sql-server-source-adress|task-0] ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connector-producer-azure-sql-server-source-adress-0
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = none
	compression.zstd.level = 3
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	enable.metrics.push = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metadata.recovery.strategy = none
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.max.ms = 1000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2025-04-13 15:59:39,800] INFO [azure-sql-server-source-adress|task-0] initializing Kafka metrics collector (org.apache.kafka.common.telemetry.internals.KafkaMetricsCollector:269)
[2025-04-13 15:59:39,803] INFO [azure-sql-server-source-adress|task-0] These configurations '[metrics.context.connect.kafka.cluster.id, metrics.context.connect.group.id]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:381)
[2025-04-13 15:59:39,803] INFO [azure-sql-server-source-adress|task-0] Kafka version: 3.8.1 (org.apache.kafka.common.utils.AppInfoParser:124)
[2025-04-13 15:59:39,803] INFO [azure-sql-server-source-adress|task-0] Kafka commitId: 70d6ff42debf7e17 (org.apache.kafka.common.utils.AppInfoParser:125)
[2025-04-13 15:59:39,803] INFO [azure-sql-server-source-adress|task-0] Kafka startTimeMs: 1744559979803 (org.apache.kafka.common.utils.AppInfoParser:126)
[2025-04-13 15:59:39,805] INFO [azure-sql-server-source-adress|task-0] Starting SqlServerConnectorTask with configuration: (io.debezium.connector.common.BaseSourceTask:135)
[2025-04-13 15:59:39,806] INFO [azure-sql-server-source-adress|task-0]    connector.class = io.debezium.connector.sqlserver.SqlServerConnector (io.debezium.connector.common.BaseSourceTask:137)
[2025-04-13 15:59:39,806] INFO [azure-sql-server-source-adress|task-0]    incrementing.column.name = AddressID (io.debezium.connector.common.BaseSourceTask:137)
[2025-04-13 15:59:39,806] INFO [azure-sql-server-source-adress|task-0]    transforms.unwrap.delete.handling.mode = rewrite (io.debezium.connector.common.BaseSourceTask:137)
[2025-04-13 15:59:39,806] INFO [azure-sql-server-source-adress|task-0]    tasks.max = 1 (io.debezium.connector.common.BaseSourceTask:137)
[2025-04-13 15:59:39,806] INFO [azure-sql-server-source-adress|task-0]    transforms = unwrap (io.debezium.connector.common.BaseSourceTask:137)
[2025-04-13 15:59:39,806] INFO [azure-sql-server-source-adress|task-0]    mode = incrementing (io.debezium.connector.common.BaseSourceTask:137)
[2025-04-13 15:59:39,806] INFO [azure-sql-server-source-adress|task-0]    topic.prefix = azure-sql- (io.debezium.connector.common.BaseSourceTask:137)
[2025-04-13 15:59:39,806] INFO [azure-sql-server-source-adress|task-0]    schema.history.internal.kafka.topic = schema-changes.database01 (io.debezium.connector.common.BaseSourceTask:137)
[2025-04-13 15:59:39,806] INFO [azure-sql-server-source-adress|task-0]    poll.interval.ms = 10000 (io.debezium.connector.common.BaseSourceTask:137)
[2025-04-13 15:59:39,806] INFO [azure-sql-server-source-adress|task-0]    transforms.unwrap.drop.tombstones = true (io.debezium.connector.common.BaseSourceTask:137)
[2025-04-13 15:59:39,806] INFO [azure-sql-server-source-adress|task-0]    transforms.unwrap.type = io.debezium.transforms.ExtractNewRecordState (io.debezium.connector.common.BaseSourceTask:137)
[2025-04-13 15:59:39,806] INFO [azure-sql-server-source-adress|task-0]    database.encrypt = true (io.debezium.connector.common.BaseSourceTask:137)
[2025-04-13 15:59:39,806] INFO [azure-sql-server-source-adress|task-0]    database.user = kafkadmin@kafkadatabase (io.debezium.connector.common.BaseSourceTask:137)
[2025-04-13 15:59:39,806] INFO [azure-sql-server-source-adress|task-0]    database.dbname = database01 (io.debezium.connector.common.BaseSourceTask:137)
[2025-04-13 15:59:39,806] INFO [azure-sql-server-source-adress|task-0]    database.names = database01 (io.debezium.connector.common.BaseSourceTask:137)
[2025-04-13 15:59:39,806] INFO [azure-sql-server-source-adress|task-0]    database.server.name = server1 (io.debezium.connector.common.BaseSourceTask:137)
[2025-04-13 15:59:39,806] INFO [azure-sql-server-source-adress|task-0]    schema.history.internal.kafka.bootstrap.servers = localhost:9092 (io.debezium.connector.common.BaseSourceTask:137)
[2025-04-13 15:59:39,806] INFO [azure-sql-server-source-adress|task-0]    database.port = 1433 (io.debezium.connector.common.BaseSourceTask:137)
[2025-04-13 15:59:39,806] INFO [azure-sql-server-source-adress|task-0]    task.class = io.debezium.connector.sqlserver.SqlServerConnectorTask (io.debezium.connector.common.BaseSourceTask:137)
[2025-04-13 15:59:39,806] INFO [azure-sql-server-source-adress|task-0]    database.hostname = kafkadatabase.database.windows.net (io.debezium.connector.common.BaseSourceTask:137)
[2025-04-13 15:59:39,806] INFO [azure-sql-server-source-adress|task-0]    database.password = ******** (io.debezium.connector.common.BaseSourceTask:137)
[2025-04-13 15:59:39,806] INFO [azure-sql-server-source-adress|task-0]    name = azure-sql-server-source-adress (io.debezium.connector.common.BaseSourceTask:137)
[2025-04-13 15:59:39,809] INFO [azure-sql-server-source-adress|task-0]    task.id = 0 (io.debezium.connector.common.BaseSourceTask:137)
[2025-04-13 15:59:39,809] INFO [azure-sql-server-source-adress|task-0]    table.include.list = SalesLT.Address (io.debezium.connector.common.BaseSourceTask:137)
[2025-04-13 15:59:39,809] INFO [azure-sql-server-source-adress|task-0]    database.trustServerCertificate = true (io.debezium.connector.common.BaseSourceTask:137)
[2025-04-13 15:59:39,810] INFO [azure-sql-server-source-adress|task-0] Loading the custom source info struct maker plugin: io.debezium.connector.sqlserver.SqlServerSourceInfoStructMaker (io.debezium.config.CommonConnectorConfig:1318)
[2025-04-13 15:59:39,806] INFO [Worker clientId=connect-10.0.0.4:8083, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1988)
[2025-04-13 15:59:39,810] INFO [azure-sql-server-source-adress|task-0] Loading the custom topic naming strategy plugin: io.debezium.schema.SchemaTopicNamingStrategy (io.debezium.config.CommonConnectorConfig:1066)
[2025-04-13 15:59:39,812] INFO [azure-sql-server-source-adress|task-0] KafkaSchemaHistory Consumer config: {key.deserializer=org.apache.kafka.common.serialization.StringDeserializer, value.deserializer=org.apache.kafka.common.serialization.StringDeserializer, enable.auto.commit=false, group.id=azure-sql--schemahistory, bootstrap.servers=localhost:9092, fetch.min.bytes=1, session.timeout.ms=10000, auto.offset.reset=earliest, client.id=azure-sql--schemahistory} (io.debezium.storage.kafka.history.KafkaSchemaHistory:245)
[2025-04-13 15:59:39,815] INFO [azure-sql-server-source-adress|task-0] KafkaSchemaHistory Producer config: {retries=1, value.serializer=org.apache.kafka.common.serialization.StringSerializer, acks=1, batch.size=32768, max.block.ms=10000, bootstrap.servers=localhost:9092, buffer.memory=1048576, key.serializer=org.apache.kafka.common.serialization.StringSerializer, client.id=azure-sql--schemahistory, linger.ms=0} (io.debezium.storage.kafka.history.KafkaSchemaHistory:246)
[2025-04-13 15:59:39,815] INFO [azure-sql-server-source-adress|task-0] Requested thread factory for connector SqlServerConnector, id = azure-sql- named = db-history-config-check (io.debezium.util.Threads:271)
[2025-04-13 15:59:39,816] WARN [azure-sql-server-source-adress|task-0] Unable to register metrics as an old set with the same name exists, retrying in PT5S (attempt 1 out of 12) (io.debezium.pipeline.JmxUtils:55)
[2025-04-13 15:59:39,814] INFO [azure-sql-server-source-adress|task-0] [Producer clientId=connector-producer-azure-sql-server-source-adress-0] Cluster ID: PRZJITuEQBeLmWOW7dnIsg (org.apache.kafka.clients.Metadata:364)
[2025-04-13 15:59:44,816] WARN [azure-sql-server-source-adress|task-0] Unable to register metrics as an old set with the same name exists, retrying in PT5S (attempt 2 out of 12) (io.debezium.pipeline.JmxUtils:55)
[2025-04-13 15:59:49,817] WARN [azure-sql-server-source-adress|task-0] Unable to register metrics as an old set with the same name exists, retrying in PT5S (attempt 3 out of 12) (io.debezium.pipeline.JmxUtils:55)
[2025-04-13 15:59:54,817] WARN [azure-sql-server-source-adress|task-0] Unable to register metrics as an old set with the same name exists, retrying in PT5S (attempt 4 out of 12) (io.debezium.pipeline.JmxUtils:55)
[2025-04-13 15:59:59,818] WARN [azure-sql-server-source-adress|task-0] Unable to register metrics as an old set with the same name exists, retrying in PT5S (attempt 5 out of 12) (io.debezium.pipeline.JmxUtils:55)
